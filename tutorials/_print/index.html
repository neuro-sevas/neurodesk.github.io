<!doctype html><html lang=en class=no-js>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=generator content="Hugo 0.89.2"><link rel=canonical type=text/html href=https://neurodesk.github.io/tutorials/>
<link rel=alternate type=application/rss+xml href=https://neurodesk.github.io/tutorials/index.xml>
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<link rel="shortcut icon" href=/favicons/favicon.ico>
<link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180>
<link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16>
<link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32>
<link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36>
<link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48>
<link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72>
<link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96>
<link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144>
<link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192>
<title>Tutorials | NeuroDesk</title>
<meta name=description content="Tutorials
">
<meta property="og:title" content="Tutorials">
<meta property="og:description" content="Tutorials
">
<meta property="og:type" content="website">
<meta property="og:url" content="https://neurodesk.github.io/tutorials/"><meta property="og:site_name" content="NeuroDesk">
<meta itemprop=name content="Tutorials">
<meta itemprop=description content="Tutorials
"><meta name=twitter:card content="summary">
<meta name=twitter:title content="Tutorials">
<meta name=twitter:description content="Tutorials
">
<link rel=preload href=/scss/main.min.07088c7cdf0ef572c4320691d48af4ae3ff0098f2abcc47cee83589c7933226a.css as=style>
<link href=/scss/main.min.07088c7cdf0ef572c4320691d48af4ae3ff0098f2abcc47cee83589c7933226a.css rel=stylesheet integrity>
<script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<link rel=stylesheet href=/css/prism.css>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-00000000-0','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
</head>
<body class=td-section>
<header>
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
<a class=navbar-brand href=/>
<span class=navbar-logo></span><span class="text-uppercase font-weight-bold">NeuroDesk</span>
</a>
<div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar>
<ul class="navbar-nav mt-2 mt-lg-0">
<li class="nav-item mr-4 mb-2 mb-lg-0">
<a class=nav-link href=/docs/><span>Documentation</span></a>
</li>
<li class="nav-item mr-4 mb-2 mb-lg-0">
<a class=nav-link href=/developers/><span>Developers</span></a>
</li>
<li class="nav-item mr-4 mb-2 mb-lg-0">
<a class="nav-link active" href=/tutorials/><span class=active>Tutorials</span></a>
</li>
<li class="nav-item mr-4 mb-2 mb-lg-0">
<a class=nav-link href=/blog/><span>News</span></a>
</li>
<li class="nav-item mr-4 mb-2 mb-lg-0">
<a class=nav-link href=https://github.com/NeuroDesk target=_blank><i class="fab fa-github"></i><span>GitHub</span></a>
</li>
</ul>
</div>
<div class="navbar-nav d-none d-lg-block">
<input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off>
</div>
</nav>
</header>
<div class="container-fluid td-outer">
<div class=td-main>
<div class="row flex-xl-nowrap">
<div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
</div>
<div class="d-none d-xl-block col-xl-2 td-toc d-print-none">
</div>
<main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main>
<div class=td-content>
<div class="pageinfo pageinfo-primary d-print-none">
<p>
This the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.
</p><p>
<a href=/tutorials/>Return to the regular view of this page</a>.
</p>
</div>
<h1 class=title>Tutorials</h1>
<div class=lead>Tutorials</div>
<ul>
<li>1: <a href=#pg-49ca1e3e5876541479c39ca4c2df0968>Electrophysiology</a></li>
<ul>
<li>1.1: <a href=#pg-7212f82ad48dcf25da7a87aef4dbbdaf>Analysing EEG Data with MNE</a></li>
</ul>
<li>2: <a href=#pg-692ee0c0d1d645ba985513777e1a945e>MRI phase Processing</a></li>
<ul>
<li>2.1: <a href=#pg-ed3153aa84e753252b1a096df3880cc5>Quantitative Susceptibility Mapping</a></li>
<li>2.2: <a href=#pg-3174433b4a44ad886176920795e9074f>SWI</a></li>
<li>2.3: <a href=#pg-359022268721811f542c4065f38891ed>Unwrapping</a></li>
</ul>
<li>3: <a href=#pg-15c972db4ef066d5b196709a32931050>Structural Imaging</a></li>
<ul>
<li>3.1: <a href=#pg-0fe48d9b685f097a75026e660a1fae15>FreeSurfer</a></li>
</ul>
<li>4: <a href=#pg-9d3542de6d1d1b0ffa46b2886fe35344>Documentation</a></li>
<ul>
<li>4.1: <a href=#pg-b0590b6e45cbf130ebe8a6b8b8677519>Template for workflow creation</a></li>
</ul>
</ul>
<div class=content>
</div>
</div>
<div class=td-content>
<h1 id=pg-49ca1e3e5876541479c39ca4c2df0968>1 - Electrophysiology</h1>
<div class=lead>Tutorials about processing of EEG/MEG/ECoG data</div>
</div>
<div class=td-content>
<h1 id=pg-7212f82ad48dcf25da7a87aef4dbbdaf>1.1 - Analysing EEG Data with MNE</h1>
<div class=lead>Use mne-python to load, pre-process, and plot example EEG data in a jupyter notebook through vscode.</div>
<h2 id=getting-started>Getting started</h2>
<p>Open Visual Studio Code:</p>
<p><img src=/EEG_Tutorial/EEGtut1.png alt=EEGtut1 title=EEGtut1></p>
<p>Open the folder: “/home/user/Desktop/neurodesktop-storage” or a subfolder in which you would like to store this demo. In this folder, create a new file named “EEGDemo.ipynb” or something similar:</p>
<p><img src=/EEG_Tutorial/EEGtut2.png alt=EEGtut2 title=EEGtut2></p>
<p>If this is your first time opening a Jupyter notebook on vscode in neurodesktop, you will see the following popup. If so, click “install” to install the vscode extensions for Jupyter.</p>
<p><img src=/EEG_Tutorial/EEGtut3.png alt=EEGtut3 title=EEGtut3></p>
<h2 id=set-up-an-environment>Set up an environment</h2>
<blockquote>
<p>Coming soon! Neurodesktop will soon feature a number of built in conda environments for standard analyses of behavioural, physiological, and encephalographic data.</p>
</blockquote>
<p>From the top menu in vscode, select Terminal->New Terminal, or hit [Ctrl]+[Shift]+[`]. From this terminal, create and activate a new conda environment in which to run mne-python.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>conda create --name=mne --channel=conda-forge mne python=3 jupyter nb_conda_kernels 
conda activate mne
</code></pre></div><p>Once your new environment is activated, in the top right corner of your empty jupyter notebook, click “Select Kernel”:</p>
<p><img src=/EEG_Tutorial/EEGtut4.png alt=EEGtut4 title=EEGtut4></p>
<p>Then, select the instance of Python associated with the environment you have just created (“mne”). If your new environment does not appear in the list, you may need to restart vscode:</p>
<p><img src=/EEG_Tutorial/EEGtut5.png alt=EEGtut5 title=EEGtut5></p>
<p>At this point you may also be prompted to install the vscode packages for python. Once you have installed these, you’re ready to rumble!</p>
<h2 id=download-sample-data>Download sample data</h2>
<p>In the terminal, input the following code to download some BIDS formatted sample EEG data:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>pip install osfclient
osf -p C689U fetch Data_sample.zip /neurodesktop-storage/EEGDEMO/Data_sample.zip
unzip Data_sample.zip 
</code></pre></div><p>This is a small dataset with only 5 EEG channels from a single participant. The participant is viewing a frequency tagged display and is cued to attend to dots tagged at one frequency or another (6 Hz, 7.5 Hz) for long, 15 s trials. To read more about the dataset, click <a href=https://osf.io/c689u/>here</a></p>
<h2 id=plotting-settings>Plotting settings</h2>
<p>To make sure our plots retain their interactivity, set the following line at the top of your notebook:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>%matplotlib qt
</code></pre></div><p>This will mean your figures pop out as individual, interactive plots that will allow you to explore the data, rather than as static, inline plots. You can switch “qt” to “inline” to switch back to default, inline plotting.</p>
<h2 id=loading-and-processing-data>Loading and processing data</h2>
<blockquote>
<p>NOTE: MNE has many helpful tutorials which delve into data processing and analysis using MNE-python in much further detail. These can be found <a href=https://mne.tools/stable/auto_tutorials/index.html>here</a></p>
</blockquote>
<p>Begin by importing the necessary modules and creating a pointer to the data:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback># Interactive plotting
%matplotlib qt

# Import modules
import os
import numpy as np
import mne

# Load data
sample_data_folder = &#39;/home/user/Desktop/neurodesktop-storage/EEGDemo/Data_sample&#39;
sample_data_raw_file = os.path.join(sample_data_folder, &#39;sub-01&#39;, &#39;eeg&#39;,
                                    &#39;sub-01_task-FeatAttnDec_eeg.vhdr&#39;)
raw = mne.io.read_raw_brainvision(sample_data_raw_file , preload=True)
</code></pre></div><p>the raw.info structure contains information about the dataset:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback># Display data info
print(raw)
print(raw.info)
</code></pre></div><p>This data file did not include a montage. Lets create one using standard values for the electrodes we have:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback># Create montage
montage = {&#39;Iz&#39;:  [0, -110, -40],
            &#39;Oz&#39;: [0, -105, -15],
            &#39;POz&#39;: [0,   -100, 15],
            &#39;O1&#39;: [-40, -106, -15],
            &#39;O2&#39;:  [40, -106, -15],
 }

montageuse = mne.channels.make_dig_montage(ch_pos=montage, lpa=[-82.5, -19.2, -46], nasion=[0, 83.2, -38.3], rpa=[82.2, -19.2, -46]) # based on mne help file on setting 10-20 montage
</code></pre></div><p>Next, lets visualise the data.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>raw.plot()
</code></pre></div><p>This should open an interactive window in which you can scroll through the data. See the MNE documentation for help on how to customise this plot.</p>
<p><img src=/EEG_Tutorial/EEGtut6.png alt=EEGtut6 title=EEGtut6></p>
<p>If, upon visual inspection, you decide to exclude one of the channels, you can specify this in raw.info[‘bads’] now. For example:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>raw.info[&#39;bads&#39;] = [&#39;POz&#39;]
</code></pre></div><p>Next, we’ll extract our events. The trigger channel in this file is incorrectly scaled, so we’ll correct that before we extract our events:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback># Correct trigger scaling
trigchan = raw.pick(&#39;TRIG&#39;).copy()
trigchan._data = trigchan._data*1000000

# Extract events
events = mne.find_events(trigchan, stim_channel=&#39;TRIG&#39;, consecutive=True, initial_event=True, verbose=True)
print(&#39;Found %s events, first five:&#39; % len(events))
print(events[:5])

# Plot events
mne.viz.plot_events(events, raw.info[&#39;sfreq&#39;], raw.first_samp)
</code></pre></div><p><img src=/EEG_Tutorial/EEGtut7.png alt=EEGtut7 title=EEGtut7></p>
<p>Now that we’ve extracted our events, we can extract our EEG channels and do some simple pre-processing:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback># select
eeg_data = raw.copy().pick_types(eeg=True, exclude=[&#39;TRIG&#39;])

# Set montage
eeg_data.info.set_montage(montageuse)

# Interpolate
eeg_data_interp = eeg_data.copy().interpolate_bads(reset_bads=True) 

# Filter Data
eeg_data_interp.filter(l_freq=1, h_freq=45, h_trans_bandwidth=0.1)
</code></pre></div><p>Let’s visualise our data again now that it’s cleaner:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>#plot results again, this time with some events and scaling. 
eeg_data_interp.plot(events=events, duration=10.0, scalings=dict(eeg=0.00005), color=&#39;k&#39;, event_color=&#39;r&#39;)
</code></pre></div><p><img src=/EEG_Tutorial/EEGtut8.png alt=EEGtut8 title=EEGtut8></p>
<p>That’s looking good! We can even see hints of the frequency tagging. It’s about time to epoch our data.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback># Epoch to events of interest
event_id = {&#39;attend 6Hz K&#39;: 23, &#39;attend 7.5Hz K&#39;:  27}  

# Extract 15 s epochs relative to events, baseline correct, linear detrend, and reject 
# epochs where eeg amplitude is &gt; 400
epochs = mne.Epochs(eeg_data_interp, events, event_id=event_id, tmin=0,
                    tmax=15, baseline=(0, 0), reject=dict(eeg=0.000400), detrend=1)  

# Drop bad trials
epochs.drop_bad()
</code></pre></div><p>We can average these epochs to form Event Related Potentials (ERPs):</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback># Average erpochs to form ERPs
attend6 = epochs[&#39;attend 6Hz K&#39;].average()
attend75 = epochs[&#39;attend 7.5Hz K&#39;].average()

# Plot ERPs
evokeds = dict(attend6=list(epochs[&#39;attend 6Hz K&#39;].iter_evoked()),
               attend75=list(epochs[&#39;attend 7.5Hz K&#39;].iter_evoked()))
mne.viz.plot_compare_evokeds(evokeds, combine=&#39;mean&#39;)
</code></pre></div><p><img src=/EEG_Tutorial/EEGtut9.png alt=EEGtut9 title=EEGtut9></p>
<p>In this plot, we can see that the data are frequency tagged. While these data were collected, the participant was performing an attention task in which two visual stimuli were flickering at 6 Hz and 7.5 Hz respectively. On each trial the participant was cued to monitor one of these two stimuli for brief bursts of motion. From previous research, we expect that the steady-state visual evoked potential (SSVEP) should be larger at the attended frequency than the unattended frequency. Lets check if this is true.</p>
<p>We&rsquo;ll begin by exporting our epoched EEG data to a numpy array</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback># Preallocate
n_samples = attend6.data.shape[1]
sampling_freq = 1200 # sampling frequency
epochs_np = np.empty((n_samples, 2) )

# Get data - averaging across EEG channels
epochs_np[:,0] = attend6.data.mean(axis=0)
epochs_np[:,1] = attend75.data.mean(axis=0)

</code></pre></div><p>Next, we can use a Fast Fourier Transform (FFT) to transform the data from the time domain to the frequency domain. For this, we&rsquo;ll need to import the FFT packages from scipy:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>from scipy.fft import fft, fftfreq, fftshift

# Get FFT
fftdat = np.abs(fft(epochs_np, axis=0)) / n_samples
freq = fftfreq(n_samples, d=1 / sampling_freq)  # get frequency bins

</code></pre></div><p>Now that we have our frequency transformed data, we can plot our two conditions to assess whether attention altered the SSVEP amplitudes:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>import matplotlib.pyplot as plt

fig,ax = plt.subplots(1, 1)

ax.plot(freq, fftdat[:,0], &#39;-&#39;, label=&#39;attend 6Hz&#39;, color=[78 / 255, 185 / 255, 159 / 255])  
ax.plot(freq, fftdat[:,1], &#39;-&#39;, label=&#39;attend 7.5Hz&#39;, color=[236 / 255, 85 / 255, 58 / 255])  
ax.set_xlim(4, 17)
ax.set_ylim(0, 1e-6)
ax.set_title(&#39;Frequency Spectrum&#39;)
ax.legend()


</code></pre></div><p><img src=/EEG_Tutorial/EEGtut10.PNG alt=EEGtut10 title=EEGtut10></p>
<p>This plot shows that the SSVEPs were indeed modulated by attention in the direction we would expect! Congratulations! You’ve run your first analysis of EEG data in neurodesktop.</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-692ee0c0d1d645ba985513777e1a945e>2 - MRI phase Processing</h1>
<div class=lead>Tutorials about processing MRI phase</div>
</div>
<div class=td-content>
<h1 id=pg-ed3153aa84e753252b1a096df3880cc5>2.1 - Quantitative Susceptibility Mapping</h1>
<div class=lead>Example workflow for Quantitative Susceptibility Mapping</div>
<h2 id=quantitative-susceptibility-mapping-in-qsmxt>Quantitative Susceptibility Mapping in QSMxT</h2>
<p>Neurodesk includes QSMxT, a complete and end-to-end QSM processing and analysis framework that excels at automatically reconstructing and processing QSM for large groups of participants.</p>
<p>QSMxT provides pipelines implemented in Python that:</p>
<ol>
<li>Automatically convert DICOM data to the Brain Imaging Data Structure (BIDS)</li>
<li>Automatically reconstruct QSM, including steps for:
<ol>
<li>Robust masking without anatomical priors</li>
<li>Phase unwrapping (Laplacian based)</li>
<li>Background field removal + dipole inversion (<code>tgv_qsm</code>)</li>
<li>Multi-echo combination</li>
</ol>
</li>
<li>Automatically generate a common group space for the whole study, as well as average magnitude and QSM images that facilitate group-level analyses.</li>
<li>Automatically segment T1w data and register them to the QSM space to extract quantitative values in anatomical regions of interest.</li>
<li>Export quantitative data to CSV for all subjects using the automated segmentations, or a custom segmentation in the group space (we recommend ITK snap).</li>
</ol>
<p>If you use QSMxT for a study, please cite <a href=https://doi.org/10.1101/2021.05.05.442850>https://doi.org/10.1101/2021.05.05.442850</a>.</p>
<h2 id=download-demo-data>Download demo data</h2>
<p>Open a terminal and run:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>pip install osfclient
cd /neurodesktop-storage/
osf -p ru43c clone /neurodesktop-storage/qsmxt-demo
unzip /neurodesktop-storage/qsmxt-demo/osfstorage/GRE_2subj_1mm_TE20ms/sub1/GR_M_5_QSM_p2_1mmIso_TE20.zip -d /neurodesktop-storage/qsmxt-demo/dicoms
unzip /neurodesktop-storage/qsmxt-demo/osfstorage/GRE_2subj_1mm_TE20ms/sub1/GR_P_6_QSM_p2_1mmIso_TE20.zip -d /neurodesktop-storage/qsmxt-demo/dicoms
unzip /neurodesktop-storage/qsmxt-demo/osfstorage/GRE_2subj_1mm_TE20ms/sub2/GR_M_5_QSM_p2_1mmIso_TE20.zip -d /neurodesktop-storage/qsmxt-demo/dicoms
unzip /neurodesktop-storage/qsmxt-demo/osfstorage/GRE_2subj_1mm_TE20ms/sub2/GR_P_6_QSM_p2_1mmIso_TE20.zip -d /neurodesktop-storage/qsmxt-demo/dicoms
</code></pre></div><h2 id=qsmxt-usage>QSMxT Usage</h2>
<p>Start QSMxT (in this demo we used 1.1.6) from the applications menu in the desktop (<em>Neurodesk</em> > <em>Quantitative Imaging</em> > <em>qsmxt</em>)</p>
<ol>
<li>Convert DICOM data to BIDS:
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87>cd</span> /neurodesktop-storage/qsmxt-demo
python3 /opt/QSMxT/run_0_dicomSort.py /neurodesktop-storage/qsmxt-demo/dicoms 00_dicom
python3 /opt/QSMxT/run_1_dicomToBids.py 00_dicom 01_bids
</code></pre></div></li>
</ol>
<p>After this step check if the data were correctly recognized and converted to BIDS. Otherwise make a copy of /opt/QSMxT/bidsmap.yaml - adjust based on provenance example in 01_bids/code/bidscoin/bidsmap.yaml (see for example what it detected under extra_files) - and run again with the parameter <code>--heuristic bidsmap.yaml</code>. If the data were acquired on a GE scanner the complex data needs to be corrected by applying an FFT shift, this can be done with <code>python /opt/QSMxT/run_1_fixGEphaseFFTshift.py 01_bids/sub*/ses*/anat/*_run-1_*.nii.gz</code> .</p>
<ol start=2>
<li>Run QSM pipeline:
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>python3 /opt/QSMxT/run_2_qsm.py 01_bids 02_qsm_output
</code></pre></div></li>
</ol>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-3174433b4a44ad886176920795e9074f>2.2 - SWI</h1>
<div class=lead>Example workflow for SWI processing</div>
<h2 id=download-demo-data>Download demo data</h2>
<p>Open a terminal and run:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>pip install osfclient
cd /neurodesktop-storage/
osf -p ru43c fetch 01_bids.zip /neurodesktop-storage/swi-demo/01_bids.zip

unzip /neurodesktop-storage/swi-demo/01_bids.zip -d /neurodesktop-storage/swi-demo/
</code></pre></div><p>Open the CLEARSWI tool from the application menu:</p>
<p>paste this julia script in a julia file and execute:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>cd /neurodesktop-storage/
vi clearswi.jl
</code></pre></div><p>hit a or i and then paste this:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>using CLEARSWI

TEs = [20] 
nifti_folder = &#34;/neurodesktop-storage/swi-demo/01_bids/sub-170705134431std1312211075243167001/ses-1/anat&#34;
magfile = joinpath(nifti_folder, &#34;sub-170705134431std1312211075243167001_ses-1_acq-qsm_run-1_magnitude.nii.gz&#34;)
phasefile = joinpath(nifti_folder, &#34;sub-170705134431std1312211075243167001_ses-1_acq-qsmPH00_run-1_phase.nii.gz&#34;) 

mag = readmag(magfile);
phase = readphase(phasefile);
data = Data(mag, phase, mag.header, TEs);

swi = calculateSWI(data);
# mip = createIntensityProjection(swi, minimum); # minimum intensity projection, other Julia functions can be used instead of minimum
mip = createMIP(swi); # shorthand for createIntensityProjection(swi, minimum)

savenii(swi, &#34;/neurodesktop-storage/swi-demo/swi.nii&#34;; header=mag.header) 
savenii(mip, &#34;/neurodesktop-storage/swi-demo/mip.nii&#34;; header=mag.header)
</code></pre></div><p>hit SHIFT-Z-Z and run:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>julia clearswi.jl
</code></pre></div><p>Open ITK snap from the Visualization Application&rsquo;s menu and inspect the results (the outputs are in swi-demo/swi.nii and mip.nii)
<img src=https://user-images.githubusercontent.com/4021595/137708852-6b7dd2c7-3e6f-42fd-88e6-06afe87a72a9.png alt=image></p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-359022268721811f542c4065f38891ed>2.3 - Unwrapping</h1>
<div class=lead>MRI Phase Unwrapping</div>
<h2 id=download-demo-data>Download demo data</h2>
<p>Open a terminal and run:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>pip install osfclient
cd /neurodesktop-storage/
osf -p ru43c fetch 01_bids.zip /neurodesktop-storage/swi-demo/01_bids.zip

unzip /neurodesktop-storage/swi-demo/01_bids.zip -d /neurodesktop-storage/swi-demo/


mkdir /neurodesktop-storage/romeo-demo/

cp /neurodesktop-storage/swi-demo/01_bids/sub-170705134431std1312211075243167001/ses-1/anat/sub-170705134431std1312211075243167001_ses-1_acq-qsmPH00_run-1_phase.nii.gz /neurodesktop-storage/romeo-demo/phase.nii.gz

cp /neurodesktop-storage/swi-demo/01_bids/sub-170705134431std1312211075243167001/ses-1/anat/sub-170705134431std1312211075243167001_ses-1_acq-qsm_run-1_magnitude.nii.gz /neurodesktop-storage/romeo-demo/mag.nii.gz

gunzip /neurodesktop-storage/romeo-demo/mag.nii.gz
gunzip /neurodesktop-storage/romeo-demo/phase.nii.gz
</code></pre></div><h3 id=using-romeo-for-phase-unwrapping>Using ROMEO for phase unwrapping</h3>
<p>Open the ROMEO tool from the application menu and run:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>romeo -p /neurodesktop-storage/romeo-demo/phase.nii -m /neurodesktop-storage/romeo-demo/mag.nii -k nomask -o /neurodesktop-storage/romeo-demo/
</code></pre></div><p><img src=/MRIPhase_Tutorial/romeo.PNG alt=Romeo title=Romeo></p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-15c972db4ef066d5b196709a32931050>3 - Structural Imaging</h1>
<div class=lead>Tutorials about processing structural MRI data</div>
</div>
<div class=td-content>
<h1 id=pg-0fe48d9b685f097a75026e660a1fae15>3.1 - FreeSurfer</h1>
<div class=lead>Example workflow for FreeSurfer</div>
<h2 id=download-demo-data>Download demo data</h2>
<p>Open a terminal and run:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>pip install osfclient
osf -p bt4ez fetch TOMCAT_DIB/sub-01/ses-01_7T/anat/sub-01_ses-01_7T_T1w_defaced.nii.gz /neurodesktop-storage/sub-01_ses-01_7T_T1w_defaced.nii.gz
</code></pre></div><h2 id=freesurfer-license-file>FreeSurfer License file:</h2>
<p>Before using Freesurfer you need to request a license here (<a href=https://surfer.nmr.mgh.harvard.edu/registration.html>https://surfer.nmr.mgh.harvard.edu/registration.html</a>) and store it in your homedirectory as ~/.license</p>
<h2 id=freesurfer-example>FreeSurfer Example</h2>
<p>Open FreeSurfer (Neurodesk -> Image Segmentation -> Freesurfer -> Freesurfer 7.1.1)</p>
<p>Setup FreeSurfer license (for example - replace with your license):</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>echo &#34;Steffen.Bollmann@cai.uq.edu.au
&gt; 21029
&gt;  *Cqyn12sqTCxo
&gt;  FSxgcvGkNR59Y&#34; &gt;&gt; ~/.license

export FS_LICENSE=~/.license 
</code></pre></div><p>Setup FreeSurfer:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>mkdir /neurodesktop-storage/freesurfer-output
source /opt/freesurfer-7.1.1/SetUpFreeSurfer.sh
export SUBJECTS_DIR=/neurodesktop-storage/freesurfer-output
</code></pre></div><p>Run Recon all pipeline:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>recon-all -subject test-subject -i /neurodesktop-storage/sub-01_ses-01_7T_T1w_defaced.nii.gz -all
</code></pre></div>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-9d3542de6d1d1b0ffa46b2886fe35344>4 - Documentation</h1>
<div class=lead>Tutorials on contributing to the Neurodesk Documentation</div>
</div>
<div class=td-content>
<h1 id=pg-b0590b6e45cbf130ebe8a6b8b8677519>4.1 - Template for workflow creation</h1>
<div class=lead>Follow this template to contribute your own workflow to the Neurodesk documentation.</div>
<blockquote>
<p><em>This tutorial was created by Name P. Namington.</em></p>
<p>Email: <a href=mailto:n.namington@institution.edu.au>n.namington@institution.edu.au</a></p>
<p>Github: @Namesgit</p>
<p>Twitter: @Nameshandle</p>
</blockquote>
<p>Welcome to the workflow template, which you can use to contribute your own neurodesk workflow to our documentation. We aim to collect a wide variety of workflows representing the spectrum of tools available under the neurodesk architechture and the diversity in how researchers might apply them. Please add plently of descriptive detail and make sure that all steps of the workflow work before submitting the tutorial.</p>
<p>You can embelish your text in this tutorial using markdown conventions; text can be <strong>bold</strong>, <em>italic</em>, or <del>strikethrough</del>. You can also add <a href=https://neurodesk.github.io/>Links</a>.</p>
<h2 id=level-2-heading>Level 2 heading</h2>
<p>You can organise your tutorial with headers, starting at level 2 (the page title is a level 1 header). You can also include progressively smaller subheadings:</p>
<h3 id=level-3-heading>Level 3 heading</h3>
<p>Some more detailed information.</p>
<h4 id=level-4-heading>Level 4 heading</h4>
<p>Even more detailed information.</p>
<h2 id=code-blocks>Code blocks</h2>
<p>You can add codeblocks to your tutorial as follows:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback># Some example code
import numpy as np
a = np.array([1, 2])
b = np.array([3, 4])
print(a+b)
</code></pre></div><p>Or add syntax highlighting to your codeblocks:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#a40000>#</span> <span style=color:#000>Some</span> <span style=color:#000>example</span> <span style=color:#000>code</span>
<span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>numpy</span> <span style=color:#000>as</span> <span style=color:#000>np</span>
<span style=color:#000>a</span> <span style=color:#000;font-weight:700>=</span> <span style=color:#000>np</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>array</span><span style=color:#000;font-weight:700>([</span><span style=color:#0000cf;font-weight:700>1</span><span style=color:#000;font-weight:700>,</span> <span style=color:#0000cf;font-weight:700>2</span><span style=color:#000;font-weight:700>])</span>
<span style=color:#000>b</span> <span style=color:#000;font-weight:700>=</span> <span style=color:#000>np</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>array</span><span style=color:#000;font-weight:700>([</span><span style=color:#0000cf;font-weight:700>3</span><span style=color:#000;font-weight:700>,</span> <span style=color:#0000cf;font-weight:700>4</span><span style=color:#000;font-weight:700>])</span>
<span style=color:#204a87>print</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>a</span><span style=color:#ce5c00;font-weight:700>+</span><span style=color:#000>b</span><span style=color:#000;font-weight:700>)</span>
</code></pre></div><p>You can also add code snippets, e.g. <code>var foo = "bar";</code>, which will be shown inline.</p>
<h2 id=images>Images</h2>
<p>To add screenshots to your tutorial, create a subfolder in <code>neurodesk.github.io/static</code> with the same link name as your tutorial. Add your screenshot to this folder, keeping in mind that you may want to adjust your screenshot to a reasonable size before uploading. You can then embed these images in your tutorial using the following convention:</p>
<p><img src=/EEG_Tutorial/EEGtut1.png alt=EEGtut1 title=EEGtut1> </p>
<h2 id=alets-and-warnings>Alets and warnings</h2>
<p>You can grab reader&rsquo;s attention to particularly important information with quoteblocks, alerts and warnings:</p>
<blockquote>
<p>This is a quoteblock</p>
</blockquote>
<p>
<div class="alert alert-primary" role=alert>
This is an alert.
</div>
<div class="alert alert-primary" role=alert>
<h4 class=alert-heading>Note</h4>
This is an alert with a title.
</div>
<div class="alert alert-warning" role=alert>
This is a warning.
</div>
<div class="alert alert-warning" role=alert>
<h4 class=alert-heading>Warning</h4>
This is a warning with a title.
</div>
</p>
<p>You can also segment information as follows:</p>
<hr>
<p>There&rsquo;s a horizontal rule above and below this.</p>
<hr>
<p>Of add page information:
<div class="pageinfo pageinfo-primary">
<p>This is a placeholder. Replace it with your own content.</p>
</div>
</p>
<h2 id=tables>Tables</h2>
<p>You may want to order information in a table as follows:</p>
<table>
<thead>
<tr>
<th>Neuroscientist</th>
<th>Notable work</th>
<th>Lifetime</th>
</tr>
</thead>
<tbody>
<tr>
<td>Santiago Ramón y Cajal</td>
<td>Investigations on microscopic structure of the brain</td>
<td>1852–1934</td>
</tr>
<tr>
<td>Rita Levi-Montalcini</td>
<td>Discovery of nerve growth factor (NGF)</td>
<td>1909–2012</td>
</tr>
<tr>
<td>Anne Treisman</td>
<td>Feature integration theory of attention</td>
<td>1935–2018</td>
</tr>
</tbody>
</table>
<h2 id=lists>Lists</h2>
<p>You may want to organise information in a list as follows:</p>
<p>Here is an unordered list:</p>
<ul>
<li>Rstudio</li>
<li>JASP</li>
<li>SPSS</li>
</ul>
<p>And an ordered list:</p>
<ol>
<li>Collect data</li>
<li>Try to install analysis software</li>
<li>Cry a little</li>
</ol>
<p>And an unordered task list:</p>
<ul>
<li><input checked disabled type=checkbox> Install Neurodesktop</li>
<li><input checked disabled type=checkbox> Analyse data</li>
<li><input disabled type=checkbox> Take a vacation</li>
</ul>
<p>And a &ldquo;mixed&rdquo; task list:</p>
<ul>
<li><input disabled type=checkbox> writing</li>
<li>?</li>
<li><input disabled type=checkbox> more writing probably</li>
</ul>
<p>And a nested list:</p>
<ul>
<li>EEG file extensions
<ul>
<li>.eeg, .vhdr, .vmrk</li>
<li>.edf</li>
<li>.bdf</li>
<li>.set, .fdt</li>
<li>.smr</li>
</ul>
</li>
<li>MEG file extensions
<ul>
<li>.ds</li>
<li>.fif</li>
<li>.sqd</li>
<li>.raw</li>
<li>.kdf</li>
</ul>
</li>
</ul>
<h2 id=thanks>Thanks</h2>
<p>Thanks so much for taking the time to contribute your workflow to the Neurodesk community! If you have any feedback on the process, please let us know on <a href=https://github.com/NeuroDesk/neurodesk.github.io/discussions>github discussions</a>.</p>
</div>
</main>
</div>
</div>
<footer class="bg-dark py-5 row d-print-none">
<div class="container-fluid mx-sm-5">
<div class=row>
<div class="col-6 col-sm-4 text-xs-center order-sm-2">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title aria-label>
<a class=text-white target=_blank rel=noopener href aria-label>
<i></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter>
<a class=text-white target=_blank rel=noopener href=https://twitter.com/neuro_desk aria-label=Twitter>
<i class="fab fa-twitter"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=RSS aria-label=RSS>
<a class=text-white target=_blank rel=noopener href=https://neurodesk.github.io/blog/index.xml aria-label=RSS>
<i class="fas fa-rss"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title aria-label>
<a class=text-white target=_blank rel=noopener href aria-label>
<i></i>
</a>
</li>
</ul>
</div>
<div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub>
<a class=text-white target=_blank rel=noopener href=https://github.com/NeuroDesk aria-label=GitHub>
<i class="fab fa-github"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title aria-label>
<a class=text-white target=_blank rel=noopener href aria-label>
<i></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Dicussion Forum (requires github login)" aria-label="Dicussion Forum (requires github login)">
<a class=text-white target=_blank rel=noopener href=https://github.com/NeuroDesk/neurodesk.github.io/discussions aria-label="Dicussion Forum (requires github login)">
<i class="fa fa-envelope"></i>
</a>
</li>
</ul>
</div>
<div class="col-12 col-sm-4 text-center py-2 order-sm-2">
</div>
</div>
</div>
</footer>
</div>
<script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js integrity=sha384-+YQ4JLhjyBLPDQt//I+STsc9iw4uQqACwlvpslubQzn4u2UU2UFM80nGisd026JF crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script>
<script src=/js/main.min.f6e5038a2fe223cb025ddb9e3f0d6e61c17f7ee07173fa91a33f23be1ed1ab52.js integrity="sha256-9uUDii/iI8sCXduePw1uYcF/fuBxc/qRoz8jvh7Rq1I=" crossorigin=anonymous></script>
<script src=/js/prism.js></script>
</body>
</html>