<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.94.0"><meta name=ROBOTS content="INDEX, FOLLOW"><link rel="shortcut icon" href=/neurodesk.github.io/favicons/favicon.ico><link rel=apple-touch-icon href=/neurodesk.github.io/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/neurodesk.github.io/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/neurodesk.github.io/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/neurodesk.github.io/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/neurodesk.github.io/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/neurodesk.github.io/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/neurodesk.github.io/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/neurodesk.github.io/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/neurodesk.github.io/favicons/android-192x192.png sizes=192x192><title>Analysing EEG Data with MNE | NeuroDesk</title><meta name=description content="Use mne-python to load, pre-process, and plot example EEG data in a jupyter notebook through vscode. 
"><meta property="og:title" content="Analysing EEG Data with MNE"><meta property="og:description" content="Use mne-python to load, pre-process, and plot example EEG data in a jupyter notebook through vscode. 
"><meta property="og:type" content="article"><meta property="og:url" content="https://neuro-sevas/neurodesk.github.io/tutorials/electrophysiology/eeg_mne-python/"><meta property="article:section" content="tutorials"><meta property="article:modified_time" content="2022-02-22T19:43:10+10:00"><meta property="og:site_name" content="NeuroDesk"><meta itemprop=name content="Analysing EEG Data with MNE"><meta itemprop=description content="Use mne-python to load, pre-process, and plot example EEG data in a jupyter notebook through vscode. 
"><meta itemprop=dateModified content="2022-02-22T19:43:10+10:00"><meta itemprop=wordCount content="1141"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Analysing EEG Data with MNE"><meta name=twitter:description content="Use mne-python to load, pre-process, and plot example EEG data in a jupyter notebook through vscode. 
"><link rel=preload href=/neurodesk.github.io/scss/main.min.8ae326e95d9c6881ebe419ebd82c6634a8ac6728b2415ccd672d345f03b4cb1b.css as=style><link href=/neurodesk.github.io/scss/main.min.8ae326e95d9c6881ebe419ebd82c6634a8ac6728b2415ccd672d345f03b4cb1b.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script src=https://unpkg.com/lunr@2.3.8/lunr.min.js integrity=sha384-vRQ9bDyE0Wnu+lMfm57BlYLO0/XauFuKpVsZPs7KEDwYKktWi5+Kz3MP8++DFlRY crossorigin=anonymous></script>
<link rel=stylesheet href=/neurodesk.github.io/css/prism.css><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-221108279-1","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body class=td-page><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/neurodesk.github.io/><span class=navbar-logo></span><span class="text-uppercase font-weight-bold">NeuroDesk</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/neurodesk.github.io/docs/how-to-cite-us/><span>Cite</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/neurodesk.github.io/docs/><span>Documentation</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/neurodesk.github.io/docs/faq/><span>FAQ</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/neurodesk.github.io/applications/><span>Applications</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/neurodesk.github.io/developers/><span>Developers</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/neurodesk.github.io/tutorials/><span class=active>Tutorials</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://github.com/NeuroDesk target=_blank><span>GitHub</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://twitter.com/neuro_desk target=_blank><span>News</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/neurodesk.github.io/offline-search-index.49958059539d8b508473f889b67a882f.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/neurodesk.github.io/offline-search-index.49958059539d8b508473f889b67a882f.json data-offline-search-base-href=/ data-offline-search-max-results=10>
<button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type=button data-toggle=collapse data-target=#td-section-nav aria-controls=td-docs-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="collapse td-sidebar-nav" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-neurodeskgithubiotutorials-li><a href=/neurodesk.github.io/tutorials/ class="align-left pl-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-neurodeskgithubiotutorials><span>Tutorials</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-neurodeskgithubiotutorialselectrophysiology-li><a href=/neurodesk.github.io/tutorials/electrophysiology/ class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id=m-neurodeskgithubiotutorialselectrophysiology><span>Electrophysiology</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialselectrophysiologyfieldtrip-li><a href=/neurodesk.github.io/tutorials/electrophysiology/fieldtrip/ title="Analysing M/EEG Data with FieldTrip" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialselectrophysiologyfieldtrip><span>fieldtrip</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-neurodeskgithubiotutorialselectrophysiologyeeg_mne-python-li><a href=/neurodesk.github.io/tutorials/electrophysiology/eeg_mne-python/ title="Analysing EEG Data with MNE" class="align-left pl-0 active td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialselectrophysiologyeeg_mne-python><span class=td-sidebar-nav-active-item>MNE-Python: EEG</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-neurodeskgithubiotutorialsfunctional_imaging-li><a href=/neurodesk.github.io/tutorials/functional_imaging/ class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id=m-neurodeskgithubiotutorialsfunctional_imaging><span>Functional Imaging</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialsfunctional_imagingfmriprep_cvl-li><a href=/neurodesk.github.io/tutorials/functional_imaging/fmriprep_cvl/ title="Using fmriprep with neurodesk on an HPC" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialsfunctional_imagingfmriprep_cvl><span>fmriprep</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialsfunctional_imagingmriqc_cvl-li><a href=/neurodesk.github.io/tutorials/functional_imaging/mriqc_cvl/ title="Using mriqc with neurodesk on HPC" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialsfunctional_imagingmriqc_cvl><span>mriqc</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialsfunctional_imagingphysio-li><a href=/neurodesk.github.io/tutorials/functional_imaging/physio/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialsfunctional_imagingphysio><span>PhysIO</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialsfunctional_imagingphysio_batch_workflow-li><a href=/neurodesk.github.io/tutorials/functional_imaging/physio_batch_workflow/ title="A batch scripting example for PhysIO toolbox" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialsfunctional_imagingphysio_batch_workflow><span>PhysIO_Batch</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-neurodeskgithubiotutorialsphase_processing-li><a href=/neurodesk.github.io/tutorials/phase_processing/ title="MRI phase Processing" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id=m-neurodeskgithubiotutorialsphase_processing><span>MRI Phase</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialsphase_processingqsm-li><a href=/neurodesk.github.io/tutorials/phase_processing/qsm/ title="Quantitative Susceptibility Mapping" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialsphase_processingqsm><span>QSM</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialsphase_processingswi-li><a href=/neurodesk.github.io/tutorials/phase_processing/swi/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialsphase_processingswi><span>SWI</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialsphase_processingunwrapping-li><a href=/neurodesk.github.io/tutorials/phase_processing/unwrapping/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialsphase_processingunwrapping><span>Unwrapping</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-neurodeskgithubiotutorialsreproducibility-li><a href=/neurodesk.github.io/tutorials/reproducibility/ class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id=m-neurodeskgithubiotutorialsreproducibility><span>Reproducibility</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialsreproducibilitydatalad-run-li><a href=/neurodesk.github.io/tutorials/reproducibility/datalad-run/ title="Reproducible script execution with DataLad" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialsreproducibilitydatalad-run><span>datalad run</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-neurodeskgithubiotutorialsspectroscopy-li><a href=/neurodesk.github.io/tutorials/spectroscopy/ class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id=m-neurodeskgithubiotutorialsspectroscopy><span>Spectroscopy</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialsspectroscopylcmodel-li><a href=/neurodesk.github.io/tutorials/spectroscopy/lcmodel/ title="Spectroscopy with lcmodel" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialsspectroscopylcmodel><span>lcmodel</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-neurodeskgithubiotutorialsstructural_imaging-li><a href=/neurodesk.github.io/tutorials/structural_imaging/ class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id=m-neurodeskgithubiotutorialsstructural_imaging><span>Structural Imaging</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialsstructural_imagingfreesurfer-li><a href=/neurodesk.github.io/tutorials/structural_imaging/freesurfer/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialsstructural_imagingfreesurfer><span>FreeSurfer</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialsstructural_imagingstructuralconnectivity-li><a href=/neurodesk.github.io/tutorials/structural_imaging/structuralconnectivity/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialsstructural_imagingstructuralconnectivity><span>Structural connectivity dMRI</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-neurodeskgithubiotutorialsdocumentation-li><a href=/neurodesk.github.io/tutorials/documentation/ class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id=m-neurodeskgithubiotutorialsdocumentation><span>Documentation</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-neurodeskgithubiotutorialsdocumentationworkflowtemplate-li><a href=/neurodesk.github.io/tutorials/documentation/workflowtemplate/ title="Template for workflow creation" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-neurodeskgithubiotutorialsdocumentationworkflowtemplate><span>Workflow template</span></a></li></ul></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"><a href=https://github.com/NeuroDesk/neurodesk.github.io/edit/hugo-docsy/content/en/tutorials/electrophysiology/EEG_mne-python.md target=_blank><i class="fa fa-edit fa-fw"></i> Edit this page</a>
<a href="https://github.com/NeuroDesk/neurodesk.github.io/new/hugo-docsy/content/en/tutorials/electrophysiology/EEG_mne-python.md?filename=change-me.md&value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A" target=_blank><i class="fa fa-edit fa-fw"></i> Create child page</a>
<a href="https://github.com/NeuroDesk/neurodesk.github.io/issues/new?title=Analysing%20EEG%20Data%20with%20MNE" target=_blank><i class="fab fa-github fa-fw"></i> Create documentation issue</a>
<a href=https://github.com/NeuroDesk/neurodesk.github.io/issues/new target=_blank><i class="fas fa-tasks fa-fw"></i> Create project issue</a>
<a id=print href=https://neuro-sevas/neurodesk.github.io/tutorials/electrophysiology/_print/><i class="fa fa-print fa-fw"></i> Print entire section</a></div><div class=td-toc><nav id=TableOfContents><ul><li><a href=#getting-started>Getting started</a></li><li><a href=#select-mne-python-kernel>Select MNE python kernel</a></li><li><a href=#activate-the-mne-conda-environment-in-the-terminal>Activate the MNE conda environment in the terminal</a></li><li><a href=#download-sample-data>Download sample data</a></li><li><a href=#plotting-settings>Plotting settings</a></li><li><a href=#loading-and-processing-data>Loading and processing data</a></li></ul></nav></div></aside><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><h1>Analysing EEG Data with MNE</h1><div class=lead>Use mne-python to load, pre-process, and plot example EEG data in a jupyter notebook through vscode.</div><header class=article-meta></header><h2 id=getting-started>Getting started</h2><p>To begin, navigate to Neurodesk->Electrophysiology->mne->vscodeGUI 0.23.4 in the menu. This version of vscode has been installed in a software container together with the a conda environment containing MNE-python. Note that if you open any other version of vscode in Neurodesk, you will not be able to access the MNE conda environment.</p><p><img src=/EEG_Tutorial/EEGtut0.png alt=EEGtut0 title=EEGtut0></p><p><img src=/EEG_Tutorial/EEGtut1.png alt=EEGtut1 title=EEGtut1></p><p>Open the folder: “/home/user/Desktop/storage” or a subfolder in which you would like to store this demo. In this folder, create a new file named “EEGDemo.ipynb” or something similar:</p><p><img src=/EEG_Tutorial/EEGtut2.png alt=EEGtut2 title=EEGtut2></p><p>If this is your first time opening a Jupyter notebook on vscode in neurodesktop, you may see the following popup. If so, click “install” to install the vscode extensions for Jupyter.</p><p><img src=/EEG_Tutorial/EEGtut3.png alt=EEGtut3 title=EEGtut3></p><h2 id=select-mne-python-kernel>Select MNE python kernel</h2><p>Next, we need to direct vscode to use the python kernel associated with MNE. In the top right corner of your empty jupyter notebook, click “Select Kernel”:</p><p><img src=/EEG_Tutorial/EEGtut4.png alt=EEGtut4 title=EEGtut4></p><p>Then, select mne-0.23.4 from the dropdown menu, which should look something like this:</p><p><img src=/EEG_Tutorial/EEGtut5.png alt=EEGtut5 title=EEGtut5></p><h2 id=activate-the-mne-conda-environment-in-the-terminal>Activate the MNE conda environment in the terminal</h2><p>Next, we&rsquo;ll activate the same MNE environment in a terminal. From the top menu in vscode, select Terminal->New Terminal, or hit [Ctrl]+[Shift]+[`].</p><p>If this is your first time using vscode in this container, you may have to initialise conda by typing <code>conda init bash</code> in the bash terminal. After initialising bash, you will have to close and then reopen the terminal.</p><p>Once you have initialised conda, you can activate the MNE environment in the terminal:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>conda activate mne-0.23.4
</span></span></code></pre></div><p>You should now see &ldquo;(mne-0.23.4)&rdquo; ahead of the current line in the terminal.</p><h2 id=download-sample-data>Download sample data</h2><p>In the terminal (in which you have activated the MNE environment), input the following code to download some BIDS formatted sample EEG data:</p><blockquote><p>Remember to update the path to the location you are storing this tutorial!</p></blockquote><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>pip install osfclient
</span></span><span style=display:flex><span>osf -p C689U fetch Data_sample.zip /neurodesktop-storage/EEGDEMO/Data_sample.zip
</span></span><span style=display:flex><span>unzip Data_sample.zip 
</span></span></code></pre></div><p>This is a small dataset with only 5 EEG channels from a single participant. The participant is viewing a frequency tagged display and is cued to attend to dots tagged at one frequency or another (6 Hz, 7.5 Hz) for long, 15 s trials. To read more about the dataset, click <a href=https://osf.io/c689u/>here</a></p><h2 id=plotting-settings>Plotting settings</h2><p>To make sure our plots retain their interactivity, set the following line at the top of your notebook:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>%matplotlib qt
</span></span></code></pre></div><p>This will mean your figures pop out as individual, interactive plots that will allow you to explore the data, rather than as static, inline plots. You can switch “qt” to “inline” to switch back to default, inline plotting.</p><h2 id=loading-and-processing-data>Loading and processing data</h2><blockquote><p>NOTE: MNE has many helpful tutorials which delve into data processing and analysis using MNE-python in much further detail. These can be found <a href=https://mne.tools/stable/auto_tutorials/index.html>here</a></p></blockquote><p>Begin by importing the necessary modules and creating a pointer to the data:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Interactive plotting
</span></span><span style=display:flex><span>%matplotlib qt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Import modules
</span></span><span style=display:flex><span>import os
</span></span><span style=display:flex><span>import numpy as np
</span></span><span style=display:flex><span>import mne
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Load data
</span></span><span style=display:flex><span>sample_data_folder = &#39;/neurodesktop-storage/EEGDemo/Data_sample&#39;
</span></span><span style=display:flex><span>sample_data_raw_file = os.path.join(sample_data_folder, &#39;sub-01&#39;, &#39;eeg&#39;,
</span></span><span style=display:flex><span>                                    &#39;sub-01_task-FeatAttnDec_eeg.vhdr&#39;)
</span></span><span style=display:flex><span>raw = mne.io.read_raw_brainvision(sample_data_raw_file , preload=True)
</span></span></code></pre></div><p>the raw.info structure contains information about the dataset:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Display data info
</span></span><span style=display:flex><span>print(raw)
</span></span><span style=display:flex><span>print(raw.info)
</span></span></code></pre></div><p>This data file did not include a montage. Lets create one using standard values for the electrodes we have:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Create montage
</span></span><span style=display:flex><span>montage = {&#39;Iz&#39;:  [0, -110, -40],
</span></span><span style=display:flex><span>            &#39;Oz&#39;: [0, -105, -15],
</span></span><span style=display:flex><span>            &#39;POz&#39;: [0,   -100, 15],
</span></span><span style=display:flex><span>            &#39;O1&#39;: [-40, -106, -15],
</span></span><span style=display:flex><span>            &#39;O2&#39;:  [40, -106, -15],
</span></span><span style=display:flex><span> }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>montageuse = mne.channels.make_dig_montage(ch_pos=montage, lpa=[-82.5, -19.2, -46], nasion=[0, 83.2, -38.3], rpa=[82.2, -19.2, -46]) # based on mne help file on setting 10-20 montage
</span></span></code></pre></div><p>Next, lets visualise the data.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>raw.plot()
</span></span></code></pre></div><p>This should open an interactive window in which you can scroll through the data. See the MNE documentation for help on how to customise this plot.</p><p><img src=/EEG_Tutorial/EEGtut6.png alt=EEGtut6 title=EEGtut6></p><p>If, upon visual inspection, you decide to exclude one of the channels, you can specify this in raw.info[‘bads’] now. For example:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>raw.info[&#39;bads&#39;] = [&#39;POz&#39;]
</span></span></code></pre></div><p>Next, we’ll extract our events. The trigger channel in this file is incorrectly scaled, so we’ll correct that before we extract our events:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Correct trigger scaling
</span></span><span style=display:flex><span>trigchan = raw.copy()
</span></span><span style=display:flex><span>trigchan = trigchan.pick(&#39;TRIG&#39;)
</span></span><span style=display:flex><span>trigchan._data = trigchan._data*1000000
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Extract events
</span></span><span style=display:flex><span>events = mne.find_events(trigchan, stim_channel=&#39;TRIG&#39;, consecutive=True, initial_event=True, verbose=True)
</span></span><span style=display:flex><span>print(&#39;Found %s events, first five:&#39; % len(events))
</span></span><span style=display:flex><span>print(events[:5])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Plot events
</span></span><span style=display:flex><span>mne.viz.plot_events(events, raw.info[&#39;sfreq&#39;], raw.first_samp)
</span></span></code></pre></div><p><img src=/EEG_Tutorial/EEGtut7.png alt=EEGtut7 title=EEGtut7></p><p>Now that we’ve extracted our events, we can extract our EEG channels and do some simple pre-processing:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># select
</span></span><span style=display:flex><span>eeg_data = raw.copy().pick_types(eeg=True, exclude=[&#39;TRIG&#39;])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Set montage
</span></span><span style=display:flex><span>eeg_data.info.set_montage(montageuse)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Interpolate
</span></span><span style=display:flex><span>eeg_data_interp = eeg_data.copy().interpolate_bads(reset_bads=True) 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Filter Data
</span></span><span style=display:flex><span>eeg_data_interp.filter(l_freq=1, h_freq=45, h_trans_bandwidth=0.1)
</span></span></code></pre></div><p>Let’s visualise our data again now that it’s cleaner:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>#plot results again, this time with some events and scaling. 
</span></span><span style=display:flex><span>eeg_data_interp.plot(events=events, duration=10.0, scalings=dict(eeg=0.00005), color=&#39;k&#39;, event_color=&#39;r&#39;)
</span></span></code></pre></div><p><img src=/EEG_Tutorial/EEGtut8.png alt=EEGtut8 title=EEGtut8></p><p>That’s looking good! We can even see hints of the frequency tagging. It’s about time to epoch our data.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Epoch to events of interest
</span></span><span style=display:flex><span>event_id = {&#39;attend 6Hz K&#39;: 23, &#39;attend 7.5Hz K&#39;:  27}  
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Extract 15 s epochs relative to events, baseline correct, linear detrend, and reject 
</span></span><span style=display:flex><span># epochs where eeg amplitude is &gt; 400
</span></span><span style=display:flex><span>epochs = mne.Epochs(eeg_data_interp, events, event_id=event_id, tmin=0,
</span></span><span style=display:flex><span>                    tmax=15, baseline=(0, 0), reject=dict(eeg=0.000400), detrend=1)  
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Drop bad trials
</span></span><span style=display:flex><span>epochs.drop_bad()
</span></span></code></pre></div><p>We can average these epochs to form Event Related Potentials (ERPs):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Average erpochs to form ERPs
</span></span><span style=display:flex><span>attend6 = epochs[&#39;attend 6Hz K&#39;].average()
</span></span><span style=display:flex><span>attend75 = epochs[&#39;attend 7.5Hz K&#39;].average()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Plot ERPs
</span></span><span style=display:flex><span>evokeds = dict(attend6=list(epochs[&#39;attend 6Hz K&#39;].iter_evoked()),
</span></span><span style=display:flex><span>               attend75=list(epochs[&#39;attend 7.5Hz K&#39;].iter_evoked()))
</span></span><span style=display:flex><span>mne.viz.plot_compare_evokeds(evokeds, combine=&#39;mean&#39;)
</span></span></code></pre></div><p><img src=/EEG_Tutorial/EEGtut9.png alt=EEGtut9 title=EEGtut9></p><p>In this plot, we can see that the data are frequency tagged. While these data were collected, the participant was performing an attention task in which two visual stimuli were flickering at 6 Hz and 7.5 Hz respectively. On each trial the participant was cued to monitor one of these two stimuli for brief bursts of motion. From previous research, we expect that the steady-state visual evoked potential (SSVEP) should be larger at the attended frequency than the unattended frequency. Lets check if this is true.</p><p>We&rsquo;ll begin by exporting our epoched EEG data to a numpy array</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Preallocate
</span></span><span style=display:flex><span>n_samples = attend6.data.shape[1]
</span></span><span style=display:flex><span>sampling_freq = 1200 # sampling frequency
</span></span><span style=display:flex><span>epochs_np = np.empty((n_samples, 2) )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Get data - averaging across EEG channels
</span></span><span style=display:flex><span>epochs_np[:,0] = attend6.data.mean(axis=0)
</span></span><span style=display:flex><span>epochs_np[:,1] = attend75.data.mean(axis=0)
</span></span></code></pre></div><p>Next, we can use a Fast Fourier Transform (FFT) to transform the data from the time domain to the frequency domain. For this, we&rsquo;ll need to import the FFT packages from scipy:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>from scipy.fft import fft, fftfreq, fftshift
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Get FFT
</span></span><span style=display:flex><span>fftdat = np.abs(fft(epochs_np, axis=0)) / n_samples
</span></span><span style=display:flex><span>freq = fftfreq(n_samples, d=1 / sampling_freq)  # get frequency bins
</span></span></code></pre></div><p>Now that we have our frequency transformed data, we can plot our two conditions to assess whether attention altered the SSVEP amplitudes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>import matplotlib.pyplot as plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig,ax = plt.subplots(1, 1)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax.plot(freq, fftdat[:,0], &#39;-&#39;, label=&#39;attend 6Hz&#39;, color=[78 / 255, 185 / 255, 159 / 255])  
</span></span><span style=display:flex><span>ax.plot(freq, fftdat[:,1], &#39;-&#39;, label=&#39;attend 7.5Hz&#39;, color=[236 / 255, 85 / 255, 58 / 255])  
</span></span><span style=display:flex><span>ax.set_xlim(4, 17)
</span></span><span style=display:flex><span>ax.set_ylim(0, 1e-6)
</span></span><span style=display:flex><span>ax.set_title(&#39;Frequency Spectrum&#39;)
</span></span><span style=display:flex><span>ax.legend()
</span></span></code></pre></div><p><img src=/EEG_Tutorial/EEGtut10.PNG alt=EEGtut10 title=EEGtut10></p><p>This plot shows that the SSVEPs were indeed modulated by attention in the direction we would expect! Congratulations! You’ve run your first analysis of EEG data in neurodesktop.</p><div class="text-muted mt-5 pt-3 border-top">Last modified
February 22, 2022
: <a href=https://github.com/NeuroDesk/neurodesk.github.io/commit/7802c1f8c1e90c3cde6ea85a44c5a5c9abb7373d>fixed all storage links to be backwards compatible with older neurodesk versions (7802c1f8)</a></div></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title aria-label><a class=text-white target=_blank rel=noopener href aria-label><i></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank rel=noopener href=https://twitter.com/neuro_desk aria-label=Twitter><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title aria-label><a class=text-white target=_blank rel=noopener href aria-label><i></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/NeuroDesk aria-label=GitHub><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title aria-label><a class=text-white target=_blank rel=noopener href aria-label><i></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Dicussion Forum (requires github login)" aria-label="Dicussion Forum (requires github login)"><a class=text-white target=_blank rel=noopener href=https://github.com/NeuroDesk/neurodesk.github.io/discussions aria-label="Dicussion Forum (requires github login)"><i class="fa fa-envelope"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"></div></div></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js integrity=sha384-+YQ4JLhjyBLPDQt//I+STsc9iw4uQqACwlvpslubQzn4u2UU2UFM80nGisd026JF crossorigin=anonymous></script>
<script src=/neurodesk.github.io/js/tabpane-persist.js></script>
<script src=/neurodesk.github.io/js/main.min.2b242016bd393aa86ff3b4500b2baae3b55d65f622435861b9338518eb4a5f69.js integrity="sha256-KyQgFr05Oqhv87RQCyuq47VdZfYiQ1hhuTOFGOtKX2k=" crossorigin=anonymous></script>
<script src=/neurodesk.github.io/js/prism.js></script></body></html>