












































































[{"body":"Citing tools We recommend to cite the tool you are using with the version number and the builddate, because this guarantees full reproducibility. You can find this information here: https://www.neurodesk.org/applications/. It’s also very important to cite the paper of the tool you are using and you find this information in the README.m of each tool.\nCiting Neurodesk Finally you can cite Neurodesk with its version and a link to our website.\nCiting AEDAPT If you used any EEG/MEG or electrophysiology tools, please link to the AEDAPT website: https://www.aedapt.net/\nExamples “TGV QSM (v1.0.0_20210629, Langkammer, C; Bredies, K; Poser, BA; Barth, M; Reishofer, G; Fan, AP; Bilgic, B; Fazekas, F; Mainero; C; Ropele, S. Fast Quantitative Susceptibility Mapping using 3D EPI and Total Generalized Variation. Neuroimage. 2015 May 1;111:622-30. doi: 10.1016/j.neuroimage.2015.02.041) was run in Neurodesk (v20220302, https://www.neurodesk.org/ ).”\n“EEGlab (2020.0_20211026, Delorme A \u0026 Makeig S (2004) EEGLAB: an open-source toolbox for analysis of single-trial EEG dynamics, Journal of Neuroscience Methods 134:9-21.) was run in Neurodesk (v20220302, https://www.neurodesk.org/) part of the AEDAPT project https://www.aedapt.net/.”\n","categories":"","description":"How should I cite the tools I am using and Neurodesk itself?\n","excerpt":"How should I cite the tools I am using and Neurodesk itself?\n","ref":"/neurodesk.github.io/docs/how-to-cite-us/","tags":"","title":"How to cite us"},{"body":"If you contributed to the project please list yourself here with a description of your contribution. We try to update this page based on the git commit history:\n https://github.com/NeuroDesk/neurodesktop/graphs/contributors https://github.com/NeuroDesk/neurocommand/graphs/contributors https://github.com/NeuroDesk/neurocontainers/graphs/contributors https://github.com/NeuroDesk/neurodesk.github.io/graphs/contributors https://github.com/NeuroDesk/transparent-singularity/graphs/contributors  Steffen Bollmann  https://github.com/stebo85 funding: Oracle Cloud (114k AUD), ECR Knowledge Exchange \u0026 Translation Fund (42k AUD), ARDC (CI for $566k AUD) system architecture CVMFS container deployment initial desktop container prototype container build scripts application containers (afni, aslprep, code, convert3D, freesurfer, hdbet, minc mriqc, romeo, spm12, tgvqsm, bart, fatsegnet, fsl, itksnap, lcmodel, mritools, niistat, qsmxt, root, slicer, trackvis, ants, cat12, conn, diffusiontoolkit, gimp, mricrogl, mrtrix3, rstudio, slicersalt, surfice, vesselapp, bidstools, clearswi, connectomeworkbench, dsistudio, fmriprep, julia, mrtrix3tissue, palm rabies, spinalcordtoolbox) migrating container recipes and bugfixes to neurodocker upstream (fsl, ants) documentation tutorials (QSM, SWI, Unwrapping, lcmodel, freesurfer) google colab support outreach (e.g. Twitter, talks at conferences, youtube videos)  Aswin Narayanan  https://github.com/aswinnarayanan funding: ARDC (CI for $566k AUD) Neurocontainer devops Neurodesktop development Neurocommand installer rewrite Neurodesk Play \u0026 Kubernetes implementation Jupyter notebook support Hugo website build and documentation  Angela Renton  https://github.com/air2310 Tutorials (MNE-Python, Tutorial template) graphics for website (layer diagram) documentation user testing neurodesk paper lead author  Thomas Shaw  https://github.com/thomshaw92 Win, Mac, Linux startup scripts initial transparent singularity prototype application container development (LASHiS, ASHS) user testing  Oren Civier  https://github.com/civier funding: ARDC (CI for $566k AUD) documentation softare application containers (bidscoin) user testing  Tom Johnston  https://github.com/TomEmotion funding: ARDC (PI for $566k AUD) Application Container (sigviewer)  Martin Grignard  https://github.com/MartinGrignard initial neurocommand prototype and menu system builder, including apps.json idea  David White  https://github.com/DavidjWhite33 application container development (Brainstorm, eeglab, fieldtrip)  Akshaiy Narayanan  https://github.com/Akshaiy91 bugfixes in neurodesktop, added tool for diskusage, checking of new version script  Kelly Garner  https://github.com/kel-github tutorials (fmriprep, mriqc, physio batch) user testing on MacOS  Paris Lyons  design of Neurodesk Logo project management of AEDAPT project  Thuy Dao  https://github.com/iishiishii Application search tool with lunr proof of concept for GUI application container development (civet) documentation (github workflow)  Ashley Stewart  https://github.com/astewartau application container development (qsmxt) presentation of neurodesk at OHBM Brainhack 2022 and OHBM educational course 2022  Lars Kasper  https://github.com/mrikasper tutorials (physio) Application Container (physio)  Judy D Zhu  https://github.com/JD-Zhu application containers (fieldtrip) tutorials (fieldtrip)  Korbinian Eckstein  https://github.com/korbinian90 documentation application container development (qsmxt)  Stefanie Evas  https://github.com/neuro-sevas documentation application containers  Jeryn Chang  https://github.com/Cadaei-Yuvxvs application container development (oshyx)  Sin Kim  https://github.com/AKSoo tutorial (datalad)  Jakub Kaczmarzyk  https://github.com/kaczmarj proof of concept contributions  Alan Hockings  https://github.com/ahockings application container development (mricron)  Aditya Garg  https://github.com/adityagarg011 application container development (hdbet)  Xincheng Ye  https://github.com/yexincheng application container development (delphi)  Kexin Lou  https://github.com/Kaxnn application container development (mne/torch,esilpd)  Renzo Huber  https://github.com/layerfMRI application container development (laynii)  Steering Committee members without code contributions:  Ryan Sullivan, University of Sydney, Key User, Steering Committee Thomas Close, University of Sydney, Key User, Scientific/Subject Expert Advisory Board Wojtek Goscinski, Monash University, Steering Committee, Technical Advisory Board Tony Hannan, Florey Institute of Neuroscience and Mental Health, Scientific/Subject Expert Advisory Board Gary Egan, Monash University, Steering Committee Paul Sowman, Macquarie University, Key User, Scientific/Subject Expert Advisory Board Marta Garrido, University of Melbourne, Key User, Scientific/Subject Expert Advisory Board Patrick Johnston, Queensland University of Technology, Key User, Scientific/Subject Expert Advisory Board Aina Puce, Indiana University, Key User, Scientific/Subject Expert Advisory Board Franco Pestilli, Indiana University, Technical Advisory Board Levin Kuhlmann, Monash University, Key User, Scientific/Subject Expert Advisory Board Gershon Spitz, Monash Epworth Rehabilitation Research Centre, Key User, Scientific/Subject Expert Advisory Board David Abbott, Florey Institute of Neuroscience and Mental Health, Key User, Scientific/Subject Expert Advisory Board Megan Campbell, The University of Newcastle, Key User, Scientific/Subject Expert Advisory Board Nigel Rogasch, University of Adelaide, Key User, Scientific/Subject Expert Advisory Board Will Woods, Swinburne University of Technology, Key User Satrajit Ghosh, Massachusetts Institute of Technology, Provision of advice only  ","categories":"","description":"This section acknowledges the contributions made to the project.\n","excerpt":"This section acknowledges the contributions made to the project.\n","ref":"/neurodesk.github.io/developers/contributors/","tags":"","title":"Contributors"},{"body":" This tutorial was created by Sin Kim.\nGithub: @AKSoo\nTwitter: @SinKim98\n In addition to being a convenient method of sharing data, DataLad can also help you create reproducible analyses by recording how certain result files were produced (i.e. provenance). This helps others (and you!) easily keep track of analyses and rerun them.\nThis tutorial will assume you know the basics of navigating the terminal. If you are not familiar with the terminal at all, check the DataLad Handbook’s brief guide.\nCreate a DataLad project A DataLad dataset can be any collection of files in folders, so it could be many things including an analysis project. Let’s go to the Neurodesktop storage and create a dataset for some project. Open a terminal and enter these commands:\n$ cd /storage  $ datalad create -c yoda SomeProject [INFO ] Creating a new annex repo at /home/user/Desktop/storage/SomeProject [INFO ] Running procedure cfg_yoda [INFO ] == Command start (output follows) ===== [INFO ] == Command exit (modification check follows) ===== create(ok): /home/user/Desktop/storage/SomeProject (dataset)  yoda? -c yoda option configures the dataset according to the YODA, a set of intuitive organizational principles for data analyses that works especially well with version control.  Go in the dataset and check its contents.\n$ cd SomeProject  $ ls CHANGELOG.md README.md code Create a script One of DataLad’s strengths is that it assumes very little about your datasets. Thus, it can work with any other software on the terminal: Python, R, MATLAB, AFNI, FSL, FreeSurfer, etc. For this tutorial, we will run the simplest Julia script.\n$ ml julia  $ cat \u003e code/hello.jl \u003c\u003c EOF println(\"hello neurodesktop\") EOF  EOF? For sake of demonstration, we create the script using built-in Bash terminal commands only (here document that starts after \u003c\u003c EOF and ends when you enter EOF), but you may use whatever text editor you are most comfortable with to create the code/hello.jl file.  You may want to test (parts of) your script.\n$ julia code/hello.jl \u003e hello.txt  $ cat hello.txt hello neurodesktop Run and record Before you run your analyses, you should check the dataset for changes and save or clean them.\n$ datalad status untracked: /home/user/Desktop/storage/SomeProject/code/hello.jl (file) untracked: /home/user/Desktop/storage/SomeProject/hello.txt (file)  $ datalad save -m 'hello script' code/ add(ok): code/hello.jl (file) save(ok): . (dataset) action summary:  add (ok: 1)  save (ok: 1)  $ git clean -i Would remove the following item:  hello.txt *** Commands ***  1: clean 2: filter by pattern 3: select by numbers 4: ask each 5: quit 6: help What now\u003e 1 Removing hello.txt  git git clean is for removing new, untracked files. For resetting existing, modified files to the last saved version, you would need git reset --hard.  When the dataset is clean, we are ready to datalad run!\n$ mkdir outputs  $ datalad run -m 'run hello' -o 'outputs/hello.txt' 'julia code/hello.jl \u003e outputs/hello.txt' [INFO ] == Command start (output follows) ===== [INFO ] == Command exit (modification check follows) ===== add(ok): outputs/hello.txt (file) save(ok): . (dataset) Let’s go over each of the arguments:\n -m 'run hello': Human-readable message to record in the dataset log. -o 'outputs/hello.txt': Expected output of the script. You can specify multiple -o arguments and/or use wildcards like 'outputs/*'. This script has no inputs, but you can similarly specify inputs with -i. 'julia ... ': The final argument is the command that DataLad will run.  Before getting to the exciting part, let’s do a quick sanity check.\n$ cat outputs/hello.txt hello neurodesktop View history and rerun So what’s so good about the extra hassle of running scripts with datalad run? To see that, you will need to pretend you are someone else (or you of future!) and install the dataset somewhere else. Note that -s argument is probably a URL if you were really someone else.\n$ cd ~  $ datalad install -s /neurodesktop-storage/SomeProject install(ok): /home/user/SomeProject (dataset)  $ cd SomeProject Because a DataLad dataset is a Git repository, people who download your dataset can see exactly how outputs/hello.txt was created using Git’s logs.\n$ git log outputs/hello.txt commit 52cff839596ff6e33aadf925d15ab26a607317de (HEAD -\u003e master, origin/master, origin/HEAD) Author: Neurodesk User \u003cuser@neurodesk.github.io\u003e Date: Thu Dec 9 08:31:15 2021 +0000   [DATALAD RUNCMD] run hello   === Do not change lines below ===  {  \"chain\": [],  \"cmd\": \"julia code/hello.jl \u003e outputs/hello.txt\",  \"dsid\": \"1e82813d-856f-4118-b54d-c3823e025709\",  \"exit\": 0,  \"extra_inputs\": [],  \"inputs\": [],  \"outputs\": [  \"outputs/hello.txt\"  ],  \"pwd\": \".\"  }  ^^^ Do not change lines above ^^^ Then, using that information, they can re-run the command that created the file using datalad rerun!\n$ datalad rerun 52cf [INFO ] run commit 52cff83; (run hello) run.remove(ok): outputs/hello.txt (file) [Removed file] [INFO ] == Command start (output follows) ===== [INFO ] == Command exit (modification check follows) ===== add(ok): outputs/hello.txt (file) action summary:  add (ok: 1)  run.remove (ok: 1)  save (notneeded: 1)  git In Git, each commit (save state) is assigned a long, unique machine-generated ID. 52cf refers to the commit with ID that starts with those characters. Usually 4 is the minimum needed to uniquely identify a commit. Of course, this ID is probably different for you, so change this argument to match your commit.  See Also  To learn more basics and advanced applications of DataLad, check out the DataLad Handbook. DataLad is built on top of the popular version control tool Git. There are many great resources on Git online, like this free book. DataLad is only available on the terminal. For a detailed introduction on the Bash terminal, check the BashGuide. For even more reproducibility, you can include containers with your dataset to run analyses in. DataLad has an extension to support script execution in containers. See here.  ","categories":"","description":"Using datalad run, you can precisely record results of your analysis scripts.\n","excerpt":"Using datalad run, you can precisely record results of your analysis …","ref":"/neurodesk.github.io/tutorials/reproducibility/datalad-run/","tags":["datalad"],"title":"Reproducible script execution with DataLad"},{"body":"Overview For an overview of the Neurodesk platform, go to: Overview\nQuick Start To install the Neurodesktop container, go to: Getting Started\nFeedback \u0026 Inquiries To ask questions or suggest new features, join the discussion on github. For issues with the Neurodesk platform, please open a new issue.\nAcknowledgments -- Funding Thank you to Oracle for Research for providing Oracle Cloud credits and related resources to support this project.\nThis project is supported by an Australian Research Data Commons (ARDC) Platform project “Australian Electrophysiology Data Analytics PlaTform (AEDAPT)”.\nLicense MIT License\nCopyright (c) 2021 NeuroDesk\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n","categories":"","description":"A flexible, scalable and easy to use data analysis environment for reproducible neuroimaging.\n","excerpt":"A flexible, scalable and easy to use data analysis environment for …","ref":"/neurodesk.github.io/docs/","tags":"","title":"Documentation"},{"body":"What is Neurodesk? Neurodesk provides a containerised data analysis environment to facilitate reproducible analysis of neuroimaging data. Analysis pipelines for neuroimaging data typically rely on specific versions of packages and software, and are dependent on their native operating system. These dependencies mean that a working analysis pipeline may fail or produce different results on a new computer, or even on the same computer after a software update. Neurodesk provides a platform in which anyone, anywhere, using any computer can reproduce your original research findings given the original data and analysis code.\nMore information:\n A Neurodesk Overview A 2 minute video explaining what Neurodesk is: Neurodesk in 2 minutes An online interactive demo you can try RIGHT NOW in your browser: https://neurodesk.github.io/docs/neurodesktop/getting-started/play/  In-depth information:\n A 15 minute video explaining what Neurodesk is: Neurodesk in 15 minutes A 35 minute video explaining the technical details of Neurodesk: Neurodesk in 35 minutes - behind the scenes  How should I cite the tools I am using and Neurodesk itself? See here\nCan I run Neurodesk on an HPC without Docker? Yes, our project aims to run on the hardware you have access to. However, without docker support you cannot use our desktop interface NeuroDesktop but you can still use the command line interface NeuroCommand on HPC. This works well for batch processing on HPCs once you developed your pipeline in our desktop interface. If your HPC provides a desktop interface you can use all our graphical applications without any issues and the GUIs even work via SSH x-forwarding - it’s not the most performant experience, but it works well enough.\nIs there reduced performance when using containers? If you are running containers on Linux there is no performance penalty - on an HPC with a Lustre filesystem it can even be faster to run our containers than running natively on the filesystem (because meta data operations are shifted to the compute node - more information can be found here: Rioux, Pierre, Gregory Kiar, Alexandre Hutton, Alan C. Evans, and Shawn T. Brown. ‘Deploying Large Fixed File Datasets with SquashFS and Singularity’. ArXiv:2002.06129 [Cs], 14 February 2020. http://arxiv.org/abs/2002.06129.). However, running Neurodesktop on Windows and Mac will have a performance penalty, because Linux runs in a Hypervisor on these systems.\nHow can I see how much resources Neurodesk containers need? In Linux the containers run as normal processes and you can use htop and top to inspect the resource footprint. For Windows and Mac the information is not readily available and we wrote some information here: Troubleshooting\nHow do I get my files in there? It depends where you are running Neurodesk and where your files are. We provide many different ways from drag-and-drop, to cloud storage to file mounts. An overview about Storage can be found here: Storage in Neurodesk\nWhat applications are included in Neurodesk? We provide certain applications as part of the Neurodesktop image (https://www.neurodesk.org/docs/neurodesktop/whatsinthebox/) - these are applications that don’t work well in containers. The majority of applications are provided via containers and a full list can be found here: https://www.neurodesk.org/applications/\nFreeview 7.2.0 crashes when I open files Freeview (and Freesurfer!) needs a valid license to work and we are not allowed to distribute a license with Neurodesk!\nSo here is how you can run freeview 7.2.0 and open your files:\n apply for a license (https://surfer.nmr.mgh.harvard.edu/registration.html) and paste this license in ~/.license  then run\necho \"export FS_LICENSE=~/.license\" \u003e\u003e ~/.bashrc then start freeview 7.2.0 and it should all work perfectly. Can I just use the plain containers? Yes, there are multiple ways of using the containers directly and we provide an overview here: https://www.neurodesk.org/docs/neurocontainers/\nHow can I contribute new containers? We are still working on making this easier, but the current workflow to add new applications is described here: https://www.neurodesk.org/developers/new_tools/add_tool/\nI couldn’t find the information I was looking for. Where can I get additional assistance? Open a Github account, and post your question on the Neurodesk forum: https://github.com/NeuroDesk/neurodesk.github.io/discussions\n","categories":"","description":"Frequently Asked Questions.\n","excerpt":"Frequently Asked Questions.\n","ref":"/neurodesk.github.io/docs/faq/","tags":"","title":"Neurodesk FAQ"},{"body":" This tutorial was created by Judy D Zhu.\nEmail: judyzhud@gmail.com\nGithub: @JD-Zhu\nTwitter: @JudyDZhu\n  Please note that this container uses a compiled version of FieldTrip to run scripts (without needing a Matlab license). Code development is not currently supported within the container and needs to be carried out separatedly in Matlab.\n\nGetting started  Navigate to Neurodesk-\u003eElectrophysiology-\u003efieldtrip-\u003efieldtrip20211114 in the menu:  Once this window is loaded, you are ready to go:\n Type the following into the command window (replacing “yourscript.m” with the name of your custom script - note that you may also need to supply the full path):  run_fieldtrip.sh /opt/MCR/v99 yourscript.m For example, here we ran a script to browse some raw data:\nThe fieldtrip GUI is displayed automatically and functions as it normally would when running inside Matlab.\nNOTES:\n The script specified in the command line can call other scripts The script and the scripts it calls can use all the MATLAB toolboxes included in the compiled version of FieldTrip. If additional MATLAB toolboxes are needed, they need to be put in a filesystem accessible to the FieldTrip container (/neurodesktop-storage, /home/user, etc.), and the path should be added to the MATLAB search path with the addpath function (https://www.mathworks.com/help/matlab/ref/addpath.html)  ","categories":"","description":"A brief guide to using FieldTrip to analyse electrophysiological data within neurodesk.\n","excerpt":"A brief guide to using FieldTrip to analyse electrophysiological data …","ref":"/neurodesk.github.io/tutorials/electrophysiology/fieldtrip/","tags":["fieldtrip","documentation"],"title":"Analysing M/EEG Data with FieldTrip"},{"body":" This tutorial was created by Kelly G. Garner.\nGithub: @kel_github\nTwitter: @garnertheory\n  This workflow documents how to use fmriprep with neurodesk and provides some details that may help you troubleshoot some common problems I found along the way.\n  Assumptions  Your data is already in BIDS format You plan to run fmriprep using Neurodesk You have a local copy of the freesurfer license file (freesurfer.txt)   Steps Open fmriprep From the applications go Neurodesk -\u003e Functional Imaging -\u003e fmriprep and select the latest version of fmriprep. This should take you to a terminal window with fmriprep loaded.\nSetting up fmriprep command If you like, you can enter the following fmriprep command straight into the command line in the newly opened terminal. However, as with increasing options and preferences the command can get rather verbose, I instead opted to create an executable bash script that I can run straight from the command line, with minimal editing inbetween runs. If you’re not interested in this option you can skip straight to copying/adjusting the code from fmriprep to -v below.\n open a new file in your editor of choice but really you know it should be Visual Studio Code save that file with your chosen name without an extension, e.g. run_fmriprep paste in the following and update with your details  #!/bin/bash # # written by A. Name - the purpose of this code is to run fmriprep with neurodesk  export ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS=6 # specify the number of threads you want to use  fmriprep /path/to/your/data \\ # this is the top level of your data folder  /path/to/your/data/derivatives \\ # where you want fmriprep output to be saved  participant \\ # this tells fmriprep to analyse at the participant level  --fs-license-file /path/to/your/freesurfer.txt \\ # where the freesurfer license file is  --output-spaces T1w MNI152NLin2009cAsym fsaverage fsnative \\   --participant-label 01 \\ # put what ever participant labels you want to analyse  --nprocs 6 --mem 10000 \\ # fmriprep can be greedy on the hpc, make sure it is not  --skip_bids_validation \\ # its normally fine to skip this but do make sure your data are BIDS enough  -v # be verbal fmriprep, tell me what you are doing To make the file executable, navigate to this file via the command line in terminal and type\nchmod u+x run_fmriprep # this tells the system to make your new file executable Then to run your new executable, return to your terminal window for fmriprep (that opened when you navigated to fmriprep) and type:\n./run_fmriprep fmriprep should now be merrily working away on your data :)\n Some common pitfalls I have learned from my mistakes (and sometimes from others)   If fmriprep hangs it could well be that you are out of disk space. Sometimes this is because fmriprep created a work directory in your home folder which is often limited on the HPC. Make sure fmriprep knows to use a work drectory in your scratch. you can specify this in the fmriprep command by using -w /path/to/the/work/directory/you/made\n  I learned this from TomCat (@thomshaw92) - fmriprep can get confused between subjects when run in parallel. Parallelise with caution.\n  If running on a HPC, make sure to set the processor and memory limits, if not your job will get killed because it hogs all the resources.\n  ","categories":"","description":"A brief guide to using fmriprep with neurodesk, using data from the STRIAVISE project.\n","excerpt":"A brief guide to using fmriprep with neurodesk, using data from the …","ref":"/neurodesk.github.io/tutorials/functional_imaging/fmriprep_cvl/","tags":["fmriprep","documentation","preprocessing"],"title":"Using fmriprep with neurodesk on an HPC"},{"body":" This tutorial was created by Steffen Bollmann.\nGithub: @stebo85 Web: mri.sbollmann.net Twitter: @sbollmann_MRI\n Download demo data Open a terminal and run:\npip install osfclient osf -p bt4ez fetch TOMCAT_DIB/sub-01/ses-01_7T/anat/sub-01_ses-01_7T_T1w_defaced.nii.gz /neurodesktop-storage/sub-01_ses-01_7T_T1w_defaced.nii.gz FreeSurfer License file: Before using Freesurfer you need to request a license here (https://surfer.nmr.mgh.harvard.edu/registration.html) and store it in your homedirectory as ~/.license\nFreeSurfer Example Open FreeSurfer (Neurodesk -\u003e Image Segmentation -\u003e Freesurfer -\u003e Freesurfer 7.1.1)\nSetup FreeSurfer license (for example - replace with your license):\necho \"Steffen.Bollmann@cai.uq.edu.au \u003e 21029 \u003e *Cqyn12sqTCxo \u003e FSxgcvGkNR59Y\" \u003e\u003e ~/.license  export FS_LICENSE=~/.license Setup FreeSurfer:\nmkdir /neurodesktop-storage/freesurfer-output source /opt/freesurfer-7.1.1/SetUpFreeSurfer.sh export SUBJECTS_DIR=/neurodesktop-storage/freesurfer-output Run Recon all pipeline:\nrecon-all -subject test-subject -i /neurodesktop-storage/sub-01_ses-01_7T_T1w_defaced.nii.gz -all ","categories":"","description":"Example workflow for FreeSurfer\n","excerpt":"Example workflow for FreeSurfer\n","ref":"/neurodesk.github.io/tutorials/structural_imaging/freesurfer/","tags":"","title":"FreeSurfer"},{"body":"Get Neurocontainers code Neurocontainers uses a forked-repo and rebase-oriented workflow. This means that all contributors create a fork of the neurocontainer repository they want to contribute to and then submit pull requests to the upstream repository to have their contributions reviewed and accepted. We also recommend you work on feature branches.\nStep 1a: Create your fork The following steps you’ll only need to do the first time you set up a machine for contributing to Neurocontainers. You’ll need to repeat the steps for any additional NeuroDesk projects (list) that you work on.\nThe first thing you’ll want to do to contribute to NeuroDesk is fork (see how) the appropriate NeuroDesk repository.\nStep 1b: Clone to your machine Next, clone your fork to your local machine:\n$ git clone --config pull.rebase https://github.com/YOUR_USERNAME/neurocontainers.git Cloning into 'neurocontainers'... remote: Enumerating objects: 6730, done. remote: Counting objects: 100% (504/504), done. remote: Compressing objects: 100% (229/229), done. remote: Total 6730 (delta 308), reused 423 (delta 269), pack-reused 6226 Receiving objects: 100% (6730/6730), 1.67 MiB | 196.00 KiB/s, done. Resolving deltas: 100% (4222/4222), done. (The --config pull.rebase option configures Git so that git pull will behave like git pull --rebase by default. Using git pull --rebase to update your changes to resolve merge conflicts is expected by essentially all of open source projects. You can also set that option after cloning using git config --add pull.rebase true, or just be careful to always run git pull --rebase, never git pull).\nNote: If you receive an error while cloning, you may not have added your ssh key to GitHub.\nStep 1c: Connect your fork to Neurocontainers upstream Next you’ll want to configure an upstream remote repository for your fork of Neurocontainers. This will allow you to sync changes from the main project back into your fork.\nFirst, show the currently configured remote repository:\n$ git remote -v origin git@github.com:YOUR_USERNAME/neurocontainers.git (fetch) origin git@github.com:YOUR_USERNAME/neurocontainers.git (push) Note: If you’ve cloned the repository using Github GUI, you may already have the upstream remote repository configured. For example, when you clone NeuroDesk/neurocontainers with the GitHub desktop client it configures the remote repository neurocontainer and you see the following output from git remote -v:\norigin git@github.com:YOUR_USERNAME/neurocontainer.git (fetch) origin git@github.com:YOUR_USERNAME/neurocontainer.git (push) neurocontainers\thttps://github.com/NeuroDesk/neurocontainers.git (fetch) neurocontainers\thttps://github.com/NeuroDesk/neurocontainers.git (push) If your client hasn’t automatically configured a remote for NeuroDesk/eurocontainers, you’ll need to with:\n$ git remote add -f upstream https://github.com/NeuroDesk/neurocontainers.git Finally, confirm that the new remote repository, upstream, has been configured:\n$ git remote -v origin\thttps://github.com/YOUR_USERNAME/neurocontainers.git (fetch) origin\thttps://github.com/YOUR_USERNAME/neurocontainers.git (push) upstream\thttps://github.com/NeuroDesk/neurocontainers.git (fetch) upstream\thttps://github.com/NeuroDesk/neurocontainers.git (push) Step 2: Set up the Neurocontainers development environment If you haven’t already, now is a good time to install the Neurocontainers development environment (Add tools).\nStep 3: Configure continuous integration for your fork This step is optional, but recommended.\n Go to your neurocontainers fork. If Actions tab is missing, go to Settings \u003e Actions. Select Allow all actions. Then Save. In the actions tab, select “I understand my workflows, go ahead and enable them”  Neurocontainers is configured to use GitHub Actions to test and create builds upon each new commit and pull request. GitHub Actions is the primary CI that runs frontend and backend tests across a wide range of Ubuntu distributions.\nGitHub Actions is free for open source projects and it’s easy to configure for your own fork of neurocontainer. After doing so, GitHub Actions will run tests for new refs you push to GitHub and email you the outcome (you can also view the results in the web interface).\nRunning CI against your fork can help save both your and the NeuroDesk maintainers time by making it easy to test a change fully before submitting a pull request. We generally recommend a workflow where as you make changes, you use a fast edit-refresh cycle running individual tests locally until your changes work. But then once you’ve gotten the tests you’d expect to be relevant to your changes working, push a branch to run the full test suite in GitHub Actions before you create a pull request. While you wait for GitHub Actions jobs to run, you can start working on your next task. When the tests finish, you can create a pull request that you already know passes the tests.\nGitHub Actions will run all the jobs by default on your forked repository. You can check the Actions tab of your repository to see the builds.\n","categories":"","description":"Clone neurocontainer code\n","excerpt":"Clone neurocontainer code\n","ref":"/neurodesk.github.io/developers/new_tools/cloning/","tags":"","title":"Get Neurodesk code"},{"body":"","categories":"","description":"Select your operating system to get started with neurocommand.\n","excerpt":"Select your operating system to get started with neurocommand.\n","ref":"/neurodesk.github.io/docs/neurocommand/getting-started/","tags":"","title":"Getting Started"},{"body":"","categories":"","description":"Select your operating system to get started with neurodesktop.\n","excerpt":"Select your operating system to get started with neurodesktop.\n","ref":"/neurodesk.github.io/docs/neurodesktop/getting-started/","tags":"","title":"Getting Started"},{"body":" This tutorial was created by Steffen Bollmann.\nGithub: @stebo85 Web: mri.sbollmann.net Twitter: @sbollmann_MRI\n Open lcmodel from the menu: Applications -\u003e Spectroscopy -\u003e lcmodel -\u003e lcmodel 6.3\nrun\nsetup_lcmodel.sh then run\nlcmgui We packed example data into the container (https://zenodo.org/record/3904443/) and we will use this to show a basic analysis.\nThe example data comes in the Varian fid format, so click on Varian:\nand then select the fid data in: /opt/datasets/Spectra_hippocampus(rat)_TE02/s_20131015_03_BDL106_scan0/isise_01.fid\nThen Change BASIS and select the appropriate basis set in /opt/datasets/Spectra_hippocampus(rat)_TE02/Control_files_Basis_set\nThen hit Run LCModel:\nand confirm:\nthen wait a couple of minutes until the analyzed spectra appear - by closing the window you can go through the results:\nthe results are also saved in ~/.lcmodel/saved/\n","categories":"","description":"Using lcmodel, you can analyze MR spectroscopy data.\n","excerpt":"Using lcmodel, you can analyze MR spectroscopy data.\n","ref":"/neurodesk.github.io/tutorials/spectroscopy/lcmodel/","tags":["lcmodel"],"title":"Spectroscopy with lcmodel"},{"body":"Ways of using Neurocommand in Linux:  You can use Neurocontainers directly via CVMFS: https://www.neurodesk.org/docs/neurocontainers/cvmfs/ or you can install Neurocommand as described here:  Requirements: Required  python 3.6+ https://docs.conda.io/en/latest/miniconda.html#linux-installers singularity https://sylabs.io/guides/3.5/user-guide/quick_start.html git  Optional  lmod https://lmod.readthedocs.io/en/latest/  command line mode (e.g. running on an HPC or CVL)  Load singularity and for best performance it should be 3.x e.g. module load singularity/3.5.0 Load or install aria2 to optimize the download performance of our containers e.g. module load aria2c Run git clone https://github.com/NeuroDesk/neurocommand.git to clone the repository - make sure to clone this to a directory with enough storage, write permissions and NOT a symbolic link (to be sure run cd `pwd -P`)! Run cd neurocommand to change into the directory Run pip3 install -r neurodesk/requirements.txt --user to install pre-requisite python packages Run bash build.sh --cli to install in cli mode Run bash containers.sh for installing indiviual containers or bash containers.sh --all for installing all containers Run module use $PWD/local/containers/modules/ to add the containers to your module search path. Add this to your .bashrc if working. Run ml avail to see the installed containers at the top of the list (neurodesk containers will take preference over system modules with the same name). - If a container is not yet there run ml --ignore_cache avail  For Lxde desktops If running on an lxde desktop… Run bash build.sh --lxde --edit\nFor Mate desktops Run bash build.sh --init (or bash build.sh --lxde --edit)\nlxde/mate: Mate\ninstalldir: Where all the neurocommand files will be stored (Default: ./local)\nappmenu: The linux menu xml file. (Usually /etc/xdg/menus/****-applications.menu)\nappdir: Location for the .desktop files for this linux desktop (Usually /usr/share/applications)\ndeskdir: Location for the .directory files for this linux desktop (Typically /usr/share/desktop-directories)\nFor desktop menus: sudo bash install.sh to install\nCreates symlinks to menu files in installation dir\nsudo bash uninstall.sh to uninstall\nRemoves symlinks\nTo update Run git pull\nRun bash build.sh\ninstall.sh does not need to be run again\nTo download all containers Run bash containers.sh --all\n","categories":"","description":"Install neurocommand on Linux\n","excerpt":"Install neurocommand on Linux\n","ref":"/neurodesk.github.io/docs/neurocommand/getting-started/linux/","tags":"","title":"Linux"},{"body":"Minimum System Requirements  At least 3GB free space for neurodesktop base image Docker requirements. Details found under https://docs.docker.com/get-docker/  Quickstart 1. Install Docker Install Docker from here: https://docs.docker.com/get-docker/. Additional information available below\n2. Run Neurodesktop Before the first run, create a local folder where the downloaded applications will be stored, e.g. ~/neurodesktop-storage\nThen use one of the following options to run Neurodesktop:\nOption 1: NeuroDesktop.run Download and run the following executable https://github.com/NeuroDesk/neurodesktop/raw/main/Linux_run_Neurodesk/NeuroDesktop.run\nOption 2: Using Terminal  Open a terminal, and type the folowing command to automatically download the neurodesktop container and run it  sudo docker run \\ --shm-size=1gb -it --privileged --name neurodesktop \\ -v ~/neurodesktop-storage:/neurodesktop-storage \\ -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\"\\ -p 8080:8080 \\ -h neurodesktop-20220701 vnmd/neurodesktop:20220701 If you get errors in neurodesktop then check if the ~/neurodesktop-storage directory is writable to all users, otherwise run chmod a+rwx ~/neurodesktop-storage   Once neurodesktop is downloaded i.e. guacd[77]: INFO: Listening on host 127.0.0.1, port 4822 is displayed in terminal, leave the terminal open and neurodesktop running (i.e., do not press CTRL+C)\n  Open a browser and go to:\n  http://localhost:8080/#/?username=user\u0026password=password  If using Chrome, a pop-up may open with the text:\n\"http://localhost:8080 wants to See text and images copied to the clipboard\". You should press “Allow”\n If using Firefox, you might not be able to paste clipboard content into the virtual desktop from the host computer. In that case, please follow the instructions here: https://www.neurodesk.org/docs/neurodesktop/troubleshooting/#the-clipboard-in-firefox-is-not-working-correctly   Press on “Desktop Auto-Resolution” under “ALL CONNECTIONS”\n  If it is the first time you use Neruodesktop, wait until the desktop appears (it may take a few seconds). Otherwise, it should appear instantaneously.\n  Neurodesk is ready to use! Click “What’s next?” on the left of this page for further instructions.\n  For an optimal experience, switch your browser to full-screen mode by following the instructions for your browser here: https://www.thewindowsclub.com/open-chrome-edge-or-firefox-browser-in-full-screen-mode\n  The browser can be closed anytime, and Neurodesktop will continue running in the background. To reconnect to Neurodesktop, simply start over from step 3 above.  Deleting neurodesktop: When done processing your data it is important to stop and remove the container - otherwise the next start or container update will give an error (\"… The container name “/neurodesktop” is already in use…\")\nNote Notice that any data that were saved outside of /neurodesktop-storage would be lost. Please make sure to move all your data to that folder before deleting neurodesktop.    Click on the terminal from which you ran neurodesktop\n  Press Ctrl-C\n  Run:\n  docker stop neurodesktop  Run:  docker rm neurodesktop  Installing Docker For general installation instructions, refer to https://docs.docker.com/get-docker/\nRHEL/CentOS (yum-based) Refer to https://docs.docker.com/engine/install/centos/\nOne example to install docker in a yum-based distribution could look like this:\nsudo dnf install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo dnf install docker-ce docker-ce-cli containerd.io # or if dnf not found: sudo yum install docker-ce docker-ce-cli containerd.io sudo systemctl enable docker sudo systemctl start docker sudo docker version sudo docker info sudo groupadd docker sudo usermod -aG docker $USER sudo chown root:docker /var/run/docker.sock newgrp docker  Ubuntu/Debian (apt-based) Refer to https://docs.docker.com/engine/install/ubuntu/\nOne example to install docker in a apt-based distribution could look like this:\nsudo apt-get update sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list  /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io  GPU support RHEL/CentOS (yum-based) sudo yum install nvidia-container-toolkit -y  Running neurodesktop container with GPU sudo docker run \\ --shm-size=1gb -it --privileged --name neurodesktop \\ -v ~/neurodesktop-storage:/neurodesktop-storage \\ -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\" \\ -e NVIDIA_VISIBLE_DEVICES=all \\ -e NVIDIA_DISABLE_REQUIRE=1 \\ -p 8080:8080 -h neurodesktop-20220701 \\ vnmd/neurodesktop:20220701  Then inside the neurodesktop container run:\n sudo apt update sudo apt install libcudart10.1   For a GPU with Nvidia driver Version \u003e 495.29.05:\n wget https://developer.download.nvidia.com/compute/cuda/11.5.0/local_installers/cuda_11.5.0_495.29.05_linux.run sudo sh ./cuda_11.5.0_495.29.05_linux.run   Running tensorflow (w/ GPU) Using tensorflow (python)  conda install tensorflow-gpu python  \" import tensorflow as tf print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))  Using tensorflow (singularity container in neurodesktop) singularity pull docker://tensorflow/tensorflow:latest-gpu singularity run --nv tensorflow_latest-gpu.sif python  \" import tensorflow as tf print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))  Using an RDP Client Startup Neurodesktop using the following command:\nsudo docker run \\ --shm-size=1gb -it --privileged --name neurodesktop \\ -v ~/neurodesktop-storage:/neurodesktop-storage \\ -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\"\\ -p 8080:8080 -p 3390:3389 \\ -h neurodesktop-20220701 vnmd/neurodesktop:20220701 If you want to connect via RDP using a different port, replace 3390 in the previous and next step with your port  Open your RDP client and connect to Computer localhost:3390\nUse the following details to login if prompted\nusername: user password: password Using VNC To enable VNC and disable RDP, startup Neurodesktop using the following command:\nsudo docker run \\ --shm-size=1gb -it --privileged --name neurodesktop \\ -v ~/neurodesktop-storage:/neurodesktop-storage \\ -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\"\\ -p 8080:8080 \\ -h neurodesktop-20220701 vnmd/neurodesktop:20220701 --vnc To enable both VNC and RDP, startup Neurodesktop using the following command:\nsudo docker run \\ --shm-size=1gb -it --privileged --name neurodesktop \\ -v ~/neurodesktop-storage:/neurodesktop-storage \\ -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\"\\ -p 8080:8080 \\ -h neurodesktop-20220701 vnmd/neurodesktop:20220701 --vnc --rdp VNC allows for multiple desktop connections to same instance\nNote: Neurodesktop VNC on the browser currently does not support auto-resolution\n Using a VNC Client Needs testing  Startup Neurodesktop using the following command:\nsudo docker run \\ --shm-size=1gb -it --privileged --name neurodesktop \\ -v ~/neurodesktop-storage:/neurodesktop-storage \\ -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\"\\ -p 8080:8080 -p 5901:5901 \\ -h neurodesktop-20220701 vnmd/neurodesktop:20220701 --vnc Open a VNC Client and connect to port 5901\n","categories":"","description":"Install neurodesktop on Linux\n","excerpt":"Install neurodesktop on Linux\n","ref":"/neurodesk.github.io/docs/neurodesktop/getting-started/linux/","tags":"","title":"Linux"},{"body":"Local Hugo Docsy in Linux and WSL2 https://github.com/NeuroDesk/neurodesk.github.io/blob/hugo-docsy/CONTRIBUTING.md\nLocal Hugo Docsy in Windows Clone repository Using SSH\ngit clone --recurse-submodules git@github.com:NeuroDesk/neurodesk.github.io.git\nor Https:\ngit clone --recurse-submodules https://github.com/NeuroDesk/neurodesk.github.io.git\nIf you cloned without –recurse-submodules Run the following command to pull submodules\ngit submodule update --init --recursive --remote\nDownload Hugo binary Hugo releases are on https://github.com/gohugoio/hugo/releases\nDownload latest version of hugo extended\ne.g. for windows: https://github.com/gohugoio/hugo/releases/download/v0.88.1/hugo_extended_0.88.1_Windows-64bit.zip\nStart local hugo server Extract hugo binary (hugo.exe) to your neurodesk.github.io dir\nRun server for windows: .\\hugo.exe server --disableFastRender\nOnce started, dev website will be accessible via http://localhost:1313\nUpdate docsy theme submodule git submodule update --remote git add themes/ git commit -m \"Updating theme submodule\" git push origin hugo-docsy ","categories":"","description":"How to edit the documentation\n","excerpt":"How to edit the documentation\n","ref":"/neurodesk.github.io/developers/documentation/local-hugo-docsy/","tags":"","title":"Local Hugo Docsy"},{"body":"Getting started To begin, navigate to Neurodesk-\u003eElectrophysiology-\u003emne-\u003evscodeGUI 0.23.4 in the menu. This version of vscode has been installed in a software container together with the a conda environment containing MNE-python. Note that if you open any other version of vscode in Neurodesk, you will not be able to access the MNE conda environment.\nOpen the folder: “/home/user/Desktop/storage” or a subfolder in which you would like to store this demo. In this folder, create a new file named “EEGDemo.ipynb” or something similar:\nIf this is your first time opening a Jupyter notebook on vscode in neurodesktop, you may see the following popup. If so, click “install” to install the vscode extensions for Jupyter.\nSelect MNE python kernel Next, we need to direct vscode to use the python kernel associated with MNE. In the top right corner of your empty jupyter notebook, click “Select Kernel”:\nThen, select mne-0.23.4 from the dropdown menu, which should look something like this:\nActivate the MNE conda environment in the terminal Next, we’ll activate the same MNE environment in a terminal. From the top menu in vscode, select Terminal-\u003eNew Terminal, or hit [Ctrl]+[Shift]+[`].\nIf this is your first time using vscode in this container, you may have to initialise conda by typing conda init bash in the bash terminal. After initialising bash, you will have to close and then reopen the terminal.\nOnce you have initialised conda, you can activate the MNE environment in the terminal:\nconda activate mne-0.23.4 You should now see “(mne-0.23.4)” ahead of the current line in the terminal.\nDownload sample data In the terminal (in which you have activated the MNE environment), input the following code to download some BIDS formatted sample EEG data:\n Remember to update the path to the location you are storing this tutorial!\n pip install osfclient osf -p C689U fetch Data_sample.zip /neurodesktop-storage/EEGDEMO/Data_sample.zip unzip Data_sample.zip This is a small dataset with only 5 EEG channels from a single participant. The participant is viewing a frequency tagged display and is cued to attend to dots tagged at one frequency or another (6 Hz, 7.5 Hz) for long, 15 s trials. To read more about the dataset, click here\nPlotting settings To make sure our plots retain their interactivity, set the following line at the top of your notebook:\n%matplotlib qt This will mean your figures pop out as individual, interactive plots that will allow you to explore the data, rather than as static, inline plots. You can switch “qt” to “inline” to switch back to default, inline plotting.\nLoading and processing data  NOTE: MNE has many helpful tutorials which delve into data processing and analysis using MNE-python in much further detail. These can be found here\n Begin by importing the necessary modules and creating a pointer to the data:\n# Interactive plotting %matplotlib qt  # Import modules import os import numpy as np import mne  # Load data sample_data_folder = '/neurodesktop-storage/EEGDemo/Data_sample' sample_data_raw_file = os.path.join(sample_data_folder, 'sub-01', 'eeg',  'sub-01_task-FeatAttnDec_eeg.vhdr') raw = mne.io.read_raw_brainvision(sample_data_raw_file , preload=True) the raw.info structure contains information about the dataset:\n# Display data info print(raw) print(raw.info) This data file did not include a montage. Lets create one using standard values for the electrodes we have:\n# Create montage montage = {'Iz': [0, -110, -40],  'Oz': [0, -105, -15],  'POz': [0, -100, 15],  'O1': [-40, -106, -15],  'O2': [40, -106, -15],  }  montageuse = mne.channels.make_dig_montage(ch_pos=montage, lpa=[-82.5, -19.2, -46], nasion=[0, 83.2, -38.3], rpa=[82.2, -19.2, -46]) # based on mne help file on setting 10-20 montage Next, lets visualise the data.\nraw.plot() This should open an interactive window in which you can scroll through the data. See the MNE documentation for help on how to customise this plot.\nIf, upon visual inspection, you decide to exclude one of the channels, you can specify this in raw.info[‘bads’] now. For example:\nraw.info['bads'] = ['POz'] Next, we’ll extract our events. The trigger channel in this file is incorrectly scaled, so we’ll correct that before we extract our events:\n# Correct trigger scaling trigchan = raw.copy() trigchan = trigchan.pick('TRIG') trigchan._data = trigchan._data*1000000  # Extract events events = mne.find_events(trigchan, stim_channel='TRIG', consecutive=True, initial_event=True, verbose=True) print('Found %s events, first five:' % len(events)) print(events[:5])  # Plot events mne.viz.plot_events(events, raw.info['sfreq'], raw.first_samp) Now that we’ve extracted our events, we can extract our EEG channels and do some simple pre-processing:\n# select eeg_data = raw.copy().pick_types(eeg=True, exclude=['TRIG'])  # Set montage eeg_data.info.set_montage(montageuse)  # Interpolate eeg_data_interp = eeg_data.copy().interpolate_bads(reset_bads=True)  # Filter Data eeg_data_interp.filter(l_freq=1, h_freq=45, h_trans_bandwidth=0.1) Let’s visualise our data again now that it’s cleaner:\n#plot results again, this time with some events and scaling. eeg_data_interp.plot(events=events, duration=10.0, scalings=dict(eeg=0.00005), color='k', event_color='r') That’s looking good! We can even see hints of the frequency tagging. It’s about time to epoch our data.\n# Epoch to events of interest event_id = {'attend 6Hz K': 23, 'attend 7.5Hz K': 27}  # Extract 15 s epochs relative to events, baseline correct, linear detrend, and reject # epochs where eeg amplitude is \u003e 400 epochs = mne.Epochs(eeg_data_interp, events, event_id=event_id, tmin=0,  tmax=15, baseline=(0, 0), reject=dict(eeg=0.000400), detrend=1)  # Drop bad trials epochs.drop_bad() We can average these epochs to form Event Related Potentials (ERPs):\n# Average erpochs to form ERPs attend6 = epochs['attend 6Hz K'].average() attend75 = epochs['attend 7.5Hz K'].average()  # Plot ERPs evokeds = dict(attend6=list(epochs['attend 6Hz K'].iter_evoked()),  attend75=list(epochs['attend 7.5Hz K'].iter_evoked())) mne.viz.plot_compare_evokeds(evokeds, combine='mean') In this plot, we can see that the data are frequency tagged. While these data were collected, the participant was performing an attention task in which two visual stimuli were flickering at 6 Hz and 7.5 Hz respectively. On each trial the participant was cued to monitor one of these two stimuli for brief bursts of motion. From previous research, we expect that the steady-state visual evoked potential (SSVEP) should be larger at the attended frequency than the unattended frequency. Lets check if this is true.\nWe’ll begin by exporting our epoched EEG data to a numpy array\n# Preallocate n_samples = attend6.data.shape[1] sampling_freq = 1200 # sampling frequency epochs_np = np.empty((n_samples, 2) )  # Get data - averaging across EEG channels epochs_np[:,0] = attend6.data.mean(axis=0) epochs_np[:,1] = attend75.data.mean(axis=0) Next, we can use a Fast Fourier Transform (FFT) to transform the data from the time domain to the frequency domain. For this, we’ll need to import the FFT packages from scipy:\nfrom scipy.fft import fft, fftfreq, fftshift  # Get FFT fftdat = np.abs(fft(epochs_np, axis=0)) / n_samples freq = fftfreq(n_samples, d=1 / sampling_freq) # get frequency bins Now that we have our frequency transformed data, we can plot our two conditions to assess whether attention altered the SSVEP amplitudes:\nimport matplotlib.pyplot as plt  fig,ax = plt.subplots(1, 1)  ax.plot(freq, fftdat[:,0], '-', label='attend 6Hz', color=[78 / 255, 185 / 255, 159 / 255]) ax.plot(freq, fftdat[:,1], '-', label='attend 7.5Hz', color=[236 / 255, 85 / 255, 58 / 255]) ax.set_xlim(4, 17) ax.set_ylim(0, 1e-6) ax.set_title('Frequency Spectrum') ax.legend() This plot shows that the SSVEPs were indeed modulated by attention in the direction we would expect! Congratulations! You’ve run your first analysis of EEG data in neurodesktop.\n","categories":"","description":"Use mne-python to load, pre-process, and plot example EEG data in a jupyter notebook through vscode. \n","excerpt":"Use mne-python to load, pre-process, and plot example EEG data in a …","ref":"/neurodesk.github.io/tutorials/electrophysiology/eeg_mne-python/","tags":"","title":"Analysing EEG Data with MNE"},{"body":" This tutorial was created by Kelly G. Garner.\nGithub: @kel_github\nTwitter: @garnertheory\n  This workflow documents how to use mriqc with neurodesk and provides some details that may help you troubleshoot some common problems I found along the way.\n  Assumptions  Your data is already in BIDS format You plan to run mriqc using Neurodesk   Steps Open mriqc From the applications go Neurodesk -\u003e Functional Imaging -\u003e mriqc and select the latest version of mriqc. This should take you to a terminal window with mriqc loaded. \n\u003c!– –\u003e\nSetting up mriqc command If you like, you can enter the following mriqc commands straight into the command line in the newly opened terminal. However, as with increasing options and preferences the command can get rather verbose, so I instead opted to create executable bash scripts that I can run straight from the command line, with minimal editing inbetween runs. I made one for running mriqc at the participant level, and one for running at the group level (for the group report, once all the participants are done). If you’re not interested in this option you can skip straight to copying/adjusting the code from mriqc to -v below.\n open a new file in your editor of choice (e.g. Visual Studio Code) save that file with your chosen name without an extension, e.g. run_mriqc_participant or run_mriqc_group paste in the following and update with your details  #!/bin/bash # # written by A. Name - the purpose of this code is to run mriqc with neurodesk  export ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS=6 # specify the number of threads you want to use  mriqc /path/to/your/data \\ # this is the top level of your data folder  /path/to/your/data/derivatives \\ # where you want mriqc output to be saved  participant \\ # this tells mriqc to analyse at the participant level  --participant-label 01 \\ # put what ever participant labels you want to analyse  --work-dir /path/to/work/directory \\ #useful to specify so your home directory definitely doesnt get clogged  --nprocs 6 --mem_gb 10000 \\ # mriqc can be greedy on the hpc, make sure it is not  -v # be verbal mriqc, tell me what you are doing OR: if you have run all the participants and you just want the group level report, use these mriqc commands instead:\nmriqc /path/to/your/data \\ # this is the top level of your data folder  /path/to/your/data/derivatives \\ # where you want mriqc output to be saved. As you are running the group level analysis this folder should be prepopulated with the results of the participant level analysis  group \\ # this tells mriqc to agive you the group report  -w /path/to/work/directory \\ #useful to specify so your home directory definitely doesnt get clogged  --nprocs 6 --mem_gb 10000 \\ # mriqc can be greedy on the hpc, make sure it is not  -v # be verbal mriqc, tell me what you are doing To make either of yours files executable, navigate via the terminal to the same folder in which this file is saved. If you list the files in the folder by using the command ls you should see your file with the name printed in white.\n\u003c!– –\u003e\nNow type the following command:\nchmod u+x run_mriqc_participant # this tells the system to make your new file executable To know this worked, list the files again. If you have successfully made your file executable then it will be listed in green.\n\u003c!– –\u003e\nThen to run your new executable, return to your terminal window for mriqc (that opened when you navigated to mriqc), navigate to the directory where your executable file is stored and type:\n./name_of_your_mriqc_file mriqc should now be merrily working away on your data :)\n Some common pitfalls I have learned from my mistakes (and sometimes from others)  If running on a HPC, make sure to set the processor and memory limits, if not your job will get killed because mriqc hogs all the resources.  ","categories":"","description":"A brief guide to using mriqc with neurodesk, using data from the STRIAVISE project.\n","excerpt":"A brief guide to using mriqc with neurodesk, using data from the …","ref":"/neurodesk.github.io/tutorials/functional_imaging/mriqc_cvl/","tags":["mriqc","documentation","preprocessing"],"title":"Using mriqc with neurodesk on HPC"},{"body":" This tutorial was created by Lars Kasper.\nGithub: @mrikasper\nTwitter: @mrikasper\n Origin The PhysIO Toolbox implements ideas for robust physiological noise modeling in fMRI, outlined in this paper:\n Kasper, L., Bollmann, S., Diaconescu, A.O., Hutton, C., Heinzle, J., Iglesias, S., Hauser, T.U., Sebold, M., Manjaly, Z.-M., Pruessmann, K.P., Stephan, K.E., 2017. The PhysIO Toolbox for Modeling Physiological Noise in fMRI Data. Journal of Neuroscience Methods 276, 56-72. https://doi.org/10.1016/j.jneumeth.2016.10.019  PhysIO is part of the open-source TAPAS Software Package for Translational Neuromodeling and Computational Psychiatry, introduced in the following paper:\nFrässle, S., Aponte, E.A., Bollmann, S., Brodersen, K.H., Do, C.T., Harrison, O.K., Harrison, S.J., Heinzle, J., Iglesias, S., Kasper, L., Lomakina, E.I., Mathys, C., Müller-Schrader, M., Pereira, I., Petzschner, F.H., Raman, S., Schöbi, D., Toussaint, B., Weber, L.A., Yao, Y., Stephan, K.E., 2021. TAPAS: an open-source software package for Translational Neuromodeling and Computational Psychiatry. Frontiers in Psychiatry 12, 857. https://doi.org/10.3389/fpsyt.2021.680811  Please cite these works if you use PhysIO and see the FAQ for details.\nNeuroDesk offers the possibility of running PhysIO without installing Matlab or requiring a Matlab license. The functionality should be equivalent, though debugging and extending the toolbox, as well as unreleased development features, will only be available in the Matlab version of PhysIO, which is exlusively hosted on the TAPAS GitHub.\nMore general info about PhysIO besides NeuroDesk usage is found in the README on GitHub.\nPurpose The general purpose of the PhysIO toolbox is model-based physiological noise correction of fMRI data using peripheral measures of respiration and cardiac pulsation (respiratory bellows, ECG, pulse oximeter/plethysmograph).\nIt incorporates noise models of\n cardiac/respiratory phase (RETROICOR, Glover et al. 2000), as well as heart rate variability and respiratory volume per time (cardiac response function, Chang et. al, 2009, respiratory response function, Birn et al. 2006), and extended motion models (e.g., censoring/scrubbing)  While the toolbox is particularly well integrated with SPM via the Batch Editor GUI, its output text files can be incorporated into any major neuroimaging analysis package for nuisance regression, e.g., within a GLM.\nCore design goals for the toolbox were: flexibility, robustness, and quality assurance to enable physiological noise correction for large-scale and multi-center studies.\nSome highlights:\n Robust automatic preprocessing of peripheral recordings via iterative peak detection, validated in noisy data and patients, and extended processing of respiratory data (Harrison et al., 2021) Flexible support of peripheral data formats (BIDS, Siemens, Philips, GE, BioPac, HCP, …) and noise models (RETROICOR, RVHRCOR). Fully automated noise correction and performance assessment for group studies. Integration in fMRI pre-processing pipelines as SPM Toolbox (Batch Editor GUI).  The accompanying technical paper about the toolbox concept and methodology can be found at: https://doi.org/10.1016/j.jneumeth.2016.10.019\nDownload Example Data The example data should already be present in NeuroDesk in the following folder /opt/spm12\nIf you cannot find the example data there:\n Download the latest version from the location mentioned in the TAPAS distribution  e.g., https://www.tapas.tnu-zurich.com/examples_v5.0.0.zip   Follow the instructions for copying your own data in the next section  Copy your own data  On Windows, the folder C:\\neurodesktop-storage should have been automatically created when starting NeuroDesk This is your direct link to the NeuroDesk environment, and anything you put in there should end up within the NeuroDesk desktop in /neurodesktop-storage/ and on your desktop under storage  Example: Running PhysIO in the GUI  Open the PhysIO GUI (Neurodesk -\u003e Functional Imaging -\u003e physio -\u003e physioGUI r7771, see screenshot:  SPM should automatically open up (might take a while). Select ‘fMRI’ from the modality selection screen. Press the “Batch Editor” button (see screenshot with open Batch Editor, red highlights)  - NB: If you later want to create a new PhysIO batch with all parameters, from scratch or explore the options, select from the Batch Editor Menu top row, SPM -\u003e Tools -\u003e TAPAS PhysIO Toolbox (see screenshot, read highlights)  For now, load an existing example (or previously created SPM Batch File) as follows: It is most convenient to change the working directory of SPM to the location of the physiological logfiles  In the Batch Editor GUI, lowest row, choose ‘CD’ from the ‘Utils..’ dropdown menu Navigate to any of the example folders, e.g., /opt/spm12/examples/Philips/ECG3T/ and select it NB: you can skip this part, if you later manually update all input files in the Batch Editor window (resp/cardiac/scan timing and realignment parameter file further down) Any other example should also work the same way, just CD to its folder before the next step   Select File -\u003e Load Batch from the top row menu of the Batch Editor window  make sure you select the matlab batch file *_spm_job.\u003cm|mat\u003e, (e.g., philips_ecg3t_spm_job.m and philips_ecg3t_spm_job.mat are identical, either is fine), but not the script.   Press The green “Play” button in the top icon menu row of the Batch Editor Window Several output figures should appear, with the last being a grayscale plot of the nuisance regressor design matrix  Congratulations, your first successful physiological noise model has been created! If you don’t see the mentioned figure, chances are certain input files were not found (e.g., wrong file location specified). You can always check the text output in the “bash” window associated with the SPM window for any error messages.  Further Info on PhysIO Please check out the README and FAQ\n","categories":"","description":"Example workflow for the PhysIO Toolbox\n","excerpt":"Example workflow for the PhysIO Toolbox\n","ref":"/neurodesk.github.io/tutorials/functional_imaging/physio/","tags":"","title":"PhysIO"},{"body":" This tutorial was created by Kelly G. Garner.\nGithub: @kel-github\nTwitter: @garner_theory\n This tutorial walks through 1 way to batch script the use of the PhysIO toolbox with Neurodesk. The goal is to use the toolbox to generate physiological regressors to use when modelling fMRI data. The output format of the regressor files are directly compatible for use with SPM, and can be adapted to fit the specifications of other toolboxes. \nGetting started This tutorial assumes the following:\n Your data are (largely) in BIDs format That you have converted your .zip files containing physiological data to .log files. As I was using a CMRR multi-band sequence, I used this function That your .log files are in the subject derivatives/…/sub-…/ses-…/‘func’ folders of aformentioned BIDs structured data That you have a file that contains the motion regressors you plan to use in your GLM. I’ll talk below a bit about what I did with the output given by fmriprep (e.g. …_desc-confounds_timeseries.tsv’) That you can use SPM12 and the PhysIO GUI to initialise your batch code  NB. You can see the code generated from this tutorial here (Coming soon!) \n1. Generate an example script for batching First you will create an example batch script that is specific to one of your participants. To achieve this I downloaded locally the relevant ‘.log’ files for one participant, as well as the ‘…desc-confounds_timeseries.tsv’ output for fmriprep for each run. PhysIO is nice in that it will append the regressors from your physiological data to your movement parameters, so that you have a single file of regressors to add to your design matrix in SPM etc (other toolboxes are available). \nTo work with PhysIO toolbox, your motion parameters need to be in the .txt format as required by SPM.\nI made some simple functions in python that would extract my desired movement regressors and save them to the space separated .txt file as is required by SPM. They can be found here. (Coming soon!)\nOnce I had my .log files and .txt motion regressors file, I followed the instructions here to get going with the Batch editor, and used this paper to aid my understanding of how to complete the fields requested by the Batch editor.\nI wound up with a Batch script for the PhysIO toolbox that looked a little bit like this:\n\u003c!– –\u003e\n2. Generalise the script for use with any participant Now that you have an example script that contains the specific details for a single participant, you are ready to generalise this code so that you can run it for any participant you choose. I decided to do this by doing the following:\n First I generate an ‘info’ structure for each participant. This is a structure saved as a matfile for each participant under ‘derivatives’, in the relevant sub-z/ses-y/func/ folder. This structure contains the subject specific details that PhysIO needs to know to run. Thus I wrote a matlab function that saves a structure called info with the following fields:  % -- outputs: a matfile containing a structure called info with the % following fields: % -- sub_num = subject number: [string] of form '01' '11' or '111' % -- sess = session number: [integer] e.g. 2 % -- nrun = [integer] number of runs for that participant % -- nscans = number of scans (volumes) in the design matrix for each % run [1, nrun] % -- cardiac_files = a cell of the cardiac files for that participant % (1,n = nrun) - attained by using extractCMRRPhysio() % -- respiration_files = same as above but for the resp files - attained by using extractCMRRPhysio() % -- scan_timing = info file from Siemens - attained by using extractCMRRPhysio() % -- movement = a cell of the movement regressor files for that % participant (.txt, formatted for SPM) To directly see the functions that produce this information, you can go to this repo here coming soon!\n Next I amended the batch script to load a given participant’s info file and to retrieve this information for the required fields in the batch. The batch script winds up looking like this:  %% written by K. Garner, 2022 % uses batch info: %----------------------------------------------------------------------- % Job saved on 17-Aug-2021 10:35:05 by cfg_util (rev $Rev: 7345 $) % spm SPM - SPM12 (7771) % cfg_basicio BasicIO - Unknown %----------------------------------------------------------------------- % load participant info, and print into the appropriate batch fields below % before running spm jobman % assumes data is in BIDS format  %% load participant info sub = '01'; dat_path = '/file/path/to/top-level/of-your-derivatives-fmriprep/folder'; task = 'attlearn'; load(fullfile(dat_path, sprintf('sub-%s', sub), 'ses-02', 'func', ...  sprintf('sub-%s_ses-02_task-%s_desc-physioinfo', sub, task)))  % set variables nrun = info.nrun; nscans = info.nscans; cardiac_files = info.cardiac_files; respiration_files = info.respiration_files; scan_timing = info.scan_timing; movement = info.movement;  %% initialise spm spm_jobman('initcfg'); % check this for later spm('defaults', 'FMRI');  %% run through runs, print info and run   for irun = 1:nrun   clear matlabbatch   matlabbatch{1}.spm.tools.physio.save_dir = cellstr(fullfile(dat_path, sprintf('sub-%s', sub), 'ses-02', 'func')); % 1  matlabbatch{1}.spm.tools.physio.log_files.vendor = 'Siemens_Tics';  matlabbatch{1}.spm.tools.physio.log_files.cardiac = cardiac_files(irun); % 2  matlabbatch{1}.spm.tools.physio.log_files.respiration = respiration_files(irun); % 3  matlabbatch{1}.spm.tools.physio.log_files.scan_timing = scan_timing(irun); % 4  matlabbatch{1}.spm.tools.physio.log_files.sampling_interval = [];  matlabbatch{1}.spm.tools.physio.log_files.relative_start_acquisition = 0;  matlabbatch{1}.spm.tools.physio.log_files.align_scan = 'last';  matlabbatch{1}.spm.tools.physio.scan_timing.sqpar.Nslices = 81;  matlabbatch{1}.spm.tools.physio.scan_timing.sqpar.NslicesPerBeat = [];  matlabbatch{1}.spm.tools.physio.scan_timing.sqpar.TR = 1.51;  matlabbatch{1}.spm.tools.physio.scan_timing.sqpar.Ndummies = 0;  matlabbatch{1}.spm.tools.physio.scan_timing.sqpar.Nscans = nscans(irun); % 5  matlabbatch{1}.spm.tools.physio.scan_timing.sqpar.onset_slice = 1;  matlabbatch{1}.spm.tools.physio.scan_timing.sqpar.time_slice_to_slice = [];  matlabbatch{1}.spm.tools.physio.scan_timing.sqpar.Nprep = [];  matlabbatch{1}.spm.tools.physio.scan_timing.sync.nominal = struct([]);  matlabbatch{1}.spm.tools.physio.preproc.cardiac.modality = 'PPU';  matlabbatch{1}.spm.tools.physio.preproc.cardiac.filter.no = struct([]);  matlabbatch{1}.spm.tools.physio.preproc.cardiac.initial_cpulse_select.auto_template.min = 0.4;  matlabbatch{1}.spm.tools.physio.preproc.cardiac.initial_cpulse_select.auto_template.file = 'initial_cpulse_kRpeakfile.mat';  matlabbatch{1}.spm.tools.physio.preproc.cardiac.initial_cpulse_select.auto_template.max_heart_rate_bpm = 90;  matlabbatch{1}.spm.tools.physio.preproc.cardiac.posthoc_cpulse_select.off = struct([]);  matlabbatch{1}.spm.tools.physio.preproc.respiratory.filter.passband = [0.01 2];  matlabbatch{1}.spm.tools.physio.preproc.respiratory.despike = true;  matlabbatch{1}.spm.tools.physio.model.output_multiple_regressors = 'mregress.txt';  matlabbatch{1}.spm.tools.physio.model.output_physio = 'physio';  matlabbatch{1}.spm.tools.physio.model.orthogonalise = 'none';  matlabbatch{1}.spm.tools.physio.model.censor_unreliable_recording_intervals = true; %false;   matlabbatch{1}.spm.tools.physio.model.retroicor.yes.order.c = 3;  matlabbatch{1}.spm.tools.physio.model.retroicor.yes.order.r = 4;  matlabbatch{1}.spm.tools.physio.model.retroicor.yes.order.cr = 1;  matlabbatch{1}.spm.tools.physio.model.rvt.no = struct([]);  matlabbatch{1}.spm.tools.physio.model.hrv.no = struct([]);  matlabbatch{1}.spm.tools.physio.model.noise_rois.no = struct([]);  matlabbatch{1}.spm.tools.physio.model.movement.yes.file_realignment_parameters = {fullfile(dat_path, sprintf('sub-%s', sub), 'ses-02', 'func', sprintf('sub-%s_ses-02_task-%s_run-%d_desc-motion_timeseries.txt', sub, task, irun))}; %8  matlabbatch{1}.spm.tools.physio.model.movement.yes.order = 6;  matlabbatch{1}.spm.tools.physio.model.movement.yes.censoring_method = 'FD';  matlabbatch{1}.spm.tools.physio.model.movement.yes.censoring_threshold = 0.5;  matlabbatch{1}.spm.tools.physio.model.other.no = struct([]);  matlabbatch{1}.spm.tools.physio.verbose.level = 2;  matlabbatch{1}.spm.tools.physio.verbose.fig_output_file = '';  matlabbatch{1}.spm.tools.physio.verbose.use_tabs = false;   spm_jobman('run', matlabbatch);  end 3. Ready to run on Neurodesk! Now we have a batch script, we’re ready to run this on Neurodesk - yay! \nFirst make sure the details at the top of the script are correct. You can see that this script could easily be amended to run multiple subjects.\nOn Neurodesk, go to the PhysIO toolbox, but select the command line tool rather than the GUI interface (‘physio r7771 instead of physioGUI r7771). This will take you to the container for the PhysIO toolbox \n\u003c!– –\u003e\nNow to run your PhysIO batch script, type the command:\nrun_spm12.sh /opt/mcr/v99/ batch /your/batch/scipt/named_something.m Et Voila! Physiological regressors are now yours - mua ha ha!\n","categories":"","description":"Follow this tutorial as an example of how to batch script for the PhysIO toolbox using Neurodesk.\n","excerpt":"Follow this tutorial as an example of how to batch script for the …","ref":"/neurodesk.github.io/tutorials/functional_imaging/physio_batch_workflow/","tags":["template","documentation"],"title":"A batch scripting example for PhysIO toolbox"},{"body":"If you want more speed in a region one way could be to setup another Stratum 1 server or a proxy. We currently don’t run any proxy servers but it would be important for using it on a cluster.\n\" data-output=\"2-4\" docker run --shm-size=1gb -it --privileged --name neurodesktop ` -v C:/neurodesktop-storage:/neurodesktop-storage -p 8080:8080 ` -h neurodesktop-20220701 ` vnmd/neurodesktop:20220701  Setup a CVMFS proxy server sudo yum install -y squid  Open the squid.confand use the following configuration\nsudo vi /etc/squid/squid.conf  # List of local IP addresses (separate IPs and/or CIDR notation) allowed to access your local proxy #acl local_nodes src YOUR_CLIENT_IPS # Destination domains that are allowed #acl stratum_ones dstdomain .YOURDOMAIN.ORG #acl stratum_ones dstdom_regex YOUR_REGEX acl stratum_ones dst 140.238.211.92 # Squid port http_port 3128 # Deny access to anything which is not part of our stratum_ones ACL. http_access deny !stratum_ones # Only allow access from our local machines #http_access allow local_nodes http_access allow localhost # Finally, deny all other access to this proxy http_access deny all minimum_expiry_time 0 maximum_object_size 1024 MB cache_mem 128 MB maximum_object_size_in_memory 128 KB # 5 GB disk cache cache_dir ufs /var/spool/squid 5000 16 256   sudo squid -k parse sudo systemctl start squid sudo systemctl enable squid sudo systemctl status squid sudo systemctl restart squid  ","categories":"","description":"Setup CVMFS Proxy server\n","excerpt":"Setup CVMFS Proxy server\n","ref":"/neurodesk.github.io/developers/cvmfs/proxy/","tags":"","title":"Setup CVMFS Proxy"},{"body":" This tutorial was created by Steffen Bollmann.\nGithub: @stebo85 Web: mri.sbollmann.net Twitter: @sbollmann_MRI\n Quantitative Susceptibility Mapping in QSMxT Neurodesk includes QSMxT, a complete and end-to-end QSM processing and analysis framework that excels at automatically reconstructing and processing QSM for large groups of participants.\nQSMxT provides pipelines implemented in Python that:\n Automatically convert DICOM data to the Brain Imaging Data Structure (BIDS) Automatically reconstruct QSM, including steps for:  Robust masking without anatomical priors Phase unwrapping (Laplacian based) Background field removal + dipole inversion (tgv_qsm) Multi-echo combination   Automatically generate a common group space for the whole study, as well as average magnitude and QSM images that facilitate group-level analyses. Automatically segment T1w data and register them to the QSM space to extract quantitative values in anatomical regions of interest. Export quantitative data to CSV for all subjects using the automated segmentations, or a custom segmentation in the group space (we recommend ITK snap).  If you use QSMxT for a study, please cite https://doi.org/10.1101/2021.05.05.442850 (for QSMxT) and http://www.ncbi.nlm.nih.gov/pubmed/25731991 (for TGVQSM)\nDownload demo data Open a terminal and run:\npip install osfclient export PATH=$PATH:~/.local/bin cd /neurodesktop-storage/ osf -p ru43c clone /neurodesktop-storage/qsmxt-demo unzip /neurodesktop-storage/qsmxt-demo/osfstorage/GRE_2subj_1mm_TE20ms/sub1/GR_M_5_QSM_p2_1mmIso_TE20.zip -d /neurodesktop-storage/qsmxt-demo/dicoms unzip /neurodesktop-storage/qsmxt-demo/osfstorage/GRE_2subj_1mm_TE20ms/sub1/GR_P_6_QSM_p2_1mmIso_TE20.zip -d /neurodesktop-storage/qsmxt-demo/dicoms unzip /neurodesktop-storage/qsmxt-demo/osfstorage/GRE_2subj_1mm_TE20ms/sub2/GR_M_5_QSM_p2_1mmIso_TE20.zip -d /neurodesktop-storage/qsmxt-demo/dicoms unzip /neurodesktop-storage/qsmxt-demo/osfstorage/GRE_2subj_1mm_TE20ms/sub2/GR_P_6_QSM_p2_1mmIso_TE20.zip -d /neurodesktop-storage/qsmxt-demo/dicoms QSMxT Usage Start QSMxT (in this demo we used 1.1.9) from the applications menu in the desktop (Neurodesk \u003e Quantitative Imaging \u003e qsmxt)\n Convert DICOM data to BIDS: cd /neurodesktop-storage/qsmxt-demo python3 /opt/QSMxT/run_0_dicomSort.py /neurodesktop-storage/qsmxt-demo/dicoms 00_dicom python3 /opt/QSMxT/run_1_dicomConvert.py 00_dicom 01_bids   This will bring up an interactive question to ask you which sequence your QSM data are. It will automatically detect the QSM sequence if it has qsm or t2star in the protocol name or you can use the command line argument --t2starw_series_patterns to specify. This demo data comes without a structural scan (automatically recognized with t1w in the name, or specified with --t1w_series_patterns, so hit Enter to continue when it asks you to identify which scan the T1w scan is:\nRun QSM pipeline: python3 /opt/QSMxT/run_2_qsm.py 01_bids 02_qsm_output   Then you can open a viewer (Visualization -\u003e mricrogl -\u003e mricroglGUI) and you can find the QSM outputs in /neurodesktop-storage/qsmxt-demo/02_qsm_output/qsm_final/_run_run-1/\nfor example: sub-170705-134431-std-1312211075243167001_ses-1_run-1_part-phase_T2starw_scaled_qsm_000_composite_average.nii\n Please note that the demo dataset does not have a T1w scan for anatomical segmentation and therefore the subsequent steps in QSMxT (e.g. python3 /opt/QSMxT/run_3_segment.py 01_bids 03_segmentation) will NOT work.\n ","categories":"","description":"Example workflow for Quantitative Susceptibility Mapping\n","excerpt":"Example workflow for Quantitative Susceptibility Mapping\n","ref":"/neurodesk.github.io/tutorials/phase_processing/qsm/","tags":"","title":"Quantitative Susceptibility Mapping"},{"body":" Check if the last automated build ran OK: https://github.com/NeuroDesk/neurodesktop/actions Run this build date and test if everything is ok and no regression happened Check what changes where made since the last release: https://github.com/NeuroDesk/neurodesktop/commits/main Summarize the main changes and copy this to the Release History: https://www.neurodesk.org/docs/neurodesktop/release-history/ Change the version of the latest desktop in https://github.com/NeuroDesk/neurodesk.github.io/blob/hugo-docsy/data/neurodesktop.toml Commit all changes Tweet a quick summary of the changes and announce new version: https://twitter.com/neuro_desk  ","categories":"","description":"A description of what to do to create new release of our Neurodesktop\n","excerpt":"A description of what to do to create new release of our Neurodesktop\n","ref":"/neurodesk.github.io/developers/architecture/release_process/","tags":"","title":"Neurodesktop Release Process"},{"body":"We store our singuarlity containers unpacked on CVMFS. We tried the DUCC tool in the beginning, but it was causing too many issues with dockerhub and we were rate limited. The script to unpack our singularity containers is here: https://github.com/NeuroDesk/neurocommand/blob/main/cvmfs/sync_containers_to_cvmfs.sh\nIt gets called by a cronjob on the CVMFS Stratum 0 server and relies on the log.txt file being updated via an action in the neurocommand repository (https://github.com/NeuroDesk/neurocommand/blob/main/.github/workflows/upload_containers_simg.sh)\nThe Stratum 1 servers then pull this repo from Stratum 0 and our desktops mount these repos (configured here: https://github.com/NeuroDesk/neurodesktop/blob/main/Dockerfile)\nThe startup script (https://github.com/NeuroDesk/neurodesktop/blob/main/config/startup.sh) sets up CVMFS and tests which server is fastest during the container startup.\nThis can also be done manually:\nsudo cvmfs_talk -i neurodesk.ardc.edu.au host info sudo cvmfs_talk -i neurodesk.ardc.edu.au host probe cvmfs_config stat -v neurodesk.ardc.edu.au  ","categories":"","description":"CVMFS architecture\n","excerpt":"CVMFS architecture\n","ref":"/neurodesk.github.io/developers/cvmfs/cvmfs_architecture/","tags":"","title":"CVMFS architecture"},{"body":"Setup a Stratum 0 server: Setup Storage (would object storage be better? -\u003e see comment below under next iteration ideas)\nlsblk -l sudo mkfs.ext4 /dev/vdb sudo mkdir /storage sudo mount /dev/vdb /storage/ -t auto sudo chown ec2-user /storage/ sudo chmod a+rwx /storage/  sudo vi /etc/fstab /dev/vdb /storage auto defaults,nofail 0 2  Setup server sudo yum install vim htop gcc git screen sudo timedatectl set-timezone Australia/Brisbane sudo yum install -y https://ecsft.cern.ch/dist/cvmfs/cvmfs-release/cvmfs-release-latest.noarch.rpm sudo yum install -y cvmfs cvmfs-server sudo systemctl enable httpd sudo systemctl restart httpd # sudo systemctl stop firewalld # restore keys: sudo mkdir /etc/cvmfs/keys/incoming sudo chmod a+rwx /etc/cvmfs/keys/incoming cd connections/cvmfs_keys/ scp neuro* ec2-user@203.101.226.164:/etc/cvmfs/keys/incoming sudo mv /etc/cvmfs/keys/incoming/* /etc/cvmfs/keys/ #backup keys: #mkdir cvmfs_keys #scp opc@158.101.127.61:/etc/cvmfs/keys/neuro* . sudo cvmfs_server mkfs -o $USER neurodesk.ardc.edu.au cd /storage sudo mkdir -p cvmfs-storage/srv/ cd /srv/ sudo mv cvmfs/ /storage/cvmfs-storage/srv/ sudo ln -s /storage/cvmfs-storage/srv/cvmfs/ cd /var/spool sudo mkdir /storage/spool sudo mv cvmfs/ /storage/spool/ sudo ln -s /storage/spool/cvmfs . cvmfs_server transaction neurodesk.ardc.edu.au cvmfs_server publish neurodesk.ardc.edu.au  sudo vi /etc/cron.d/cvmfs_resign  0 11 * * 1 root /usr/bin/cvmfs_server resign neurodesk.ardc.edu.au  cat /etc/cvmfs/keys/neurodesk.ardc.edu.au.pub  MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAuV9JBs9uXBR83qUs7AiE nSQfvh6VCdNigVzOfRMol5cXsYq3cFy/Vn1Nt+7SGpDTQArQieZo4eWC9ww2oLq0 vY1pWyAms3Y4i+IUmMbwNifDU4GQ1KN9u4zl9Peun2YQCLE7mjC0ZLQtLM7Q0Z8h NwP8jRJTN+u8mRKzkyxfSMLscVMKhm2pAwnT1zB9i3bzVV+FSnidXq8rnnzNHMgv tfqx1h0gVyTeodToeFeGG5vq69wGZlwEwBJWVRGzzr+a8dWNBFMJ1HxamrBEBW4P AxOKGHmQHTGbo+tdV/K6ZxZ2Ry+PVedNmbON/EPaGlI8Vd0fascACfByqqeUEhAB dQIDAQAB -----END PUBLIC KEY-----  Next iteration of this: use object storage?  current implementation uses block storage, but this makes increasing the volume size a bit more work we coulddn’t get object storage to work on Oracle as it assumes AWS S3  Optimize settings for repositories for Container Images from the CVMFS documentation: Repositories containing Linux container image contents (that is: container root file systems) should use overlayfs as a union file system and have the following configuration:\nCVMFS_INCLUDE_XATTRS=true CVMFS_VIRTUAL_DIR=true  Extended attributes of files, such as file capabilities and SElinux attributes, are recorded. And previous file system revisions can be accessed from the clients.\nCurrently not used We tested the DUCC tool in the beginning, but it was leading to too many docker pulls and we therefore replaced it with our own script: https://github.com/NeuroDesk/neurocommand/blob/main/cvmfs/sync_containers_to_cvmfs.sh\nThis is the old DUCC setup\nsudo yum install cvmfs-ducc.x86_64 sudo -i dnf install -y yum-utils yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo dnf install docker-ce docker-ce-cli containerd.io systemctl enable docker systemctl start docker docker version docker info # leave root mode sudo groupadd docker sudo usermod -aG docker $USER sudo chown root:docker /var/run/docker.sock newgrp docker vi convert_appsjson_to_wishlist.sh export DUCC_DOCKER_REGISTRY_PASS=configure_secret_password_here_and_dont_push_to_github cd neurodesk git pull ./gen_cvmfs_wishlist.sh cvmfs_ducc convert recipe_neurodesk_auto.yaml cd .. chmod +x convert_appsjson_to_wishlist.sh git clone https://github.com/NeuroDesk/neurodesk/ # setup cron job sudo vi /etc/cron.d/cvmfs_dockerpull */5 * * * * opc cd ~ \u0026\u0026 bash /home/opc/convert_appsjson_to_wishlist.sh #vi recipe.yaml ##version: 1 #user: vnmd #cvmfs_repo: neurodesk.ardc.edu.au #output_format: '$(scheme)://$(registry)/vnmd/thin_$(image)' #input: #- 'https://registry.hub.docker.com/vnmd/tgvqsm_1.0.0:20210119' #- 'https://registry.hub.docker.com/vnmd/itksnap_3.8.0:20201208' #cvmfs_ducc convert recipe_neurodesk.yaml #cvmfs_ducc convert recipe_unpacked.yaml   ","categories":"","description":"Host a Stratum 0 server\n","excerpt":"Host a Stratum 0 server\n","ref":"/neurodesk.github.io/developers/cvmfs/stratum0/","tags":"","title":"Setup Stratum 0 server"},{"body":"The stratum 1 servers for the desktop are configured here: https://github.com/NeuroDesk/neurodesktop/blob/main/Dockerfile\nIf you want more speed in a region one way could be to setup another Stratum 1 server or a proxy.\nSetup a Stratum 1 server: sudo yum install -y https://ecsft.cern.ch/dist/cvmfs/cvmfs-release/cvmfs-release-latest.noarch.rpm sudo yum install -y cvmfs-server squid sudo yum install -y python3-mod_wsgi sudo sed -i 's/Listen 80/Listen 127.0.0.1:8080/' /etc/httpd/conf/httpd.conf set +H echo \"http_port 80 accel\" | sudo tee /etc/squid/squid.conf echo \"http_port 8000 accel\" | sudo tee -a /etc/squid/squid.conf echo \"http_access allow all\" | sudo tee -a /etc/squid/squid.conf echo \"cache_peer 127.0.0.1 parent 8080 0 no-query originserver\" | sudo tee -a /etc/squid/squid.conf echo \"acl CVMFSAPI urlpath_regex ^/cvmfs/[^/]*/api/\" | sudo tee -a /etc/squid/squid.conf echo \"cache deny !CVMFSAPI\" | sudo tee -a /etc/squid/squid.conf echo \"cache_mem 128 MB\" | sudo tee -a /etc/squid/squid.conf sudo systemctl start httpd sudo systemctl start squid sudo systemctl enable httpd sudo systemctl enable squid echo 'CVMFS_GEO_LICENSE_KEY=kGepdzqbAP4fjf5X' | sudo tee -a /etc/cvmfs/server.local sudo chmod 600 /etc/cvmfs/server.local sudo mkdir -p /etc/cvmfs/keys/ardc.edu.au/ echo \"-----BEGIN PUBLIC KEY----- MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwUPEmxDp217SAtZxaBep Bi2TQcLoh5AJ//HSIz68ypjOGFjwExGlHb95Frhu1SpcH5OASbV+jJ60oEBLi3sD qA6rGYt9kVi90lWvEjQnhBkPb0uWcp1gNqQAUocybCzHvoiG3fUzAe259CrK09qR pX8sZhgK3eHlfx4ycyMiIQeg66AHlgVCJ2fKa6fl1vnh6adJEPULmn6vZnevvUke I6U1VcYTKm5dPMrOlY/fGimKlyWvivzVv1laa5TAR2Dt4CfdQncOz+rkXmWjLjkD 87WMiTgtKybsmMLb2yCGSgLSArlSWhbMA0MaZSzAwE9PJKCCMvTANo5644zc8jBe NQIDAQAB -----END PUBLIC KEY-----\" | sudo tee /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub sudo cvmfs_server add-replica -o $USER http://203.101.226.164/cvmfs/neurodesk.ardc.edu.au /etc/cvmfs/keys/ardc.edu.au # CVMFS will store everything in /srv/cvmfs so make sure there is enough space or create a symlink to a bigger storage volume # e.g.: sudo cvmfs_server snapshot neurodesk.ardc.edu.au echo \"/var/log/cvmfs/*.log { weekly missingok notifempty }\" | sudo tee /etc/logrotate.d/cvmfs echo '*/5 * * * * root output=$(/usr/bin/cvmfs_server snapshot -a -i 2\u00261) || echo \"$output\" ' | sudo tee /etc/cron.d/cvmfs_stratum1_snapshot sudo yum install iptables sudo iptables -t nat -A PREROUTING -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 8000 sudo systemctl disable firewalld sudo systemctl stop firewalld # make sure that port 80 is open in the real firewall sudo cvmfs_server update-geodb   ","categories":"","description":"Host a Stratum 1 server\n","excerpt":"Host a Stratum 1 server\n","ref":"/neurodesk.github.io/developers/cvmfs/stratum1/","tags":"","title":"Setup Stratum 1 server"},{"body":" This tutorial was created by Joan Amos.\nEmail: joan@std.uestc.edu.cn Github: @Joanone\n References: The steps used for this tutorial were referenced from: https://github.com/civier/HCP-dMRI-connectome https://andysbrainbook.readthedocs.io/en/latest/MRtrix/MRtrix_Course/MRtrix_00_Diffusion_Overview.html https://mrtrix.readthedocs.io/en/latest/quantitative_structural_connectivity/structural_connectome.html\nData Description Reference: The single subject data used in this tutorial has been preprocessed and was downloaded from:\nhttps://db.humanconnectome.org/\n100307_3T_Structural_preproc.zip 100307_3T_Diffusion_preproc.zip\nDownload demo data: https://1drv.ms/u/s!AjZJgBZ_P9UO8nWvAFwQyKQnrroe?e=6qmRlQ - Diffusion data https://1drv.ms/u/s!AjZJgBZ_P9UO8nblYQyUVsibqggs?e=mkwLpQ - Structural data\nRequired structural preprocessed input files aparc+aseg.nii.gz T1w_acpc_dc_restore_brain.nii.gz\nRequired diffusion preprocessed input files bvals bvecs data.nii.gz\nInstall Neurodesk on windows and mount external storage on your host computer References: https://neurodesk.github.io/docs/neurodesktop/getting-started/windows/ https://neurodesk.github.io/docs/neurodesktop/storage/\nN/B: Constructing the structural connectivity using dMRI HCP data is computationally intensive. Thus, ensure you have sufficient disk space (\u003e100GB) and RAM size (16, 32GB)\nOpen the powershell terminal and run:\n docker run --shm-size=1gb -it --privileged --name neurodesktop -v C:/neurodesktop-storage:/neurodesktop-storage -v D:/moredata:/data -p 8080:8080 -h neurodesktop-20220222 vnmd/neurodesktop:20220222 Navigate to the mounted storage–\u003emore data–\u003eCreate a new folder of your choice–\u003e copy the required input files into a folder-\u003e100307 N/B: The folder created in this tutorial was tagged “Test”\nOpen a terminal in neurodesk and run:\n cd/data/Test/100307 Activate mrtrix3 software in the neurodesk terminal  ml mrtrix3/3.0.3 N/B: The advantage neurodesk offers is the version of software can be selected from a range of others, which caters for reproducibility. The mrtrix3 (3.0.3) version was used in this tutorial.\nStep 1: Further pre-processing Extract data.nii.gz to enable memory-mapping. The extracted files are about 4.5GB:\ngunzip -c data.nii.gz \u003e data.nii; mrconvert data.nii DWI.mif -fslgrad bvecs bvals -datatype float32 -stride 0,0,0,1 -force -info; rm -f data.nii Perform mrconvert:\ndwibiascorrect ants DWI.mif DWI_bias_ants.mif -bias bias_ants_field.mif -force -info; Extract the response function. Uses -stride 0,0,0,1:\ndwi2response dhollander DWI_bias_ants.mif response_wm.txt response_gm.txt response_csf.txt -voxels RF_voxels.mif -force;  dwiextract DWI_bias_ants.mif - -bzero | mrmath - mean meanb0.mif -axis 3 -force -info Generate mask:\n dwi2mask DWI_bias_ants.mif DWI_mask.mif -force -info; Generate Fibre Orientation Distributions (FODs):\ndwi2fod msmt_csd DWI_bias_ants.mif response_wm.txt wmfod.mif response_gm.txt gm.mif response_csf.txt csf.mif -mask DWI_mask.mif -force -info; Perform normalization:\n mtnormalise wmfod.mif wmfod_norm.mif gm.mif gm_norm.mif csf.mif csf_norm.mif -mask DWI_mask.mif -check_norm mtnormalise_norm.mif -check_mask mtnormalise_mask.mif -force -info Generate a 5 tissue image:\n5ttgen fsl T1w_acpc_dc_restore_brain.nii.gz 5TT.mif -premasked Convert the B0 image:\nmrconvert meanb0.mif mean_b0.nii.gz Activate the fsl and afni softwares in the neurodesk terminal:\nml fsl/6.0.3 ml afni/21.0.0 Use “fslroi” to extract the first volume of the segmented dataset which corresponds to the Grey Matter Segmentation:\nfslroi 5TT.nii.gz 5TT_vol0.nii.gz 0 Use “flirt” command to coregister the two datasets:\n flirt -in mean_b0.nii.gz -ref 5TT_vol0.nii.gz -interp nearestneighbour -dof 6 -omat diff2struct_fsl.mat Convert the transformation matrix to a format readble by MRtrix:\n transformconvert diff2struct_fsl.mat mean_b0.nii.gz 5TT.nii.gz flirt_import diff2struct_mrtrix.txt Coregister the anatomical image to the diffusion image:\n mrtransform 5TT.mif -linear diff2struct_mrtrix.txt -inverse 5TT_coreg Create the seed boundary which sepearates the grey from the white matter. The command “5tt2gmwmi” denotes (5 tissue type(segmentation) to grey matter/white matter interface):\n 5tt2gmwmi 5TT_coreg.mif gmwmSeed_coreg.mif Step 2: Tractogram construction The probabilistic tractography which is the default in MRtrix is used in this tutorial. The default method is the iFOD2 algorithm. The number of streamlines used is 10 million, this was chosen to save computational time:\ntckgen -act 5TT_coreg.mif -backtrack -seed_gmwmi gmwmSeed_coreg.mif -nthreads 8 -minlength 5.0 -maxlength 300 -cutoff 0.06 -select 10000000 wmfod_norm.mif tracks_10M.tck -force Step 3: SIFT2 construction The generated streamlines can be refined with tcksift2 to counterbalance the overfitting. This creates a text file containing weights for each voxel in the brain:\ntcksift2 -act 5TT_coreg.mif -out_mu sift_mu.txt -out_coeffs sift_coeffs.txt -nthreads 8 tracks.tck wmfod_norm.mif sift_1M.txt -force Step 4: Connectome construction In constructing the connectome, the desikan-killany atlas which includes the cortical and sub-cortical regions (84 regions) was used.\nCopy the FreeSurferColorLUT.txt file from the ml freesurfer 7.2.0 singularity container to the subject’s folder\ncp /opt/freesurfer-7.2.0/FreeSurferColorLUT.txt /data/Test/100307 Copy the fs_default.txt file from the ml mrtrix3 3.0.3 singularity container to the subject’s folder\ncp /opt/mrtrix3-3.0.3/share/mrtrix3/labelconvert/fs-default.txt /data/Test/100307 The command labelconvert will use the parcellation and segmentation output of FreeSurfer to create a new parcellated file in .mif format:\n labelconvert aparc+aseg.nii.gz FreeSurferColorLUT.txt fs_default.txt nodes.mif -force Perform nodes co-registeration:\nmrtransform nodes.mif -linear diff2struct_mrtrix.txt -inverse -datatype uint32 nodes_coreg.mif -force Create a whole-brain connectome which denotes the streamlines between each parcellation pair in the atlas. The “symmetric” option makes the lower and upper diagonal the same, the “scale_invnodevol” option scales the connectome by the inverse of the size of the node:\ntck2connectome -symmetric -zero_diagonal -scale_invnodevol -tck_weights_in sift_1M.txt tracks.tck nodes_coreg.mif nodes.csv -out_assignment assignments_nodes.csv -force Viewing the connectome The generated nodes.csv file can be viewed outside neurodesk as a matrix in Matlab.\nconnectome=importdata('nodes.csv'); imagesc(connectome,[0 1]) –\u003e\n","categories":"","description":"Example workflow for constructing strutural connectivity (Human connectome project: Single subject)\n","excerpt":"Example workflow for constructing strutural connectivity (Human …","ref":"/neurodesk.github.io/tutorials/structural_imaging/structuralconnectivity/","tags":"","title":"Structural connectivity dMRI"},{"body":" This tutorial was created by Steffen Bollmann.\nGithub: @stebo85 Web: mri.sbollmann.net Twitter: @sbollmann_MRI\n Download demo data Open a terminal and run:\npip install osfclient cd /neurodesktop-storage/ osf -p ru43c fetch 01_bids.zip /neurodesktop-storage/swi-demo/01_bids.zip  unzip /neurodesktop-storage/swi-demo/01_bids.zip -d /neurodesktop-storage/swi-demo/ Open the CLEARSWI tool from the application menu:\npaste this julia script in a julia file and execute:\ncd /neurodesktop-storage/ vi clearswi.jl hit a or i and then paste this:\nusing CLEARSWI  TEs = [20] nifti_folder = \"/neurodesktop-storage/swi-demo/01_bids/sub-170705134431std1312211075243167001/ses-1/anat\" magfile = joinpath(nifti_folder, \"sub-170705134431std1312211075243167001_ses-1_acq-qsm_run-1_magnitude.nii.gz\") phasefile = joinpath(nifti_folder, \"sub-170705134431std1312211075243167001_ses-1_acq-qsmPH00_run-1_phase.nii.gz\")  mag = readmag(magfile); phase = readphase(phasefile); data = Data(mag, phase, mag.header, TEs);  swi = calculateSWI(data); # mip = createIntensityProjection(swi, minimum); # minimum intensity projection, other Julia functions can be used instead of minimum mip = createMIP(swi); # shorthand for createIntensityProjection(swi, minimum)  savenii(swi, \"/neurodesktop-storage/swi-demo/swi.nii\"; header=mag.header) savenii(mip, \"/neurodesktop-storage/swi-demo/mip.nii\"; header=mag.header) hit SHIFT-Z-Z and run:\njulia clearswi.jl Open ITK snap from the Visualization Application’s menu and inspect the results (the outputs are in swi-demo/swi.nii and mip.nii) ","categories":"","description":"Example workflow for SWI processing\n","excerpt":"Example workflow for SWI processing\n","ref":"/neurodesk.github.io/tutorials/phase_processing/swi/","tags":"","title":"SWI"},{"body":" This tutorial was created by Steffen Bollmann.\nGithub: @stebo85 Web: mri.sbollmann.net Twitter: @sbollmann_MRI\n Download demo data Open a terminal and run:\npip install osfclient cd /neurodesktop-storage/ osf -p ru43c fetch 01_bids.zip /neurodesktop-storage/swi-demo/01_bids.zip  unzip /neurodesktop-storage/swi-demo/01_bids.zip -d /neurodesktop-storage/swi-demo/   mkdir /neurodesktop-storage/romeo-demo/  cp /neurodesktop-storage/swi-demo/01_bids/sub-170705134431std1312211075243167001/ses-1/anat/sub-170705134431std1312211075243167001_ses-1_acq-qsmPH00_run-1_phase.nii.gz /neurodesktop-storage/romeo-demo/phase.nii.gz  cp /neurodesktop-storage/swi-demo/01_bids/sub-170705134431std1312211075243167001/ses-1/anat/sub-170705134431std1312211075243167001_ses-1_acq-qsm_run-1_magnitude.nii.gz /neurodesktop-storage/romeo-demo/mag.nii.gz  gunzip /neurodesktop-storage/romeo-demo/mag.nii.gz gunzip /neurodesktop-storage/romeo-demo/phase.nii.gz Using ROMEO for phase unwrapping Open the ROMEO tool from the application menu and run:\nromeo -p /neurodesktop-storage/romeo-demo/phase.nii -m /neurodesktop-storage/romeo-demo/mag.nii -k nomask -o /neurodesktop-storage/romeo-demo/ ","categories":"","description":"MRI Phase Unwrapping\n","excerpt":"MRI Phase Unwrapping\n","ref":"/neurodesk.github.io/tutorials/phase_processing/unwrapping/","tags":"","title":"Unwrapping"},{"body":"a short description of your workflow. This will form the subheading for the tutorial page. Once you've filled out those details, you can delete this comment block. --  This tutorial was created by Name P. Namington.\nEmail: n.namington@institution.edu.au\nGithub: @Namesgit\nTwitter: @Nameshandle\n Welcome to the workflow template, which you can use to contribute your own neurodesk workflow to our documentation. We aim to collect a wide variety of workflows representing the spectrum of tools available under the neurodesk architechture and the diversity in how researchers might apply them. Please add plenty of descriptive detail and make sure that all steps of the workflow work before submitting the tutorial.\nHow to contribute a new workflow Begin by creating a copy of our documentation that you can edit:\n Visit the github repository for the Neurodesk documentation (https://github.com/NeuroDesk/neurodesk.github.io). Fork the repository.   You should now have your own copy of the documentation, which you can alter without affecting our official documentation. You should see a panel stating “This branch is up to date with Neurodesk:hugo-docsy.” If someone else makes a change to the official documentation, the statement will change to reflect this. You can bring your repository up to date by clicking “Fetch upstream”.  Next, create your workflow:\n Clone your forked version of our documentation to a location of your choice on your computer. In this new folder, navigate to “neurodesk.github.io/content/en/tutorials” and then navigate to the subfolder you believe your workflow belongs in (e.g. “/functional_imaging”). Create a new, appropriately named markdown file to house your workflow. (e.g. “/physio.md”) Open this file in the editor of your choice (we recommend vscode) and populate it with your workflow! Please use this template as a style guide, it can be located at “neurodesk.github.io\\content\\en\\tutorials\\documentation\\workflowtemplate.md”. You’re also welcome to have a look at other the workflows already documented on our website for inspiration.  Finally, contribute your new workflow to the official documentation!:\n Once you are happy with your workflow, make sure you commit all your changes and push these local commits to github. Navigate to your forked version of the repository on github. Before you proceed, make sure you are up to date with our upstream documentation, you may need to fetch upstream changes. Now you can preview the changes before contributing them upstream. For this click on the “Actions” tab and enable the Actions (“I understand my workflows…”). The first build will fail (due to a bug with the Github token), but the second build will work. Then you need to open the settings of the repository and check that Pages points to gh-pages and when clicking on the link the site should be there. To contribute your changes, click “Contribute”, and then “Open pull request”. Give your pull request a title (e.g. “Document PhysIO workflow”), leave a comment briefly describing what you have done, and then create the pull request. Someone from the Neurodesk team will review and accept your workflow and it will appear on our website soon!.  Thanks so much for taking the time to contribute your workflow to the Neurodesk community! If you have any feedback on the process, please let us know on github discussions.\nFormatting guidelines You can embelish your text in this tutorial using markdown conventions; text can be bold, italic, or strikethrough. You can also add Links, and you can organise your tutorial with headers, starting at level 2 (the page title is a level 1 header):\nLevel 2 heading You can also include progressively smaller subheadings:\nLevel 3 heading Some more detailed information.\nLevel 4 heading Even more detailed information.\nCode blocks You can add codeblocks to your tutorial as follows:\n# Some example code import numpy as np a = np.array([1, 2]) b = np.array([3, 4]) print(a+b) Or add syntax highlighting to your codeblocks:\n# Some example code import numpy as np a = np.array([1, 2]) b = np.array([3, 4]) print(a+b) Advanced code or command line formatting using this html snippet:\n\" data-output=\"6\" # Some example code import numpy as np a = np.array([1, 2]) b = np.array([3, 4]) print(a+b) [4 6]  You can also add code snippets, e.g. var foo = \"bar\";, which will be shown inline.\nImages To add screenshots to your tutorial, create a subfolder in neurodesk.github.io/static with the same link name as your tutorial. Add your screenshot to this folder, keeping in mind that you may want to adjust your screenshot to a reasonable size before uploading. You can then embed these images in your tutorial using the following convention:\n![EEGtut1](/EEG_Tutorial/EEGtut1.png 'EEGtut1') \u003c!-- ![filename without extension](/subfolder_name/filename.png '[filename without extension') --\u003e \u003c!– –\u003e\nAlerts and warnings You can grab reader’s attention to particularly important information with quoteblocks, alerts and warnings:\n This is a quoteblock\n  This is an alert.  Note This is an alert with a title.  This is a warning.  Warning This is a warning with a title.  You can also segment information as follows:\n There’s a horizontal rule above and below this.\n Or add page information: This is a placeholder. Replace it with your own content.\n Tables You may want to order information in a table as follows:\n   Neuroscientist Notable work Lifetime     Santiago Ramón y Cajal Investigations on microscopic structure of the brain 1852–1934   Rita Levi-Montalcini Discovery of nerve growth factor (NGF) 1909–2012   Anne Treisman Feature integration theory of attention 1935–2018    Lists You may want to organise information in a list as follows:\nHere is an unordered list:\n Rstudio JASP SPSS  And an ordered list:\n Collect data Try to install analysis software Cry a little  And an unordered task list:\n Install Neurodesktop Analyse data Take a vacation  And a “mixed” task list:\n writing ? more writing probably  And a nested list:\n EEG file extensions  .eeg, .vhdr, .vmrk .edf .bdf .set, .fdt .smr   MEG file extensions  .ds .fif .sqd .raw .kdf    ","categories":"","description":"Follow this template to contribute your own workflow to the Neurodesk documentation.\n","excerpt":"Follow this template to contribute your own workflow to the Neurodesk …","ref":"/neurodesk.github.io/tutorials/documentation/workflowtemplate/","tags":["template","documentation"],"title":"Template for workflow creation"},{"body":"","categories":"","description":"The architecture of the Neurodesk ecosystem\n","excerpt":"The architecture of the Neurodesk ecosystem\n","ref":"/neurodesk.github.io/developers/architecture/","tags":"","title":"Architecture"},{"body":"","categories":"","description":"Tutorials about processing of EEG/MEG/ECoG data\n","excerpt":"Tutorials about processing of EEG/MEG/ECoG data\n","ref":"/neurodesk.github.io/tutorials/electrophysiology/","tags":"","title":"Electrophysiology"},{"body":"","categories":"","description":"Tutorials about processing functional MRI data\n","excerpt":"Tutorials about processing functional MRI data\n","ref":"/neurodesk.github.io/tutorials/functional_imaging/","tags":"","title":"Functional Imaging"},{"body":"Minimum System Requirements  At least 3GB free space for neurodesktop base image An Intel Mac. M1/ARM Macs are not yet supported. Docker requirements. Details found under https://docs.docker.com/get-docker/  Quickstart 1. Install Docker Install Docker from here: https://docs.docker.com/get-docker/\n Docker for MacOS by default runs with 2GB Memory. For actual workloads, 4GB Memory minimum for docker is highly recommended\n   Open the Docker Desktop and Navigate to the Resources tab. Instructions found at https://docs.docker.com/desktop/mac/#resources\n  Increase the Memory slider from 2.00 GB to 4.00 GB (or greater)\n  Increase Swap slider from 1GB to 2GB (or greater)\n  2. Run Neurodesktop Create a local folder where the downloaded applications will be stored, e.g. ~/neurodesktop-storage\n Open a terminal, and type the folowing command to automatically download the neurodesktop container and run it  docker run --shm-size=1gb -it --privileged --name neurodesktop -v ~/neurodesktop-storage:/neurodesktop-storage -p 8080:8080 -h neurodesktop-20220701 vnmd/neurodesktop:20220701 There is a bug in docker 3.3.0 for Mac that makes this command not run correctly and there will be no application menu when you start the desktop. Update your docker version when you see this!  if you get errors in neurodesktop then check if the ~/neurodesktop-storage directory is writable to all users, otherwise run chmod a+rwx ~/neurodesktop-storage\n Once neurodesktop is downloaded i.e. guacd[77]: INFO: Listening on host 127.0.0.1, port 4822 is displayed in terminal, leave the terminal open and neurodesktop running (i.e., do not press CTRL+C)\n  Open a browser and go to:\n  http://localhost:8080/#/?username=user\u0026password=password  We recommend to use Chrome over Firefox as it has an option to hide the Toolbar in full screen mode (go to the menu bar, click on View, and uncheck “Always Show Toolbar in Full Screen”). This allows for Neurodesktop to truly utilise the whole of your screen.   Press on “Desktop Auto-Resolution” under “ALL CONNECTIONS”\n  If it is the first time you use Neruodesktop, wait until the desktop appears (it may take a few seconds). Otherwise, it should appear instantaneously.\n  Neurodesk is ready to use! Click “What’s next?” on the left of this page for further instructions.\n  The browser can be closed anytime, and Neurodesktop will continue to run in the background. To reconnect to Neurodesktop, simply start over from step 3 above.  Deleting neurodesktop: When done processing your data it is important to stop and remove the container - otherwise the next start or container update will give an error (\"… The container name “/neurodesktop” is already in use…\")\nNote Notice that any data that were saved outside of /neurodesktop-storage would be lost. Please make sure to move all your data to that folder before deleting neurodesktop.    Click on the terminal from which you ran neurodesktop\n  Press control-C\n  Type:\n  docker stop neurodesktop Type:  docker rm neurodesktop Using an RDP Client Startup Neurodesktop using the following command:\ndocker run --shm-size=1gb -it --privileged --name neurodesktop -v ~/neurodesktop-storage:/neurodesktop-storage -p 3390:3389 -p 8080:8080 -h neurodesktop-20220701 vnmd/neurodesktop:20220701  If you want to connect via RDP using a different port, replace 3390 in the previous and next step with your port  Open your RDP client and connect to Computer localhost:3390\nUse the following details to login if prompted\nusername: user password: password Using VNC To enable VNC and disable RDP, startup Neurodesktop using the following command:\ndocker run --shm-size=1gb -it --privileged --name neurodesktop -v ~/neurodesktop-storage:/neurodesktop-storage -e VNC_ENABLE=true -p 8080:8080 -h neurodesktop-20220701 vnmd/neurodesktop:20220701  VNC allows for multiple desktop connections to same instance\nNote: Neurodesktop VNC on the browser currently does not support auto-resolution\n Using a VNC Client Needs testing  Startup Neurodesktop using the following command:\ndocker run --shm-size=1gb -it --privileged --name neurodesktop -v ~/neurodesktop-storage:/neurodesktop-storage -e VNC_ENABLE=true -p 5901:5901 -p 8080:8080 -h neurodesktop-20220701 vnmd/neurodesktop:20220701 Open a VNC Client and connect to port 5901\n","categories":"","description":"Install neurodesktop on MacOS\n","excerpt":"Install neurodesktop on MacOS\n","ref":"/neurodesk.github.io/docs/neurodesktop/getting-started/mac/","tags":"","title":"MacOS"},{"body":"","categories":"","description":"Tutorials about processing MRI phase\n","excerpt":"Tutorials about processing MRI phase\n","ref":"/neurodesk.github.io/tutorials/phase_processing/","tags":"","title":"MRI phase Processing"},{"body":"Layers Neurodesktop: https://github.com/NeuroDesk/neurodesktop\n docker container with interface modifications contains tools necessary to manage workflows in sub-containers: vscode, git CI: builds docker image and tests if it runs; tests if CVMFS servers are OK before deployment CD: pushes images to github \u0026 docker registry  Neurocommand: https://github.com/NeuroDesk/neurocommand\n script to install and manage multiple containers using transparent singularity on any linux system this repo also handles the creation of menu entries in a general form applicable to different desktop environments this repo can be re-used in other projects like CVL and when installing it on bare-metal workstations CI: tests if containers can be installed CD: this repo checks if containers requested in apps.json file are availabe on object storage and if not converts the singularity containers based on the docker containers and uploads them to object storage  transparent-singularity: https://github.com/NeuroDesk/transparent-singularity\n script to install neuro-sub-containers, installers are called by neurocommand this repo provides a way of using our containers on HPCs for large scale processing of the pipelines (including the support of SLURM and other job schedulers) CI: test if exposing of binaries from container works  Neurocontainers: https://github.com/NeuroDesk/neurocontainers\n build scripts for neuro-sub-containers CI: building and testing of containers CD: pushing containers to github and dockerhub registry  Neurodocker: https://github.com/NeuroDesk/neurodocker\n fork of neurodocker project provides recipes for our containers built we are providing pull requests back of recipes CI: handled by neurodocker - testing of generating container recipes  ","categories":"","description":"The architecture of the Neurodesk ecosystem\n","excerpt":"The architecture of the Neurodesk ecosystem\n","ref":"/neurodesk.github.io/developers/architecture/neurodesk-components/","tags":"","title":"Neurodesk Architecture"},{"body":"Video tutorial Click here to watch a 2 minute tutorial video from OHBM 2021\nIntroduction Neurodesk provides a containerised data analysis environment to facilitate reproducible analysis of neuroimaging data. At Neurodesk, we believe that reproducibility should be a fundamental principle underlying neuroscientific data analysis (1). Analysis pipelines for neuroimaging data typically rely on specific versions of packages and software, and are dependent on their native operating system. These dependencies mean that a working analysis pipeline may fail or produce different results on a new computer, or even on the same computer after a software update. Neurodesk provides a platform in which anyone, anywhere, using any computer can reproduce your original research findings given the original data and analysis code.\nWhat is a container? The Neurodesk environment allows users to build and use containers for analysing neuroimaging data. Containers can be compared to virtual machines, in that they allow users to create a virtual, isolated computing environment with an operating system separate to that of the host machine. However, containers differ from virtual machines in that they virtualise software rather than hardware. Practically, this means that container images require few system resources to install, start-up quickly, and are easily portable between computers.\nWe recomment watching this excellent short video from the Australian Research Data Commons (ARDC) on research applications of software containers. To read more about Docker containers, visit the Docker webpage\nThe Neurodesk ecosystem The Neurodesk ecosystem includes a number of tools for containerised analysis of neuroimaging data. These include:\nNeurodesktop  If you’re new to Neurodesk, we recommend you begin with Neurodesktop.\n Neurodesktop is a compact Docker container with a browser-accessible virtual desktop that allows you develop and implement data analysis pipelines as though you’re on your own computer. The neurodesktop container has the basic tools required for the analysis of fMRI and EEG data pre-installed. To get started, see: Neurodesktop\nNeurocommand Neurocommand offers the option to install and manage multiple distinct containers for more advanced users who prefer a command-line interface. Neurocommand is the recommended interface for users seeking to use Neurodesk in high performance computing (HPC) environments.\nTo get started, see: Neurocommand\nTransparent-singularity The applications pre-installed in neurodesktop and neurocommand are accessible through transparent-singularity, which allows users to transparently use containerised software as through it were installed natively.\nTo find out more about this open-source project, see: transparent-singularity\nNeurocontainers The neurocontainers repository contains build scripts for sub-containers which are wrapped around executables for neuroimaging data-analysis software. These neurocontainers can be used in combination with neurocommand or transparent-singularity.\nTo get started, see: Neurocontainers\nNeurodocker Neurodocker is a command-line program that generates custom Dockerfiles and Singularity recipes for neuroimaging and minifies existing containers.\nTo find out more about this open-source project, see: Neurodocker\nReferences    National Academies of Sciences, Engineering, and Medicine. 2019. Reproducibility and Replicability in Science. Washington, DC: The National Academies Press. https://doi.org/10.17226/25303.    ","categories":"","description":"A flexible, scalable and easy to use data analysis environment for reproducible neuroimaging.\n","excerpt":"A flexible, scalable and easy to use data analysis environment for …","ref":"/neurodesk.github.io/docs/overview/","tags":"","title":"Neurodesk Overview"},{"body":"","categories":"","description":"Tutorials about performing reproducible analyses in general\n","excerpt":"Tutorials about performing reproducible analyses in general\n","ref":"/neurodesk.github.io/tutorials/reproducibility/","tags":"","title":"Reproducibility"},{"body":"","categories":"","description":"Tutorials about performing MR spectroscopy analyses\n","excerpt":"Tutorials about performing MR spectroscopy analyses\n","ref":"/neurodesk.github.io/tutorials/spectroscopy/","tags":"","title":"Spectroscopy"},{"body":"","categories":"","description":"Tutorials about processing structural MRI data\n","excerpt":"Tutorials about processing structural MRI data\n","ref":"/neurodesk.github.io/tutorials/structural_imaging/","tags":"","title":"Structural Imaging"},{"body":"Working copies When you work on Neurocontainers code, there are three copies of the Neurocontainers Git repository that you are generally concerned with:\n The upstream remote. This is the official Neurocontainers repository on GitHub. You probably don’t have write access to this repository. The origin remote: Your personal remote repository on GitHub. You’ll use this to share your code and create pull requests. local copy: This lives on your laptop or your remote dev instance, and is what you’ll use to make changes and create commits.  When you work on Neurocontainers code, you will end up moving code between the various working copies.\nWorkflows Sometimes you need to get commits. Here are some scenarios:\n You may fork the official Neurocontainers repository to your GitHub fork. You may fetch commits from the official Neurocontainers repository to your local copy. You occasionally may fetch commits from your forked copy.  Sometimes you want to publish commits. Here are some scenarios:\n You push code from your local copy to your GitHub fork. (You usually want to put the commit on a feature branch.) You submit a PR to the official Neurocontainers repo.  Finally, the NeuroDesk core team will occasionally want your changes!\n The NeuroDesk core team can accept your changes and add them to the official repo, usually on the master branch.  Relevant Git commands The following commands are useful for moving commits between working copies:\n git fetch: This grabs code from another repository to your local copy. (Defaults to fetching from your default remote, origin). git fetch upstream: This grabs code from the upstream repository to your local copy. git push: This pushes code from your local repository to one of the remotes. git remote: This helps you configure short names for remotes. git pull: This pulls code, but by default creates a merge commit (which you definitely don’t want). However, if you’ve followed our cloning documentation, this will do git pull --rebase instead, which is the only mode you’ll want to use when working on Neurodesk.  Know what branch you’re working on When using Git, it’s important to know which branch you currently have checked out because most Git commands implicitly operate on the current branch. You can determine the currently checked out branch several ways.\nOne way is with git status:\n$ git status On branch newapp nothing to commit, working directory clean Another is with git branch which will display all local branches, with a star next to the current branch:\n$ git branch * newapp master To see even more information about your branches, including remote branches, use git branch -vva:\n$ git branch -vva * civet_2.1.1 f736814 [origin/civet_2.1.1] set DEPLOY_PATH master a0f0455 [origin/master] Merge pull request #129 remotes/origin/cat12_with_neurodocker 763f6de works :) remotes/origin/civet_2.1.1 f736814 set DEPLOY_PATH remotes/origin/master a0f0455 Merge pull request #129 You can also configure Bash and Zsh to display the current branch in your prompt.\nKeep your fork up to date You’ll want to keep your fork up-to-date with changes from Neurocontainers’s master repositories.\nNote about git pull: Rather than using git pull, which by default is a shortcut for git fetch \u0026\u0026 git merge FETCH_HEAD (docs), you should use git pull --rebase, which is like git fetch and then git rebase.\nFirst, fetch changes from Neurocontainers’s upstream repository you configured in the step above:\n$ git fetch upstream Next, check out your master branch and rebase it on top of upstream/master:\n$ git checkout master Switched to branch 'master' $ git rebase upstream/master This will rollback any changes you’ve made to master, update it from upstream/master, and then re-apply your changes. Rebasing keeps the commit history clean and readable.\nWhen you’re ready, push your changes to your remote fork. Make sure you’re in branch master and then run git push:\n$ git checkout master $ git push origin master You can keep any branch up to date using this method. If you’re working on a feature branch (see next section), which we recommend, you would change the command slightly, using the name of your feature-branch rather than master:\n$ git checkout feature-branch Switched to branch 'feature-branch' $ git rebase upstream/master $ git push origin feature-branch Work on a feature branch One way to keep your work organized is to create a branch for each issue or feature. You can and should create as many branches as you’d like.\nFirst, make sure your master branch is up-to-date with Neurocontainers upstream (see how).\nNext, from your master branch, create a new tracking branch, providing a descriptive name for your feature branch:\n$ git checkout master Switched to branch 'master' $ git checkout -b issue-1755-fail2ban Switched to a new branch 'issue-1755-fail2ban' Alternatively, you can create a new branch explicitly based off upstream/master:\n$ git checkout -b issue-1755-fail2ban upstream/master Switched to a new branch 'issue-1755-fail2ban' Now you’re ready to work on the issue or feature.\nStage changes Recall that files tracked with Git have three possible states: committed, modified, and staged.\nTo prepare a commit, first add the files with changes that you want to include in your commit to your staging area. You add both new files and existing ones. You can also remove files from staging when necessary.\nGet status of working directory To see which files in the working directory have changes that have not been staged, use git status.\nIf you have no changes in the working directory, you’ll see something like this:\n$ git status On branch issue-123 nothing to commit, working directory clean If you have unstaged changes, you’ll see something like this:\nOn branch issue-123 Untracked files: (use \"git add \u003cfile\u003e...\" to include in what will be committed) build.sh nothing added to commit but untracked files present (use \"git add\" to track) Stage additions with git add To add changes to your staging area, use git add \u003cfilename\u003e. Because git add is all about staging the changes you want to commit, you use it to add new files as well as files with changes to your staging area.\nContinuing our example from above, after we run git add build.sh, we’ll see the following from git status:\nOn branch issue-123 Changes to be committed: (use \"git reset HEAD \u003cfile\u003e...\" to unstage) new file: build.sh You can view the changes in files you have staged with git diff --cached. To view changes to files you haven’t yet staged, just use git diff.\nIf you want to add all changes in the working directory, use git add -A (documentation).\nYou can also stage changes using your Github GUI.\nIf you stage a file, you can undo it with git reset HEAD \u003cfilename\u003e. Here’s an example where we stage a file build.sh and then unstage it:\n$ git add build.sh On branch issue-1234 Changes to be committed: (use \"git reset HEAD \u003cfile\u003e...\" to unstage) new file: build.sh $ git reset HEAD build.sh $ git status On branch issue-1234 Untracked files: (use \"git add \u003cfile\u003e...\" to include in what will be committed) build.sh nothing added to commit but untracked files present (use \"git add\" to track) Stage deletions with git rm To remove existing files from your repository, use git rm (documentation). This command can either stage the file for removal from your repository AND delete it from your working directory or just stage the file for deletion and leave it in your working directory.\nTo stage a file for deletion and remove it from your working directory, use git rm \u003cfilename\u003e:\n$ git rm test.txt rm 'test.txt' $ git status On branch issue-1234 Changes to be committed: (use \"git reset HEAD \u003cfile\u003e...\" to unstage) deleted: test.txt $ ls test.txt ls: No such file or directory To stage a file for deletion and keep it in your working directory, use git rm --cached \u003cfilename\u003e:\n$ git rm --cached test2.txt rm 'test2.txt' $ git status On branch issue-1234 Changes to be committed: (use \"git reset HEAD \u003cfile\u003e...\" to unstage) deleted: test2.txt $ ls test2.txt test2.txt If you stage a file for deletion with the --cached option, and haven’t yet run git commit, you can undo it with git reset HEAD \u003cfilename\u003e:\n$ git reset HEAD test2.txt Unfortunately, you can’t restore a file deleted with git rm if you didn’t use the --cache option. However, git rm only deletes files it knows about. Files you have never added to Git won’t be deleted.\nCommit changes When you’ve staged all your changes, you’re ready to commit. You can do this with git commit -m \"My commit message.\" to include a commit message.\nHere’s an example of committing with the -m for a one-line commit message:\n$ git commit -m \"Add a test commit for docs.\" [issue-123 173e17a] Add a test commit for docs. 1 file changed, 1 insertion(+) create mode 100644 newfile.py You can also use git commit without the -m option and your editor to open, allowing you to easily draft a multi-line commit message.\nHow long your commit message should be depends on where you are in your work. Using short, one-line messages for commits related to in-progress work makes sense. For a commit that you intend to be final or that encompasses a significant amount or complex work, you should include a longer message.\nKeep in mind that your commit should contain a ‘minimal coherent idea’ and have a quality commit message.\nHere’s an example of a longer commit message that will be used for a pull request:\nAdd CIVET 2.1.1 container.  Edit build.sh and README.md to build container for CIVET 2.1.1  Tested on my local Ubuntu development server, but need to test within Neurodesktop.  Fixes #1755. The first line is the summary. The following paragraphs are full prose and explain why and how the change was made. It explains what testing was done and asks specifically for further testing. The final paragraph indicates that this commit addresses and fixes issue #1755. When you submit your pull request, GitHub will detect and link this reference to the appropriate issue. Once your commit is merged into upstream/master, GitHub will automatically close the referenced issue. See Closing issues via commit messages for details.\nNote in particular that GitHub’s regular expressions for this feature are sloppy, so phrases like Partially fixes #1234 will automatically close the issue. Phrases like Fixes part of #1234 are a good alternative.\nMake as many commits as you need to address the issue or implement your feature.\nPush your commits to GitHub As you’re working, it’s a good idea to frequently push your changes to GitHub. This ensures your work is backed up should something happen to your local machine and allows others to follow your progress. It also allows you to work from multiple computers without losing work.\nPushing to a feature branch is just like pushing to master:\n$ git push origin \u003cbranch-name\u003e Counting objects: 6, done. Delta compression using up to 4 threads. Compressing objects: 100% (4/4), done. Writing objects: 100% (6/6), 658 bytes | 0 bytes/s, done. Total 6 (delta 3), reused 0 (delta 0) remote: Resolving deltas: 100% (3/3), completed with 1 local objects. To git@github.com:christi3k/neurocontainers.git * [new branch] issue-demo -\u003e issue-demo If you want to see what Git will do without actually performing the push, add the -n (dry-run) option: git push -n origin \u003cbranch-name\u003e. If everything looks good, re-run the push command without -n.\nIf the feature branch does not already exist on GitHub, it will be created when you push and you’ll see * [new branch] in the command output.\nExamine and tidy your commit history Examining your commit history prior to submitting your pull request is a good idea. Will the person reviewing your commit history be able to clearly understand your progression of work?\nOn the command line, you can use the git log command to display an easy to read list of your commits:\n$ git log --all --graph --oneline --decorate * 4f8d75d (HEAD -\u003e 1754-docs-add-git-workflow) docs: Add details about configuring Travis CI. * bfb2433 (origin/1754-docs-add-git-workflow) docs: Add section for keeping fork up-to-date to Git Guide. * 4fe10f8 docs: Add sections for creating and configuring fork to Git Guide. * 985116b docs: Add graphic client recs to Git Guide. * 3c40103 docs: Add stubs for remaining Git Guide sections. * fc2c01e docs: Add git guide quickstart. | * f0eaee6 (upstream/master) bug: Fix traceback in get_missed_message_token_from_address(). Alternatively, use your graphical client to view the history for your feature branch.\nIf you need to update any of your commits, you can do so with an interactive rebase. Common reasons to use an interactive rebase include:\n squashing several commits into fewer commits splitting a single commit into two or more rewriting one or more commit messages  There is ample documentation on how to rebase, so we won’t go into details here. We recommend starting with GitHub’s help article on rebasing and then consulting Git’s documentation for git-rebase if you need more details.\nIf all you need to do is edit the commit message for your last commit, you can do that with git commit --amend. See Git Basics - Undoing Things for details on this and other useful commands.\nForce-push changes to GitHub after you’ve altered your history Any time you alter history for commits you have already pushed to GitHub, you’ll need to prefix the name of your branch with a +. Without this, your updates will be rejected with a message such as:\n$ git push origin 1754-docs-add-git-workflow To git@github.com:christi3k/neurocontainers.git ! [rejected] 1754-docs-add-git-workflow -\u003e 1754-docs-add-git-workflow (non-fast-forward) error: failed to push some refs to 'git@github.com:christi3k/neurocontainers.git' hint: Updates were rejected because the tip of your current branch is behind hint: its remote counterpart. Integrate the remote changes (e.g. hint: 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details. Re-running the command with +\u003cbranch\u003e allows the push to continue by re-writing the history for the remote repository:\n$ git push origin +1754-docs-add-git-workflow Counting objects: 12, done. Delta compression using up to 4 threads. Compressing objects: 100% (12/12), done. Writing objects: 100% (12/12), 3.71 KiB | 0 bytes/s, done. Total 12 (delta 8), reused 0 (delta 0) remote: Resolving deltas: 100% (8/8), completed with 2 local objects. To git@github.com:christi3k/neurocontainers.git + 2d49e2d...bfb2433 1754-docs-add-git-workflow -\u003e 1754-docs-add-git-workflow (forced update) This is perfectly okay to do on your own feature branches, especially if you’re the only one making changes to the branch. If others are working along with you, they might run into complications when they retrieve your changes because anyone who has based their changes off a branch you rebase will have to do a complicated rebase.\n","categories":"","description":"Contribution workflow using Git \n","excerpt":"Contribution workflow using Git \n","ref":"/neurodesk.github.io/developers/new_tools/workflow/","tags":"","title":"Using Git"},{"body":"Now that you’ve installed and launched neurodesktop, you should see a virtual desktop environment in your browser, which might look something like this:\nIn this linux desktop environment, you can access the menu, launch programs, write analysis code, use version control software (i.e. git) and develop analysis pipelines as though you were on your own computer.\nRelease Keep a note of the release date of the container image that you installed. Regardless of what operating system you installed neurodesktop into, the release date would have been at the end of the docker run command:\nWe regularly update neurodesktop to make sure it’s running well and has up-to-date software. You can check the Release History page for details of previous releases. If you’d like to update your container at any time, simply switch out the release number for the version you would like. If you’ve finished working on an analysis pipeline and would like to share it with others, you can point them toward the stable release number that you worked in. That way anyone, on any computer around the world can replicate your analysis pipeline in the exact same computing environment that you developed it in.\nVideo tutorial Click here to watch a 2 minute tutorial video from OHBM 2021\nHow to access files from your Host computer There are various ways of connecting your data to to Neurodesktop. For more information see our Storage section: Storage\nHow to launch applications Click on the Launcher icon in bottom-left corner, navigate to the “Neurodesk” menu and then to the relevant submenu (or “All Applications” for an alphabetical list of all applications). Navigate to the desired application, and then click on a menu entry. If it is the first time you launch an application, it may take a few seconds until it starts (please be patient!).\nIf you choose a menu entry with “GUI” at the end (e.g., fsleyesGUI 6.0.3), the main GUI interface of the application will open.\nIf you choose a menu entry without “GUI” at the end (e.g., fsl 6.0.3), a terminal window will open, and you can use it to run any of the utilities packaged with the application, including the graphical utilities (e.g., typing “fsl” to run FSL’s main menu). Please be patient when running a utility for the first time; Neurodesk is using a clever system that only downloads the utilities that you are actually using, but this may incur a short delay on the order of seconds. Also notice that the terminal that opens only allows to run utilities from the one application chosen in the menu. To be able to run utilities from multiple applications in the same terminal (or in the same script), please open a separate terminal by clicking on the terminal icon in the bottom toolbar of Neurodesktop. You will then be able to use the ‘module’ command in order to load the desired applications.\nHow top copy and paste text You can copy and paste text within Neurodesktop and between Neurodektop and your host computer using the regular keyboard shortcuts (CTRL+C, CTRL+X, and CTRL+V). Note however that some applications (e.g., command-line terminal) are using other keyboard shortcuts. You can usually find them in the “Edit” menu of the relevent application.\nNote for Mac Users: You will need to use a combination of CTRL and Command shortcuts in order to copy and paste text between Neurodesktop and the host computer. For example, copy text from your Mac with Command+C and then paste it into Neurodesktop using CTRL+V. For the other way around, you’d use CTRL+C in Neurodesktop and then Command+V on the Mac.\nHow to keep your modifications in the container We designed neurodesk with reproducibility as a main goal, so the desktop containers should not be modified if one aims for full reproducibility. However, there is one good option to keep your settings across different container versions: You can write a shell script that installs additional packages and modifies the environment so it’s perfect for you. This script can then be re-executed in a new desktop version and will enable a reprudcible customization.\nAnother option is to “save” your docker container including all changes you made. This could be useful when your changes are too difficult to write a shell script or when you do not care about reproducibilty as much and you just want to get the job done. To do this you can commit (https://docs.docker.com/engine/reference/commandline/commit/) your container and by uploading the container to your own docker hub you could even share it.\nHow to force a complete container download to your system To increase speed and reliability of Neurodesktop we mount the application containers from a CVMFS mount and download only the files required to run your current task. Although we aim to keep everything on there reproducible, there might be a reason that you want to fully download the containers to your system. You can force this behaviour by adding another parameter to the docker call: -e CVMFS_DISABLE=true\nFor windows an example would look like this:\ndocker run --shm-size=1gb -it --privileged --name neurodesktop -v C:/neurodesktop-storage:/neurodesktop-storage -e CVMFS_DISABLE=true -p 8080:8080 -h neurodesktop-20220701 vnmd/neurodesktop:20220701 ","categories":"","description":"Congratulations! You've installed Neurodesktop. What happens next?","excerpt":"Congratulations! You've installed Neurodesktop. What happens next?","ref":"/neurodesk.github.io/docs/neurodesktop/whats-next/","tags":"","title":"What's next?"},{"body":"WSL (w/ Ubuntu + LXDE) For more information on WSL: https://docs.microsoft.com/en-us/windows/wsl\nSetting up  Setup WSL2 using the following instructions (Ubuntu 18.04 recommended)\nhttps://docs.microsoft.com/en-us/windows/wsl/install-win10 Proceed until a Ubuntu bash shell is available from the Windows Host\nRun the remaining commands in the Bash shell sudo apt-get install lxde to install LXDE desktop in WSL Reboot sudo apt-get install xrdp to install XRDP in WSL Open /etc/xrdp/xrdp.ini Change port=3389 to port=3390 and save Run echo startlxde \u003e ~/.xsession  Running  sudo service xrdp start to start xrdp server Open Microsoft Remote Desktop Connection in Windows host Connect to localhost:3390 In the next login page, leave Session as Xorg. Enter your WSL username and password and click OK This should open an LXDE Linux Desktop environment. Follow Linux guide from here on  ","categories":"","description":"Install neurocommand on Windows\n","excerpt":"Install neurocommand on Windows\n","ref":"/neurodesk.github.io/docs/neurocommand/getting-started/windows/","tags":"","title":"Windows"},{"body":"The goal of neurodesk is to provide users with a large choice of tools to use in their pipelines. Use the guide below to add a tool to neurodesktop or neurocontainers.\nGuiding principles To decide if a tool should be packaged in a singularity container in neurocontainers or be installed in the neurodesktop container we are currently following these guiding principles:\n neurodesk is not a package manager. This means we are not distributing tools in containers that can easily be installed via a standard package manager neurodesk allows users to have multiple versions of tools in parallel via lmod, this means that if different versions of a tool can’t be installed in parallel we package the tool inside a container. neurodesk aims to provide tooling to link tools from different containers (such as workflow managers like nipype or nextflow). This means that if a tool is required to coordinate various container-tools, it should be in the neurodesktop container.  Examples:\n    easy install coordinates containers small in size latest version is ok useful to most users Conclusion     git yes yes yes yes yes neurodesktop   lmod no yes yes yes yes neurodesktop   nipype yes yes yes yes yes neurodesktop   vscode yes yes yes yes yes neurodesktop   itksnap yes no yes yes yes container?   convert3D yes no yes no no container   fsl no no no no no container   mrtrix no no no no no container   freesurfer no no no no no container    Adding new recipes Refer to neurodocker for more information on neurodocker recipes\nBuild container Environment Requirements  Docker Recent Python Version\nSearch for “python_requires” in https://github.com/NeuroDesk/neurodocker/blob/master/setup.cfg for minimal version of Python required. If you have several versions of Python installed in the environment, typing ‘python’ in the terminal should launch a version with equal or higher version number Python pip3\nThis should be launched by ‘python -m pip’ git  Install Neurodocker Neurodocker is the dependency we use to build containers.\n (optional) Sync upstream repository:\nIf you have the permissions to do so: Press “Fetch upstream” in https://github.com/NeuroDesk/neurodocker to check if our fork of Neurodocker is already up-to-date. Otherwise, open an issue in https://github.com/NeuroDesk/neurocontainers/issues, requesting to pull-in latest changes from Neurodocker upstream into our fork of Neurodocker. One of the admins will attend the issue and perform the operation. (optional) Add a new neurodocker tool:\nIf relevant to your project, add an option to neurodocker that installs new software (https://github.com/NeuroDesk/neurodocker) and create a pull request to neurodocker’s main responsitory (add new tool in a branch!). Clone our fork of Neurodocker: git clone https://github.com/NeuroDesk/neurodocker/  Install neurodocker: cd neurodocker python -m pip install . cd ..  Run: echo ’export PATH=${PATH}:${HOME}/.local/bin’ » ${HOME}/.bashrc Close the terminal, and reopen it for the updated PATH to take effect  Clone the Neurocontainers repository   Option A) Fork neurocontainers and setup github actions:\nFollow the steps in Get Neurodesk code.\n  Option B) Clone from NeuroDesk:\ngit clone https://github.com/NeuroDesk/neurocontainers/   Create a new app   Copy the directory template and rename to NEWAPP in neurocontainers/recipes (NEWAPP being the name of the application to be displayed in Neurodesk’s menu; notice it shouldn’t have any special characters):\ncd neurocontainers/recipes cp -R template NEWAPP   Create your Container Files:\nModify build.sh in neurocontainers/recipes/NEWAPP to build your application and update README.md (make sure the version is correct in the README!). Notice that the example build script in the template has instructions to build a conatiner for datalad, that may or may not suite your exact needs\ncd NEWAPP (edit build.sh as required) (edit README.md as required) Upload your application to object storage first if needed, so you can then download it in build.sh (ask for instructions about this if you don’t know the key, and never share it anywhere public!)\n  Run update-builders.sh: This will auto-create the CI workflow for the application (or manually duplicate the template file and rename all occurances of template to NEWAPP)\ncd ../.. sh update-builders.sh If the CI build runs out of space, add the application to the following txt file to add additional space: https://github.com/NeuroDesk/neurocontainers/blob/master/.github/workflows/free-up-space-list.txt. Note: this increases CI run time, only use in cases of out-of-space errors.    Build and test the container locally\n  run the build script with the debug flag:\ncd recipes/NEWAPP chmod +x build.sh ./build.sh -ds NOTICE: if the README.md file does not contain the same tool-version string as in the build.sh the build will not start to prevent an incorrect README.md description.\n  test running some commands within the container that should be available in your local docker container repository.\nFor example, to open an interactive shell in a container (with the home folder /root binded to /root on host), you may run:\nsudo docker run -it -v /root:/root --entrypoint /bin/bash NEWAPP_VERSION:TAG  with VERSION being the version of the app, and TAG the version tag of the container (run ‘sudo docker image list’ to find the tag)\n  if your application requires a Matlab Runtime and you get an error about shared library “libmwlaunchermain.so” not found, check which version of the runtime was installed by the build script\n    Update changes in local git repository\ngit add .github/workflows/NEWAPP.yml recipes/NEWAPP/test.sh recipes/NEWAPP/build.sh recipes/NEWAPP/README.md git config user.email \"the email that you use for github\" git config user.name \"your name\" git commit   Push the new app to Neurocontainers Prerequisite\nGenerate git personal access token (if you don’t have one already)\n Browse to https://github.com/ Log into your account Press on your picture in upper right corner –\u003e Setting –\u003e Developer Settings –\u003e Personal Access Token Press on “generate personal access token” Write something in “Notes” (doesn’t matter what, it’s for your own use) Check “repo” Check “Workflow” Press “Generate Token” at the bottom Copy the token displayed to somewhere safe, as you will have to user it later  Step by step guide\n  Test the container locally, and if successful push repo to trigger the automatic build on GitHub. When asked for your Github password, please provide the personal access token obtained in the previous stage.\ngit pull git push   Go to https://github.com/neurodesk/neurocontainers/actions. Check that the most recent workflow run in the list terminated successfully (green). Otherwise, click on it, click on “build docker”, and the line that caused the error will be highlighted\n  Find your new package under https://github.com/orgs/NeuroDesk/packages?repo_name=neurocontainers Enter the name of the package in the search box, and verify that the full package name shows up in the format toolName_toolVersion\n  Obtain buildDate by clicking on the full package name that came up in the search. The build date will be the newest date shown under Recent tagged image versions\n  Use toolName, toolVersion and buildDate from the previous two steps to manually download the package by typing the following in a terminal open in Neurodesktop\nbash /neurocommand/local/fetch_and_run.sh toolName toolVersion buildDate (when you see the \"Singularity\" prompt, type exit and ENTER) ml toolName/toolVersion For example: If the full package name that comes up in the step 11 is itksnap_3.8.0, and the newest date under Recent tagged image versions is 20210322\nThe command to use in a terminal open in Neurodesktop is:\nbash /neurocommand/local/fetch_and_run.sh itksnap 3.8.0 20210322 (when you see the \"Singularity\" prompt, type exit and ENTER) ml toolName/toolVersion   Depreciation notice For VNM users use:\nbash /neurodesk/local/fetch_and_run.sh toolName toolVersion buildDate ml toolName/toolVersion   Test the new container. Run some commands, to see all is good\nIf the container doesn’t work yet, it’s sometimes useful to try and troubleshoot it and install missing libraries. This can be achieved by running it in a writable mode with fakeroot enabled:\nSINGULARITY_BINDPATH=''; singularity shell --writable --fakeroot /neurodesktop-storage/containers/toolName_toolVersion_buildDate/toolName_toolVersion_buildDate.simg   Fork https://github.com/NeuroDesk/neurocommand/ to your Github account\n  Edit an entry for your package in your fork of neurocommand/blob/main/neurodesk/apps.json based on one of the other entries (generating one menu item for opening a terminal inside the containers, and one menu item for the GUI, if relevant). Notice that in the json file, the version field should contain the buildDate\n  Include an icon file in your fork of neurocommand/neurodesk/icons\n  Send a pull request from your fork of neurocommand to https://github.com/NeuroDesk/neurocommand/\n  When the pull request is merged by Neurodesk admins, it will trigger an action to build the singularity container, distribute it in all object storage locations and on CVMFS, and it will update the menus in the desktop image on the next daily build.\n  Wait at least 24 hours\n  Download and run the daily build of neurodesktop to check that your app can be launched from the start menu and works properly:\nsudo docker pull vnmd/neurodesktop:latest \u0026\u0026 sudo docker run --shm-size=1gb -it --privileged --name neurodesktop -v ~/neurodesktop-storage:/neurodesktop-storage -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\" -p 8080:8080 -h neurodesktop-latest vnmd/neurodesktop:latest   Open an issue in https://github.com/NeuroDesk/neurocontainers/issues notifying that your app appears in the start menu and tested. The app will be included in the next release of Neurodesktop, and will be mentioned in the public announcement that accompanies the release. If the app is not in the start menu or not working as expected based on your earlier testing, open an issue as well, and report it.\n  If somebody wants to use the application before the next release of Neurodesktop is out, you can instruct them to use the command in step 13 above instead of the deafult commands given in the user install instructions.\n  Consider contributing a tutorial about the new tool: https://github.com/NeuroDesk/neurodesk.github.io/tree/hugo-docsy/content/en/tutorials\n  ","categories":"","description":"Add a tool to neurodesktop\n","excerpt":"Add a tool to neurodesktop\n","ref":"/neurodesk.github.io/developers/new_tools/add_tool/","tags":"","title":"Add tools"},{"body":"","categories":"","description":"How to edit the documentation\n","excerpt":"How to edit the documentation\n","ref":"/neurodesk.github.io/developers/documentation/","tags":"","title":"Documentation"},{"body":"","categories":"","description":"The plug-and-play, browser-accessible, containerised data analysis environment.\n","excerpt":"The plug-and-play, browser-accessible, containerised data analysis …","ref":"/neurodesk.github.io/docs/neurodesktop/","tags":"","title":"Neurodesktop"},{"body":" Warning For development and testing only. Not recommended for production use  Building neurodesktop-dev Dev builds can be triggered by Neurodesk admins from https://github.com/NeuroDesk/neurodesktop/actions/workflows/build-neurodesktop-dev.yml\nRunning latest neurodesktop-dev Linux docker pull vnmd/neurodesktop-dev:latest sudo docker run \\ --shm-size=1gb -it --cap-add SYS_ADMIN \\ --security-opt apparmor:unconfined --device=/dev/fuse \\ --name neurodesktop-dev \\ -v ~/neurodesktop-storage:/neurodesktop-storage \\ -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\" \\ -p 8080:8080 -h neurodesktop-dev \\ vnmd/neurodesktop-dev:latest  Windows \" docker pull vnmd/neurodesktop-dev:latest docker run --shm-size=1gb -it --cap-add SYS_ADMIN --security-opt apparmor:unconfined --device=/dev/fuse --name neurodesktop -v C:/neurodesktop-storage:/neurodesktop-storage -p 8080:8080 -h neurodesktop-dev vnmd/neurodesktop-dev:latest  ","categories":"","description":"Testing the latest dev version of Neurodesktop\n","excerpt":"Testing the latest dev version of Neurodesktop\n","ref":"/neurodesk.github.io/developers/architecture/neurodesk-dev/","tags":"","title":"Neurodesktop Dev"},{"body":"Neurodesktop comes with the essential software required for neuroimaging data analysis pre-installed. Each release is built with the most recent version of these packages available at the build date. Some example packages include:\n Editors and Programming (can be found in menu, or launched from command line by typing their name):  code (Visual Studio Code) gedit (simple visual editor) emacs vim python git   Workflow systems:  Nipype (including GraphVis)   Data Syncronisation tools: (See our Storage section for more information: Storage)  Rsync Rclone https://rclone.org/ Nextcloud client Owncloud client Globus personal connect https://docs.globus.org/how-to/globus-connect-personal-linux/  installed in /opt/globusconnectpersonal/     System Management:  Lmod (inlcuding Lua) Singularity Htop   Misc  Imagemagic Firefox OpenSSH client    The neurodesktop environment is built to be light and fast to download and start-up. Most additional programs are therefore downloaded when they are first used. A list of these packages can be found here\n","categories":"","description":"The software available in neurodesktop","excerpt":"The software available in neurodesktop","ref":"/neurodesk.github.io/docs/neurodesktop/whatsinthebox/","tags":"","title":"What's in the box?"},{"body":"Minimum System Requirements  At least 3GB free space for neurodesktop base image Docker requirements. Details found under https://docs.docker.com/get-docker/ If installing docker using WSL, atleast 20GB space recommended for WSL with Ubuntu  Quickstart 1. Install Docker Install Docker from here: https://docs.docker.com/get-docker/ The docker installation will reboot your computer a few times and there might be warnings regardings WSL2 and this also might require a few more installation steps that unfortunatley differ for every system. Please get in touch if you are stuck and have a look at our troubleshoot page.  2. Run Neurodesktop Use one of the following options to run Neurodesktop:\nOption 1: NeuroDesktop.exe Download and run the following executable. Be aware: 1) The exe file can trigger your anti virus programs and we are working on this. 2) This exe will always download the latest version of neurodesk. For full reproducibility and control please choose Option 2 :) https://github.com/NeuroDesk/neurodesktop/raw/main/Windows_run_Neurodesk/NeuroDesktop.exe\nOption 2: Using Terminal  Open a terminal (e.g. Powershell), and type the folowing command to automatically download the neurodesktop container and run it  \" docker run --shm-size=1gb -it --privileged --name neurodesktop -v C:/neurodesktop-storage:/neurodesktop-storage -p 8080:8080 -h neurodesktop-20220701 vnmd/neurodesktop:20220701   Once neurodesktop is downloaded i.e. guacd[77]: INFO: Listening on host 127.0.0.1, port 4822 is displayed in terminal, leave the terminal open and neurodesktop running (i.e., do not press CTRL+C)\n  Open a browser and go to:\n  http://localhost:8080/#/?username=user\u0026password=password  Note We do not recommend the use of the Firefox browser for accessing Neurodesktop on Windows 10, as firefox is not able to access localhost where neurodesk is running.   Press on “Desktop Auto-Resolution” under “ALL CONNECTIONS”\n  If it is the first time you use Neruodesktop, wait until the desktop appears (it may take a few seconds). Otherwise, it should appear instantaneously.\n  Neurodesk is ready to use! Click “What’s next?” on the left of this page for further instructions.\n  For an optimal experience, switch your browser to full-screen mode by following the instructions for your browser here: https://www.thewindowsclub.com/open-chrome-edge-or-firefox-browser-in-full-screen-mode\n  The browser can be closed anytime, and Neurodesktop will continue running in the background. To reconnect to Neurodesktop, simply start over from step 3 above.  Deleting neurodesktop: When done processing your data it is important to stop and remove the container - otherwise the next start or container update will give an error (\"… The container name “/neurodesktop” is already in use…\")\nNote Notice that any data that were saved outside of /neurodesktop-storage would be lost. Please make sure to move all your data to that folder before deleting neurodesktop.    Click on the terminal from which you ran neurodesktop\n  Press control-C\n  Type:\n  docker stop neurodesktop Type:  docker rm neurodesktop Using an RDP Client Startup Neurodesktop using the following command:\n\" docker run --shm-size=1gb -it --privileged --name neurodesktop -v C:/neurodesktop-storage:/neurodesktop-storage -p 3390:3389 -p 8080:8080 -h neurodesktop-20220701 vnmd/neurodesktop:20220701  If you want to connect via RDP using a different port, replace 3390 in the previous and next step with your port  Open Windows Remote Desktop Connection and connect to Computer localhost:3390 as shown below.\nResolution and multi-monitor settings can be set from the Display tab.\nOnce ready, click Connect. This will take you to the following prompt\nUse the following details to login\nSession: Xorg username: user password: password Using VNC To enable VNC and disable RDP, startup Neurodesktop using the following command:\n\" docker run --shm-size=1gb -it --privileged --name neurodesktop -v C:/neurodesktop-storage:/neurodesktop-storage -e VNC_ENABLE=true -p 8080:8080 -h neurodesktop-20220701 vnmd/neurodesktop:20220701  VNC allows for multiple desktop connections to same instance\nNote: Neurodesktop VNC on the browser currently does not support auto-resolution\n Using a VNC Client Needs testing  Startup Neurodesktop using the following command:\n\" docker run --shm-size=1gb -it --privileged --name neurodesktop -v C:/neurodesktop-storage:/neurodesktop-storage -e VNC_ENABLE=true -p 5901:5901 -p 8080:8080 -h neurodesktop-20220701 vnmd/neurodesktop:20220701  Open a VNC Client and connect to port 5901\n","categories":"","description":"Install neurodesktop on Windows\n","excerpt":"Install neurodesktop on Windows\n","ref":"/neurodesk.github.io/docs/neurodesktop/getting-started/windows/","tags":"","title":"Windows"},{"body":"","categories":"","description":"Tutorials on contributing to the Neurodesk Documentation\n","excerpt":"Tutorials on contributing to the Neurodesk Documentation\n","ref":"/neurodesk.github.io/tutorials/documentation/","tags":"","title":"Documentation"},{"body":"Fixing the last commit Changing the last commit message  git commit --amend -m \"New message\"  Changing the last commit  Make your changes to the files Run git add \u003cfilename\u003e to add one file or git add \u003cfilename1\u003e \u003cfilename2\u003e ... to add multiple files git commit --amend  Fixing older commits Changing commit messages  git rebase -i HEAD~5 (if, for example, you are editing some of the last five commits) For each commit that you want to change the message, change pick to reword, and save Change the commit messages  Deleting old commits  git rebase -i HEAD~n where n is the number of commits you are looking at For each commit that you want to delete, change pick to drop, and save  Squashing commits Sometimes, you want to make one commit out of a bunch of commits. To do this,\n git rebase -i HEAD~n where n is the number of commits you are interested in Change pick to squash on the lines containing the commits you want to squash and save  Reordering commits  git rebase -i HEAD~n where n is the number of commits you are interested in Reorder the lines containing the commits and save  Pushing commits after tidying them  git push origin +my-feature-branch (Note the + there and substitute your actual branch name.)  ","categories":"","description":"Fix commit\n","excerpt":"Fix commit\n","ref":"/neurodesk.github.io/developers/new_tools/fix_commit/","tags":"","title":"Fix commit"},{"body":"","categories":"","description":"How to add new tools to neurodesk\n","excerpt":"How to add new tools to neurodesk\n","ref":"/neurodesk.github.io/developers/new_tools/","tags":"","title":"How to add new tools"},{"body":"One way of running this project on HPCs is via https://www.neurodesk.org/docs/neurocommand/getting-started/linux/\n","categories":"","description":"Run neurodesktop in a high performance computing environment\n","excerpt":"Run neurodesktop in a high performance computing environment\n","ref":"/neurodesk.github.io/docs/neurodesktop/getting-started/hpc/","tags":"","title":"HPC"},{"body":"This option is only available to Australian researchers.\nGo to https://desktop.rc.nectar.org.au/\nClick on “Sign in”.\nChoose the AAF option.\nChoose your instituion from the list.\nProvide your email address and password.\nClick on “EXPLORE”.\nClick “VIEW DETAILS” under Neurodesktop: Click “CREATE DESKTOP +” button on the top right corner.\nChoose the desired availability zone.\nWait until everything is completed: Click “OPEN DESKTOP -\u003e”: To launch the various applications available in Neurodesktop, follow the instructions here: https://www.neurodesk.org/docs/neurodesktop/whats-next/#how-to-launch-applications\nGood luck!\n","categories":"","description":"Run neurodesktop in the Nectar Virtual Desktop Service\n","excerpt":"Run neurodesktop in the Nectar Virtual Desktop Service\n","ref":"/neurodesk.github.io/docs/neurodesktop/getting-started/nectar/","tags":"","title":"Nectar Virtual Desktop Service"},{"body":"Neurocommand requires a Linux host machine, virtual machine or WSL for Windows.\n","categories":"","description":"For more advanced users who prefer a command-line interface\n","excerpt":"For more advanced users who prefer a command-line interface\n","ref":"/neurodesk.github.io/docs/neurocommand/","tags":"","title":"Neurocommand"},{"body":"Drag and Drop support You can drag-and-drop files into the browser window to get files into the Neurodesktop. This will then start a file upload:\nTo download files from the desktop using the same mechanism you need to open the guacamole settings by pressing CTRL-ALT-SHIFT (Control-Command-Shift on Mac). This will open a menu on the side:\nwhere you can click on “Shared Drive”:\nand a click (or double clink on Mac) on the file will start the download.\nYou can browse into folders in the shared drive by clicking (double clicking on Mac) on them. To get back to the base of the shared drive, press on the drive icon in the top left of the side menu (just below the “Shared Drive” title).\nTo close the side menu, click on CTRL-ALT-SHIFT once more (Control-Command-Shift on Mac).\nData directory connection to the host computer If you are running Neurodesktop on your own hardware there will be a direct connection between the “Storage” folder on the Destkop, which is a link to “/neurodesktop-storage” and a “neurodesktop-storage” folder on your C-drive (Windows) or home directory (Mac/Linux). This connection can be used for data processing and data transfer.\nMounting external storage on your host-computer The -v C:/neurodesktop-storage:/neurodesktop-storage part of the docker command links the directory “neurodesktop-storage” on the “C drive” of your Windows computer to the directory /neurodesktop-storage inside the Desktop environment. Everything you store in there will be available inside the desktop and on the host computer. You can also mount additional directories by adding another -v parameter set (e.g. -v D:/moredata:/data) - this will mount the directory moredata from your D drive to /data inside neurodesktop. Improtant: the mountpoint inside neurodesktop should be named /data (or anything from this list: https://github.com/NeuroDesk/neurocontainers/blob/master/recipes/globalMountPointList.txt) - otherwise most of the tools will not be able to access the data.\nHere is an example for Windows adding another storage directory:\n\" docker run --shm-size=1gb -it --privileged --name neurodesktop -v C:/neurodesktop-storage:/neurodesktop-storage -v D:/moredata:/data -p 8080:8080 -h neurodesktop-20220701 vnmd/neurodesktop:20220701  Cloud-storage Another way to get your data into Neurodesktop is to use a cloud storage provider like CloudStor, Dropbox, OneDrive and their sync tools like OwnCloud, Nextcloud or very flexible tools like rclone or davfs2. Another good option could be to utilize Globus for large amounts of data.\nNextcloud and Owncloud desktop clients Under the menu item “Accessories” you can find “Nextcloud” and “ownCloud” desktop sync clients that you can configure with your cloud service accounts.\nTo connect for example to your AARNET cloudstor account you can start the ownCloud client and enter the Server Address:\nhttps://cloudstor.aarnet.edu.au/plus/ Then generate an app-password here: https://cloudstor.aarnet.edu.au/plus/settings/personal?sectionid=security\nMounting webdav storage using davfs2 Another option is to directly mount webdav storage. Here is an example how to mount CloudStor into Neurodesktop:\nsudo mount -t davfs https://cloudstor.aarnet.edu.au/plus/remote.php/webdav/ /data/ It then asks you for a username and password, which you can generate here: https://cloudstor.aarnet.edu.au/plus/settings/personal?sectionid=security\nRclone Rclone is a command line tool that enables the interaction with various cloud services. Here is an example how to setup rclone with CloudStor Aarnet:\n start the configuration in a terminal window rclone config Create a new remote: n Provide a name for the remote: CloudStor For the “Storage” option choose: webdav As “url” set: https://cloudstor.aarnet.edu.au/plus/remote.php/webdav/ As “vendor” set OwnCloud: 2 Set your CloudStor username after generating an access token https://cloudstor.aarnet.edu.au/plus/settings/personal?sectionid=security Choose to type in your own password: y Enter the Password / Token from the CloudStor App passwords page and confirm it again: Leave blank the bearer_token: \u003chit Enter\u003e No advanced config necessary: \u003chit Enter\u003e accept the configuration: \u003chit Enter\u003e Quit the config: q Now we can download data to the HPC easily: rclone copy --progress --transfers 8 CloudStor:/raw-data-for-science-paper . or upload data to CloudStor: rclone copy --progress --transfers 8 . CloudStor:/data-processed  Globus We also provide the globus client, so you can transfer large amounts of data between globus endpoints and Neurodesktop. You can configure it by running:\n/opt/globusconnectpersonal/globusconnectpersonal-*/globusconnectpersonal Once authenticated you can go to the globus file-manager https://app.globus.org/file-manager and your neurodesktop instance will be an endpoint for globus.\nMount volume using SSHFS It is theoretically possible to mount an SSH target inside Neurodesktop, but it’s not a very reliable way of mounting storage:\nsshfs -o allow_root USER@TARGET_HOST:TARGET_PATH SOURCE_PATH A better option is to use scp and copy data from an SSH endpoint:\nscp /neurodesk/myfile user@remoteserver:/data/ An alternative is to mount the SSHFS target into a parent directory on your local machine or VM and then use the -v option in the docker run command to bind the parent directory of the SSHFS mount. NOTE: the SSHFS has to be mounted to a subdirectory inside a parent directory which is then bound to the docker container. If you directly bind to the mounted directory itself, your Neurodesktop container will stop being able to access it if the SSHFS mount disconnects and will not be able to access it again without restarting the Neurodesktop container.\nFor example, on a local Linux machine or VM:\nsshfs -o allow_root USER@TARGET_HOST:TARGET_PATH/MyData SOURCE_PATH/SSHFS_Mounts/MyData Then add the following line to the docker run command when starting Neurodesktop (note the rshared flag):\n-v /SSHFS_Mounts:/data:rshared \\ TIP: If you use key pair authentication instead of password for your SSHFS mount, you can use the reconnect flag to reconnect automatically if the connection drops:\nsshfs -o IdentityFile=~/.ssh/id_rsa,allow_root,ServerAliveInterval=5,ServerAliveCountMax=3 USER@TARGET_HOST:TARGET_PATH/MyData SOURCE_PATH/SSHFS_Mounts/MyData ","categories":"","description":"Add storage to Neurodesktop\n","excerpt":"Add storage to Neurodesktop\n","ref":"/neurodesk.github.io/docs/neurodesktop/storage/","tags":"","title":"Storage"},{"body":"Following guide is for connecting to a Neurodesktop using a VS Code installation running on your host machine.\n Additional instructions if your Neurodesktop is running remotely (i.e. Cloud, HPC, VM)\n Pre-requisites Visual Studio Code (https://code.visualstudio.com) installed on your host. Standalone version should work fine\nInstall the following VS Code extensions:\n Docker extension (Required) Remote development extension pack. Includes the following extensions  Remote - Containers (Required) Remote - SSH (For remote servers) Remote - WSL (For windows hosts)    For Remote servers Open VS Code\nOpen the Command Palette (Ctrl+Shift+P)\nFind Remote-SSH: Connect to Host... and select your remote host\n More information on remote hosts available at https://code.visualstudio.com/docs/remote/ssh\n This will open a new VS Code instance connected to the remote host via SSH. You may close the previous VS Code instance.\nFollow the steps in the next section using the new VS Code instance\nConnecting to Neurodesktop Open VS Code and open a Folder (File \u003e Open Folder)\n This can be any folder (e.g. home or project folder). VS Code runs into errors if no folder is opened.\n Open the Command Palette (Ctrl+Shift+P).\nSelect Remote-Containers: Attach to Running Container from the dropdown panel\nStart typing in ’neurodesktop. Select /neurodesktop from the list\nThis should open a VS Code Window connected to the neurodesktop as a Dev Container.\n First time connection will take about a minute, as VS code has to install the VS Code server onto the container. Repeat connections should be faster\n First time connection  First time connection will default to using neurodesktop root user. We want to default connection to be as the normal user to avoid permission issues. To check which user is being use, open the terminal in the neurodesktop VS Code and check if the user is user or root\n Follow the following steps to configure your VS Code to connect to neurodesktop as normal user by default\nOpen the Command Palette (Ctrl+Shift+P).\nSelect Remote-Containers: Open Container Configuration File from the dropdown panel\nThis will open a neurodesktop%3alatest.json file. Overwrite the file with the following contents\n{ \"workspaceFolder\": \"/home/user\", \"remoteUser\": \"user\" }  Close this VS Code window. Use steps in previous section to connect normally\nUseful Additions A plugin to view neuroimaging data inside VScode is also available: ","categories":"","description":"Guide connecting your VS Code environment to Neurodesktop","excerpt":"Guide connecting your VS Code environment to Neurodesktop","ref":"/neurodesk.github.io/docs/neurodesktop/getting-started/visual-studio-code/","tags":"","title":"Visual Studio Code"},{"body":"Minimum System Requirements  At least 3GB free space for neurodesktop base image Docker requirements. Details found under https://docs.docker.com/get-docker/  Quickstart 1. Connect to cloud server On the computer from which you want to access Neurodesktop, open an SSH connection to your cloud instance with port forwarding (USER should be substituted with a username that has admin privileges on the cloud instance, and IP should be substituted with the IP address of the cloud instance)\nssh -L 8080:127.0.0.1:8080 USER@IP 2. Install Docker Install Docker on the cloud instance from here: https://docs.docker.com/get-docker/. Additional information available here: https://www.neurodesk.org/docs/neurodesktop/getting-started/linux/#installing-docker\n3. Run Neurodesktop Create a local folder ~/neurodesktop-storage on the cloud instance to store persistent data (data that will not disappear if neurodesktop is stopped)\nOption 1: NeuroDesktop.run Download and run the following executable on the cloud instance https://github.com/NeuroDesk/neurodesktop/raw/main/Linux_run_Neurodesk/NeuroDesktop.run\nOption 2: Using Terminal  Open a terminal on the cloud instance, and type the folowing command to automatically download the neurodesktop container and run it  sudo docker run \\ --shm-size=1gb -it --privileged --name neurodesktop \\ -v ~/neurodesktop-storage:/neurodesktop-storage \\ -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\"\\ -p 8080:8080 \\ -h neurodesktop-20220701 vnmd/neurodesktop:20220701 If you get errors in neurodesktop then check if the ~/neurodesktop-storage directory is writable to all users, otherwise run chmod a+rwx ~/neurodesktop-storage  Once neurodesktop is downloaded to the cloud instance (guacd[77]: INFO: Listening on host 127.0.0.1, port 4822 is displayed in terminal), leave the terminal open and neurodesktop running (i.e., do not press CTRL+C)  Even if your connection to the cloud instance is broken, and the terminal does not respond anymore, Neurodesktop will still continue running on the cloud insance. When the connection to the cloud instance is re-established, please start over the instructions from step 3 below.   If it is required to set up an SSH tunnel to access the cloud instance, please set up such a tunnel from the computer from which you want to access Neurodesktop (e.g. ssh -L 8080:127.0.0.1:8080 USER@IP)\n  Open a browser on the computer from which you want to access Neurodesktop, and go to:\n  http://localhost:8080/#/?username=user\u0026password=password If the computer runs Linux, check specific instructions at https://www.neurodesk.org/docs/neurodesktop/getting-started/linux/, Option 2, Step 3.\n Press on “Desktop Auto-Resolution” under “ALL CONNECTIONS”\n  If it is the first time you use Neruodesktop, wait until the desktop appears (it may take a few seconds). Otherwise, it should appear instantaneously.\n  Neurodesk is ready to use! Click “What’s next?” on the left of this page for further instructions.\n  For an optimal experience, switch your browser to full-screen mode by following the instructions for your browser here (except Mac where full-screen mode is built-in): https://www.thewindowsclub.com/open-chrome-edge-or-firefox-browser-in-full-screen-mode\n  The browser can be closed anytime, and Neurodesktop will continue running on the cloud instance. To reconnect to Neurodesktop, simply start over from step 4 above.  If your computer hibernates/reboots/etc. or if the network connnection has been temporarily lost, Neurodesktop still continues running on the cloud instance. To reconnect to Neurodesktop, start over from step 3 above.  If you want to connect to the same instance of Neurodesktop from another computer, close the browser in the current computer, and start over from step 3 on the other computer (note that only one computer can access Neurodesktop at a time using the default RDP protocol; for access from multiple computers simultaneously, please re-run Neurodesktop with VNC enabled as explained further below).  Deleting neurodesktop: When done processing your data it is important to stop and remove the container - otherwise the next start or container update will give an error (\"… The container name “/neurodesktop” is already in use…\")\nNote Notice that any data that were saved outside of /neurodesktop-storage would be lost. Please make sure to move all your data to that folder before deleting neurodesktop.    Click on the terminal from which you ran neurodesktop\n  Press Ctrl-C\n  Run:\n  sudo docker stop neurodesktop \u0026\u0026 sudo docker rm neurodesktop  Portforwarding to an iOS ipad You can also connect to this cloud instance from your iOS device :) For this install https://webssh.net/documentation/help/networking/port-forwarding/ and create a tunnel (the tool is free for one connection). Start the docker container in a screen session and then connect to it from your ios device in the browser.\nCloud-provider specific Tutorials    Cloud provider link     Oracle https://mri.sbollmann.net/index.php/2020/12/08/run-neurodesk-on-oracle-cloud-free-tier/   Azure https://henryjburg.medium.com/neurodesk-running-on-azure-3e38c590a152    Using an RDP Client Open an SSH connection to your cloud instance with the following command\nssh -L 3390:127.0.0.1:3390 USER@IP Startup Neurodesktop using the following command:\nsudo docker run \\ --shm-size=1gb -it --privileged --name neurodesktop \\ -v ~/neurodesktop-storage:/neurodesktop-storage \\ -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\"\\ -p 8080:8080 -p 3390:3389 \\ -h neurodesktop-20220701 vnmd/neurodesktop:20220701 If you want to connect via RDP using a different port, replace 3390 in the previous two steps and next step with your port  Open your RDP client and connect to Computer localhost:3390\nUse the following details to login if prompted\nusername: user password: password Using VNC To enable VNC and disable RDP, startup Neurodesktop using the following command:\nsudo docker run \\ --shm-size=1gb -it --privileged --name neurodesktop \\ -v ~/neurodesktop-storage:/neurodesktop-storage \\ -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\"\\ -p 8080:8080 \\ -h neurodesktop-20220701 vnmd/neurodesktop:20220701 --vnc To enable both VNC and RDP, startup Neurodesktop using the following command:\nsudo docker run \\ --shm-size=1gb -it --privileged --name neurodesktop \\ -v ~/neurodesktop-storage:/neurodesktop-storage \\ -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\"\\ -p 8080:8080 \\ -h neurodesktop-20220701 vnmd/neurodesktop:20220701 --vnc --rdp VNC allows for multiple desktop connections to same instance\nNote: Neurodesktop VNC on the browser currently does not support auto-resolution\n Using a VNC Client Needs testing  Startup Neurodesktop using the following command:\nsudo docker run \\ --shm-size=1gb -it --privileged --name neurodesktop \\ -v ~/neurodesktop-storage:/neurodesktop-storage \\ -e HOST_UID=\"$(id -u)\" -e HOST_GID=\"$(id -g)\"\\ -p 8080:8080 -p 5901:5901 \\ -h neurodesktop-20220701 vnmd/neurodesktop:20220701 --vnc Open a VNC Client and connect to port 5901\n","categories":"","description":"Run neurodesktop using Oracle or Azure cloud computing\n","excerpt":"Run neurodesktop using Oracle or Azure cloud computing\n","ref":"/neurodesk.github.io/docs/neurodesktop/getting-started/cloud/","tags":"","title":"Cloud"},{"body":"Create a pull request When you’re ready for feedback, submit a pull request. Pull requests are a feature specific to GitHub. They provide a simple, web-based way to submit your work (often called “patches”) to a project. It’s called a pull request because you’re asking the project to pull changes from your fork.\nIf you’re unfamiliar with how to create a pull request, you can check out GitHub’s documentation on creating a pull request from a fork. You might also find GitHub’s article about pull requests helpful. That all said, the tutorial below will walk you through the process.\nCreate a pull request Step 0: Make sure you’re on a feature branch (not master) It is important to work on feature branch when creating a pull request. Your new pull request will be inextricably linked with your branch while it is open, so you will need to reserve your branch only for changes related to your issue, and avoid introducing extraneous changes for other issues or from upstream.\nIf you are working on a branch named master, you need to create and switch to a feature branch before proceeding.\nStep 1: Update your branch with git rebase The best way to update your branch is with git fetch and git rebase. Do not use git pull or git merge as this will create merge commits. See keep your fork up to date for details.\nHere’s an example (you would replace issue-123 with the name of your feature branch):\n$ git checkout issue-123 Switched to branch 'issue-123' $ git fetch upstream remote: Counting objects: 69, done. remote: Compressing objects: 100% (23/23), done. remote: Total 69 (delta 49), reused 39 (delta 39), pack-reused 7 Unpacking objects: 100% (69/69), done. From https://github.com/NeuroDesk/neurocontainers/ 69fa600..43e21f6 master -\u003e upstream/master $ git rebase upstream/master First, rewinding head to replay your work on top of it... Applying: troubleshooting tip about provisioning Step 2: Push your updated branch to your remote fork Once you’ve updated your local feature branch, push the changes to GitHub:\n$ git push origin issue-123 Counting objects: 6, done. Delta compression using up to 4 threads. Compressing objects: 100% (4/4), done. Writing objects: 100% (6/6), 658 bytes | 0 bytes/s, done. Total 6 (delta 3), reused 0 (delta 0) remote: Resolving deltas: 100% (3/3), completed with 1 local objects. To git@github.com:christi3k/neurocontainers.git + 2d49e2d...bfb2433 issue-123 -\u003e issue-123 If your push is rejected with error failed to push some refs then you need to prefix the name of your branch with a +:\n$ git push origin +issue-123 Counting objects: 6, done. Delta compression using up to 4 threads. Compressing objects: 100% (4/4), done. Writing objects: 100% (6/6), 658 bytes | 0 bytes/s, done. Total 6 (delta 3), reused 0 (delta 0) remote: Resolving deltas: 100% (3/3), completed with 1 local objects. To git@github.com:christi3k/neurocontainers.git + 2d49e2d...bfb2433 issue-123 -\u003e issue-123 (forced update) This is perfectly okay to do on your own feature branches, especially if you’re the only one making changes to the branch. If others are working along with you, they might run into complications when they retrieve your changes because anyone who has based their changes off a branch you rebase will have to do a complicated rebase.\nStep 3: Open the pull request If you’ve never created a pull request or need a refresher, take a look at GitHub’s article creating a pull request from a fork. Note: Pull request titles are different from commit messages. Commit messages can be edited with git commit --amend, git rebase -i, etc., while the title of a pull request can only be edited via GitHub.\nUpdate a pull request As you make progress on your feature or bugfix, your pull request, once submitted, will be updated each time you push commits to your remote branch. This means you can keep your pull request open as long as you need, rather than closing and opening new ones for the same feature or bugfix.\nIt’s a good idea to keep your pull request mergeable with neurocontainer upstream by frequently fetching, rebasing, and pushing changes. See keep your fork up to date for details. You might also find this excellent article How to Rebase a Pull Request helpful.\nAnd, as you address review comments others have made, we recommend posting a follow-up comment in which you: a) ask for any clarifications you need, b) explain to the reviewer how you solved any problems they mentioned, and c) ask for another review.\n","categories":"","description":"Pull request and make contribution\n","excerpt":"Pull request and make contribution\n","ref":"/neurodesk.github.io/developers/new_tools/pull_request/","tags":"","title":"Create a pull request"},{"body":"","categories":"","description":"What neurocontainers are about\n","excerpt":"What neurocontainers are about\n","ref":"/neurodesk.github.io/docs/neurocontainers/","tags":"","title":"Neurocontainers"},{"body":"Transparent singularity is here https://github.com/NeuroDesk/transparent-singularity/\nThis project allows to use singularity containers transparently on HPCs, so that an application inside the container can be used without adjusting any scripts or pipelines (e.g. nipype).\nImportant: add bind points to .bashrc before executing this script This script expects that you have adjusted the Singularity Bindpoints in your .bashrc, e.g.:\nexport SINGULARITY_BINDPATH=\"/gpfs1/,/QRISdata,/data\" This gives you a list of all tested images available in neurodesk: https://github.com/NeuroDesk/neurodesk/blob/master/cvmfs/log.txt\ncurl -s https://raw.githubusercontent.com/NeuroDesk/neurodesk/master/cvmfs/log.txt Clone repo into a folder with the intented image name git clone https://github.com/NeuroDesk/transparent-singularity convert3d_1.0.0_20210104 Install This will create scripts for every binary in the container located in the $DEPLOY_PATH inside the container. It will also create activate and deactivate scripts and module files for lmod (https://lmod.readthedocs.io/en/latest/)\ncd convert3d_1.0.0_20210104 ./run_transparent_singularity.sh convert3d_1.0.0_20210104 Options for Transparent singularity:  --storage - this option can be used to force a download from docker, e.g.: --storage docker --container - this option can be used to explicitly define the container name to be downloaded --unpack - this will unpack the singularity container so it can be used on systems that do not allow to open simg / sif files for security reasons, e.g.: --unpack true --singularity-opts - this will be passed on to the singularity call, e.g.: --singularity-opts '--bind /cvmfs'  Use in module system LMOD Add the module folder path to $MODULEPATH\nManual activation and deactivation (in case module system is not available). This will add the paths to the .bashrc Activate source activate_convert3d_1.0.0_20210104.sh Deactivate source deactivate_convert3d_1.0.0_20210104.sif.sh Uninstall container and cleanup ./ts_uninstall.sh ","categories":"","description":"For more advanced users who wish to use Transparent Singularity directly\n","excerpt":"For more advanced users who wish to use Transparent Singularity …","ref":"/neurodesk.github.io/developers/transparent_singularity/","tags":"","title":"Transparent Singularity"},{"body":"","categories":"","description":"How to interact with our CVMFS service.\n","excerpt":"How to interact with our CVMFS service.\n","ref":"/neurodesk.github.io/developers/cvmfs/","tags":"","title":"Neurodesk CVMFS"},{"body":"Undo a merge commit A merge commit is a special type of commit that has two parent commits. It’s created by Git when you merge one branch into another and the last commit on your current branch is not a direct ancestor of the branch you are trying to merge in. This happens quite often in a busy project like NeuroDesk where there are many contributors because upstream/neurocontainer will have new commits while you’re working on a feature or bugfix. In order for Git to merge your changes and the changes that have occurred on neurocontainer/upstream since you first started your work, it must perform a three-way merge and create a merge commit.\nneurocontainer uses a forked-repo, rebase-oriented workflow.\nA merge commit is usually created when you’ve run git pull or git merge. You’ll know you’re creating a merge commit if you’re prompted for a commit message and the default is something like this:\nMerge branch 'master' of https://github.com/NeuroDesk/neurocontainer  # Please enter a commit message to explain why this merge is necessary, # especially if it merges an updated upstream into a topic branch. # # Lines starting with '#' will be ignored, and an empty message aborts # the commit. And the first entry for git log will show something like:\ncommit e5f8211a565a5a5448b93e98ed56415255546f94 Merge: 13bea0e e0c10ed Author: Christie Koehler \u003cck@christi3k.net\u003e Date: Mon Oct 10 13:25:51 2016 -0700 Merge branch 'master' of https://github.com/NeuroDesk/neurocontainer Some graphical Git clients may also create merge commits.\nTo undo a merge commit, first run git reflog to identify the commit you want to roll back to:\n$ git reflog e5f8211 HEAD@{0}: pull upstream master: Merge made by the 'recursive' strategy. 13bea0e HEAD@{1}: commit: test commit for docs. Reflog output will be long. The most recent Git refs will be listed at the top. In the example above e5f8211 HEAD@{0}: is the merge commit made automatically by git pull and 13bea0e HEAD@{1}: is the last commit I made before running git pull, the commit that I want to rollback to.\nOnce you’d identified the ref you want to revert to, you can do so with git reset:\n$ git reset --hard 13bea0e HEAD is now at 13bea0e test commit for docs. :::{important} git reset --hard \u003ccommit\u003e will discard all changes in your working directory and index since the commit you’re resetting to with \u003ccommit\u003e. This is the main way you can lose work in Git. If you need to keep any changes that are in your working directory or that you have committed, use git reset --merge \u003ccommit\u003e instead. :::\nYou can also use the relative reflog HEAD@{1} instead of the commit hash, just keep in mind that this changes as you run Git commands.\nNow when you look at the output of git reflog, you should see that the tip of your branch points to your last commit 13bea0e before the merge:\n$ git reflog 13bea0e HEAD@{2}: reset: moving to HEAD@{1} e5f8211 HEAD@{3}: pull upstream master: Merge made by the 'recursive' strategy. 13bea0e HEAD@{4}: commit: test commit for docs. And the first entry git log shows is this:\ncommit 13bea0e40197b1670e927a9eb05aaf50df9e8277 Author: Christie Koehler \u003cck@christi3k.net\u003e Date: Mon Oct 10 13:25:38 2016 -0700 test commit for docs. Restore a lost commit We’ve mentioned you can use git reset --hard to rollback to a previous commit. What if you run git reset --hard and then realize you actually need one or more of the commits you just discarded? No problem, you can restore them with git cherry-pick (docs).\nFor example, let’s say you just committed “some work” and your git log looks like this:\n* 67aea58 (HEAD -\u003e master) some work * 13bea0e test commit for docs. You then mistakenly run git reset --hard 13bea0e:\n$ git reset --hard 13bea0e HEAD is now at 13bea0e test commit for docs. $ git log * 13bea0e (HEAD -\u003e master) test commit for docs. And then realize you actually needed to keep commit 67aea58. First, use git reflog to confirm that commit you want to restore and then run git cherry-pick \u003ccommit\u003e:\n$ git reflog 13bea0e HEAD@{0}: reset: moving to 13bea0e 67aea58 HEAD@{1}: commit: some work $ git cherry-pick 67aea58 [master 67aea58] some work Date: Thu Oct 13 11:51:19 2016 -0700 1 file changed, 1 insertion(+) create mode 100644 test4.txt Recover from a git rebase failure One situation in which git rebase will fail and require you to intervene is when your change, which Git will try to re-apply on top of new commits from which ever branch you are rebasing on top of, is to code that has been changed by those new commits.\nFor example, while I’m working on a file, another contributor makes a change to that file, submits a pull request and has their code merged into master. Usually this is not a problem, but in this case the other contributor made a change to a part of the file I also want to change. When I try to bring my branch up to date with git fetch and then git rebase upstream/master, I see the following:\nFirst, rewinding head to replay your work on top of it... Applying: test change for docs Using index info to reconstruct a base tree... M README.md Falling back to patching base and 3-way merge... Auto-merging README.md CONFLICT (content): Merge conflict in README.md error: Failed to merge in the changes. Patch failed at 0001 test change for docs The copy of the patch that failed is found in: .git/rebase-apply/patch When you have resolved this problem, run \"git rebase --continue\". If you prefer to skip this patch, run \"git rebase --skip\" instead. To check out the original branch and stop rebasing, run \"git rebase --abort\". This message tells me that Git was not able to apply my changes to README.md after bringing in the new commits from upstream/master.\nRunning git status also gives me some information:\nrebase in progress; onto 5ae56e6 You are currently rebasing branch 'docs-test' on '5ae56e6'. (fix conflicts and then run \"git rebase --continue\") (use \"git rebase --skip\" to skip this patch) (use \"git rebase --abort\" to check out the original branch) Unmerged paths: (use \"git reset HEAD \u003cfile\u003e...\" to unstage) (use \"git add \u003cfile\u003e...\" to mark resolution) both modified: README.md no changes added to commit (use \"git add\" and/or \"git commit -a\") To fix, open all the files with conflicts in your editor and decide which edits should be applied. Git uses standard conflict-resolution (\u003c\u003c\u003c\u003c\u003c\u003c\u003c, =======, and \u003e\u003e\u003e\u003e\u003e\u003e\u003e) markers to indicate where in files there are conflicts.\nTip: You can see recent changes made to a file by running the following commands:\ngit fetch upstream git log -p upstream/master -- /path/to/file You can use this to compare the changes that you have made to a file with the ones in upstream, helping you avoid undoing changes from a previous commit when you are rebasing.\nOnce you’ve done that, save the file(s), stage them with git add and then continue the rebase with git rebase --continue:\n$ git add README.md $ git rebase --continue Applying: test change for docs For help resolving merge conflicts, see basic merge conflicts, advanced merging, and/or GitHub’s help on how to resolve a merge conflict.\nWorking from multiple computers Working from multiple computers with neurocontainer and Git is fine, but you’ll need to pay attention and do a bit of work to ensure all of your work is readily available.\nRecall that most Git operations are local. When you commit your changes with git commit they are safely stored in your local Git database only. That is, until you push the commits to GitHub, they are only available on the computer where you committed them.\nSo, before you stop working for the day, or before you switch computers, push all of your commits to GitHub with git push:\n$ git push origin \u003cbranchname\u003e When you first start working on a new computer, you’ll clone the neurocontainer repository and connect it to neurocontainer upstream. A clone retrieves all current commits, including the ones you pushed to GitHub from your other computer.\nBut if you’re switching to another computer on which you have already cloned neurocontainer, you need to update your local Git database with new refs from your GitHub fork. You do this with git fetch:\n$ git fetch \u003cusername\u003e Ideally you should do this before you have made any commits on the same branch on the second computer. Then you can git merge on whichever branch you need to update:\n$ git checkout \u003cmy-branch\u003e Switched to branch '\u003cmy-branch\u003e' $ git merge origin/master If you have already made commits on the second computer that you need to keep, you’ll need to use git log FETCH_HEAD to identify that hashes of the commits you want to keep and then git cherry-pick \u003ccommit\u003e those commits into whichever branch you need to update.\n","categories":"","description":"Troubleshoot commit issue with Git\n","excerpt":"Troubleshoot commit issue with Git\n","ref":"/neurodesk.github.io/developers/new_tools/troubleshooting/","tags":"","title":"Troubleshooting"},{"body":"Menu entry As we want to propose several versions of the tools, each piece of software should have its own submenu under VNM Neuroimaging. To do so, you first have to add a submenu to menus/vnm-applications.menu by adding:\n\u003c!-- [[Tool Name]] submenu --\u003e \u003cMenu\u003e  \u003cName\u003e[[Tool Name]]\u003c/Name\u003e  \u003cDirectory\u003evnm-[[tool-name]].directory\u003c/Directory\u003e  \u003cInclude\u003e  \u003cAnd\u003e  \u003cCategory\u003e[[Tool-Name]]\u003c/Category\u003e  \u003c/And\u003e  \u003c/Include\u003e \u003c/Menu\u003e \u003c!-- End [[Tool Name]] --\u003e The following table shows the formatting rules to follow:\n   Placeholder Rule Example     [[Tool name]] Capitalized, spaces ITK snap   [[tool-name]] Lower case, no spaces (use - instead) itk-snap or itksnap   [[Tool-name]] Capitalized, no spaces (use - instead) ITK-snap    Next, we have to create the submenu itself as we referenced it by vnm-[[tool-name]].directory. To do so, create the file menus/submenus/vnm-[[tool-name]].directory and add the following information inside:\n[Desktop Entry] Name=[[Tool Name]] Comment=[[Tool Name]] Icon=/home/neuro/.config/lxpanel/LXDE/icons/[[icon-name]].png Type=Directory If a specific icon is available in the menus/icons directory, replace [[icon-name]] by its name. Otherwise, use vnm.\nCreate the application Finally, we have to create the actual application by creating the file menus/applications/vnm-[[tool-name]]-[[0.0.0]].desktop. The name of this file must contain the version of the tool (once again to allow multiple versions to live inside the same directory). Add the following description to this file:\n[Desktop Entry] Name=[[Tool Name]] [[0.0.0]] [[(Install only)]] GenericName=[[Tool Name]] [[0.0.0]] Comment=The description of what clicking on this application does. # This will be the tooltip of the application. Exec=The command used to run the application. Icon=/home/neuro/.config/lxpanel/LXDE/icons/[[icon-name]].png Type=Application Categories=[[Tool-name]] Terminal=true # or false The important part here is the value of Exec. If the tool is in the form of a singularity image, you should run the following command:\nbash /usr/share/fetch_and_run.sh [[tool-name]] [[0.0.0]] [[YYYYMMDD]] [[cmd]] [[args]] What fetch_and_run.sh does is check if the image is already installed as a module. If not, it checks whether it can be installed or not (return 1 if not possible). After that, it installs the image as a module. If [[cmd]] is specified, once the image is installed, it runs the command by giving the arguments from [[args]]. Here are two examples for FreeSurfer and FreeView. This first one only installs the image as a module:\nbash /usr/share/fetch_and_run.sh freesurfer 6.0.1 20200506 And this does the same but runs FreeView afterward:\nbash /usr/share/fetch_and_run.sh freesurfer 6.0.1 20200506 freeview The resulting .desktop file corresponding to FreeView contains:\n[Desktop Entry] Name=FreeView 6.0.1 GenericName=FreeView 6.0.1 Comment=Start FreeView 6.0.1 Exec=bash /usr/share/fetch_and_run.sh freesurfer 6.0.1 20200506 freeview Icon=/home/neuro/.config/lxpanel/LXDE/icons/run.png Type=Application Categories=FreeSurfer Terminal=true ","categories":"","description":"Menu entries in neurodesktop\n","excerpt":"Menu entries in neurodesktop\n","ref":"/neurodesk.github.io/developers/new_tools/menu_entries/","tags":"","title":"Menu entries"},{"body":"Neurodesk is an open-source project that is always evolving. If you are experiencing an issue not listed here, please open a new issue, so that we can aim to solve it and update our help documentation.\nTo ask questions or suggest new features, join the discussion on github.\nI cannot copy and paste text within Neurodesktop using keyboard shortcuts If you’re using Mac, you might be trying to use Mac keyboard shortcuts, but Neurodesktop is using Linux keyboard shortcuts (CTRL+C and CTRL+V)\nIf you use the terminal, please see “I fixed my internet browser clipboard, but copy or paste still do not work in the terminal” below.\nCopying text from my host computer and pasting it inside Neurodesktop doesn’t work in Firefox This is a “feature” of firefox and you can disable this “feature”:\n navigate to about:config and “Accept the Risk and Continue” (“about:config” needs to be entered in the address bar of firefox and hit enter) now search for clipboard and then set the following to “true”:  dom.events.asyncClipboard.clipboardItem dom.events.asyncClipboard.read dom.events.testing.asyncClipboard    Then close firefox and restart. Then the clipboard should work as one would expect.\nIf the clipboard still does not work, check “I fixed my internet browser clipboard, but …” sections below.\nCopy and paste between my host computer and Neurodesktop (or vice versa) doesn’t work in Chrome or Edge The browsers have a security feature to protect you from something stealing your clipboard content. Depending on your security settings you have to enable it explicitly - it’s a little icon in the browser address bar that looks like a clipboard.\nAfter pressing the icon, you should choose the option shown below in the dialog that opens. After pressing “Done”, close the current browser tab and open a new one for the changes to take effect.\nIf the clipboard still does not work, check “I fixed my internet browser clipboard, but …” sections below.\nI fixed my internet browser clipboard, but copy or paste still do not work in the terminal The terminal is using special keyboard shortcuts, Shift+CTRL+C for copy, and Shift+CTRL+V for paste. Alternatively, you can copy and paste text by using the terminal’s “Edit” menu.\nI fixed my internet browser clipboard, but copy or paste still do not work in the file browser The copy and paste options in the “Edit” menu of the file browser are used to copy and paste files, not text. To copy and paste text from/into the file browser application (e.g., copy a path into the path field in the top), use the CTRL+C and CTRL+V keyboard shortcuts.\nI fixed my internet browser clipboard, but copy or paste still do not work in a specific/all applications If you’re using Mac, you might be trying to use Mac keyboard shortcuts, but Neurodesktop is using Linux keyboard shortcuts. For more details, read the “Note for Mac users” here.\nIf it still does not work, or if your host is Windows or Linux, please report the problem and we will do our best to help you:\n Copy some text from your host computer (CTRL+C, or Command+C) Open the Mousepad text editor in Neurodesktop (Start button –\u003e “Accessories” —-\u003e “Mousepad”) Try to paste the text using the menu option “Edit” –\u003e “Paste” Try to paste the text again using CTRL+V If you don’t have one already, please create a Github account here Go to our discussion forum here If you are not logged into Github, please log in (upper right corner) Press “New Discussion” button In the message that you write, please specify your operating system, your internet browser, the application in question, and if you can copy/paste to Mousepad and how?  docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?. This is usually a docker-related error, not related to neurodesktop itself. To troubleshoot docker, we can try a simpler container first:\ndocker run hello-world Try the following solutions (in this order, until the above command works)\n Win/Mac: Open docker GUI and accept T\u0026Cs. Check that the docker engine is running Close and open the terminal and retry. Log out and login again, or restart the machine (current user environment doesnt fully know docker is running) Add your user to the OS docker group (current user doesnt have permission to run docker) docker.sock permissions need to be changed (raise a github issue here)  Windows users: WSL not installed properly The Docker engine relies on the Windows subsystem for Linux (WSL) to run on a windows machine.\nNote We recommend the manual install instructions, as the simplified install requires an upgrade to a preview build of Windows that may be unstable.  If WSL is properly installed, the Resources tab of the Docker settings should look something like this:\nHowever, if WSL is missing or incorrectly configured, the Resources tab of the Docker settings may look something like this:\nIf this is the case, follow the manual install instructions to install WSL 2 (including installation of Ubuntu through Microsoft Store).\nWindows users: Not enough free space on the partition in Windows and WSL2 This could help: https://yjmantilla.github.io/tutorials/wsl2-move-vhdx.html\nWindows users: Failure to connect to Neurodesktop in Firefox We recommend using Microsoft Edge or Google Chrome to access Neurodesktop.\nTrouble installing neurodesk images This may be a memory issue. First, ensure that there is enough free space on the disk. If there is, try resetting docker settings and data. To do this:\n Open the docker engine Navigate to “Troubleshooting” (the bug icon in the top right). Click “Reset to factory defaults”  If you are still experiencing issues after this, you may need to update docker to the latest version. This can be achieved through “settings” in the docker engine, or (on windows) by right clicking on the docker tray icon:\nI got an error message ‘X killed’ or not enough memory This may be due to Docker not having access to enough RAM from your host computer.\nIf you are using Docker on MacOS  The memory amount is managed via the Docker settings:   If you are using Docker on Windows 10 with the WSL2 backend then this is managed by Windows settings. Try the following steps to check how much RAM Docker has access to and increase the amount if necessary.\n Run Docker Open a terminal (ie. Powershell) in the PC you want to use to run Neurodesktop (not in Neurodesktop itself) and type the following command:  docker info This will generate information about your Docker installation (make sure Docker is running during this step)\nLook for the line that says  Total Memory: **.**GiB If this value is ~2GB, try increasing it*:  Create a .wslconfig file in your user directory (for more detail instructions see: https://docs.microsoft.com/en-us/windows/wsl/wsl-config) In the .wslconfig file include the following lines:  [wsl2] memory=32GB  Quit Docker (make sure it’s not running in the background, ie. system tray, check task manager) In the terminal, run the following command  wsl --running --list This will list any running distributions. For the update to be successful, WSL needs to have comletely stopped running (ie. no distributions running)  Restart Docker and rerun steps 1-3 to confirm it was successful    If you are not using WSL2, you can check and manage your RAM allocation in the Docker desktop application.  Open the Docker application and navigate to settings \u003e resources \u003e advances Scroll down to the Memory option and use the sliding bar to adjust the setting Click apply and restart  *RAM requirements will vary based on the tools/data you are using. If the system you’re using has limited RAM, test out a few different amounts by running the above steps and then your analyses in Neurodesktop. Version 20220208 onwards has a memory monitor in the taskbar - you can use this to check how much memory Neurodesktop has access to and how much is being used by the analyses being run.\n","categories":"","description":"Are you experiencing issues with neurodesktop?","excerpt":"Are you experiencing issues with neurodesktop?","ref":"/neurodesk.github.io/docs/neurodesktop/troubleshooting/","tags":"","title":"Troubleshooting"},{"body":"","categories":"","description":"List of Applications. If any of the applications is not available under _Neurodesk_ --\u003e _All applications_ in Neurodesk's start menu (notice that menu entries are sorted alphabetically), you might not be using the latest version of Neurodesktop. Please use the platform-specific documentation page at https://www.neurodesk.org/docs/neurodesktop/getting-started/ to remove the current Neurodesktop (\"Stopping neurodesktop\" section down the page) and then re-install it (\"Quickstart\" section at the top of the page). If you are using the Nectar Desktop Service, please let us know on the discussion forum (https://github.com/NeuroDesk/neurodesk.github.io/discussions, Github account required) and we will notify you when the application becomes available there. \n","excerpt":"List of Applications. If any of the applications is not available …","ref":"/neurodesk.github.io/applications/","tags":"","title":"Applications"},{"body":"","categories":"","description":"Documentation for Developers\n","excerpt":"Documentation for Developers\n","ref":"/neurodesk.github.io/developers/","tags":"","title":"Developers"},{"body":"development  updated qsmxt to 1.1.12 updated 3D Slicer to 5.0.3 and included MONAI Label added Matlab 2022a updated AFNI to 22.1.14 updated Spinal Cord Toolbox to 5.7 updated Oshyx to 0.4  20220701  added laynii 2.2.1 - layer fMRI toolbox (contributed by Renzo Huber) added fieldtrip 20220617 - eeg processing (contributed by David White)  20220329  added bidscoin 3.7.0 (converting data to bids) contributed by Oren added sigviewer 0.6.4 (viewing electrophysiological data) contributed by Tom added niftyreg 1.4.0 (image registration tool) contributed by Steffen added mne 1.0.0 (EEG processing pipeline) contributed by David  20220302  update of ROMEO (phase unwrapping) to latest version 3.2.8 update of QSMxT (automated end-to-end QSM procerssing) to latest version 1.1.10 added mritools 3.3.0 (includes clearswi 1.0.1, mcpc3ds 0.1.0, romeo 3.2.8 as compiled binaries)  20220222  update for PhysIO toolbox (physiological noise correction for fMRI) to r2021a including the latest SPM r8224 update of lcmodel to include basis sets for 1.5-9.4T added a memory display plugin to illustrate how much memory is available to the container and how much is consumed added a version checker to help with identifying if a new version is available added file upload via guacamole (+ update of guacamole to 1.4) - users can now drag and drop their files onto guacamole and they get copied to the desktop  20220128  update of Spinalcordtoolbox to 5.5 update of CAT12 to r1933  20220121  MNE Python 0.23.4 container including VScode and extensions VScode container including Python/Julia Extensions and singularity to test “Inception Mode” (Running singularity containers withtin singularity containers) update of fsl to 6.0.5.1 added CAT12 (a software that allows estimation of tissue volumes (and additional surface parameters such as cortical thickness, gyrification or fractal dimension) for different volume and surface-based atlas maps)  20220111  a deep learning based vessel segmentation algorithm “vesselapp” was added in version 0.3.1 palm - Permutation Analysis of Linear Models - was added in version alpha119 niistat running in octave was added with version 1.0.20191216 MRIcroGL was updated to a version with included python support, so the scripting is now working rabies - Rodent Automated Bold Improvement of EPI Sequences was added with version 0.3.5 oshyx was updated to 0.3  20211220  neurodesktop can now be accessed via native RDP client as well (e.g. for multi-monitor support): https://www.neurodesk.org/docs/neurodesktop/getting-started/windows/#using-an-rdp-client there is a new Help button in the menu :) updates of ants 2.3.4 (now includes Scripts as well, including antsCookTemplatePriors.sh) + newly added version 2.3.5 new version of QSMxT 1.1.9 20211219 new version of Spinal Cord Toolbox 5.4 new tools: MRIcroGL and surfice - fantastic viewers for neuroimaging data  20211207  Physio toolbox compiled and added to SPM + update of SPM added brainstorm new neurodesktop container management scripts for Linux, Mac and Windows: https://github.com/NeuroDesk/neurodesktop added fieldtrip Datalad is now in the main image, so datalad run should work added Oshy-X segmentation tool updated freesurfer 7.2.0  20211028  added EEGLAB  20211018  added Rstudio, R and multiple R packages (plotly, car, tidyverse, …) added ClearSWI and ROMEO for MRI phase processing (including new Tutorials: https://www.neurodesk.org/tutorials/phase_processing/) added more categories in applications menu (Body, Electrophysiology, Hippocampus, Phase Processing, Rodent Imaging, Shape Analysis, Spine, Statistics) bugfix: improved startup time of the desktop container (miniconda in homedirectory was causing chmod slowdown) bugfix: ssh, vnc and rdp servers are now restarted in case the container was stopped and started again (e.g. on Standby)  20210929  fixed naming of aidmri to aidamri and added new category “Rodent Imaging” updated all tool icons and updated neurodesk icon including background image VScode now stores settings in persistent storage /neurodesktop-storage and with this keeps extensions and settings across different neurodesktop versions docker layers are now cached, so updating the desktop to the next version is very fast and consumes less disk space locally default theme of terminal changed from Solarized to Tango as the old theme was hiding information in tools like htop (same font colour on same background…)  20210923  removed faulty mriqc 0.15.2 container neurodesk.github.io is now starting page in firefox browser  20210918  added mriqc 0.16.1 and mrtrix 3.0.3  20210917  included more tools for connecting to cloud storage services (rclone, owncloud, nextcloud, davfs2, globus). For more info: Storage styling of desktop interface, including background wallpaper and colour scheme in terminal window new categories in menu system (visualization) and added more categories to tools  20210916  This is the first version of the newly renamed and rebuild neurodesktop (previously vnm and neuromachine) containers are mounted by default from CVMFS, but this can be deactivated by adding -e CVMFS_DISABLE=true to the docker call  ","categories":"","description":"Previous releases of neurodesktop","excerpt":"Previous releases of neurodesktop","ref":"/neurodesk.github.io/docs/neurodesktop/release-history/","tags":"","title":"Release History"},{"body":"","categories":"","description":"Tutorials\n","excerpt":"Tutorials\n","ref":"/neurodesk.github.io/tutorials/","tags":"","title":"Tutorials"},{"body":"Install CVMFS First you need to install CVMFS. Follow the official instructions here: https://cvmfs.readthedocs.io/en/stable/cpt-quickstart.html#getting-the-software\none example for Ubuntu in Windows Subsystem for Linux (WSL) could look like this:\n\" sudo apt-get install lsb-release wget https://ecsft.cern.ch/dist/cvmfs/cvmfs-release/cvmfs-release-latest_all.deb sudo dpkg -i cvmfs-release-latest_all.deb rm -f cvmfs-release-latest_all.deb sudo apt-get update sudo apt-get build-essential sudo apt-get install cvmfs  Configure CVMFS Once installed create the keys and configure the servers used:\n\" sudo mkdir -p /etc/cvmfs/keys/ardc.edu.au/ echo \"-----BEGIN PUBLIC KEY----- MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwUPEmxDp217SAtZxaBep Bi2TQcLoh5AJ//HSIz68ypjOGFjwExGlHb95Frhu1SpcH5OASbV+jJ60oEBLi3sD qA6rGYt9kVi90lWvEjQnhBkPb0uWcp1gNqQAUocybCzHvoiG3fUzAe259CrK09qR pX8sZhgK3eHlfx4ycyMiIQeg66AHlgVCJ2fKa6fl1vnh6adJEPULmn6vZnevvUke I6U1VcYTKm5dPMrOlY/fGimKlyWvivzVv1laa5TAR2Dt4CfdQncOz+rkXmWjLjkD 87WMiTgtKybsmMLb2yCGSgLSArlSWhbMA0MaZSzAwE9PJKCCMvTANo5644zc8jBe NQIDAQAB -----END PUBLIC KEY-----\" | sudo tee /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub echo \"CVMFS_USE_GEOAPI=yes\" | sudo tee /etc/cvmfs/config.d/neurodesk.ardc.edu.au.conf echo 'CVMFS_SERVER_URL=\"http://cvmfs.neurodesk.org/cvmfs/@fqrn@;http://cvmfs-brisbane.neurodesk.org/cvmfs/@fqrn@;http://cvmfs-sydney.neurodesk.org/cvmfs/@fqrn@;http://cvmfs-frankfurt.neurodesk.org/cvmfs/@fqrn@;http://cvmfs-zurich.neurodesk.org/cvmfs/@fqrn@;http://cvmfs-toronto.neurodesk.org/cvmfs/@fqrn@;http://cvmfs-ashburn.neurodesk.org/cvmfs/@fqrn@;http://cvmfs.neurodesk.org/cvmfs/@fqrn@\"' | sudo tee -a /etc/cvmfs/config.d/neurodesk.ardc.edu.au.conf echo 'CVMFS_KEYS_DIR=\"/etc/cvmfs/keys/ardc.edu.au/\"' | sudo tee -a /etc/cvmfs/config.d/neurodesk.ardc.edu.au.conf echo \"CVMFS_HTTP_PROXY=DIRECT\" | sudo tee /etc/cvmfs/default.local echo \"CVMFS_QUOTA_LIMIT=5000\" | sudo tee -a /etc/cvmfs/default.local sudo cvmfs_config setup # this is only necessary for WSL: sudo cvmfs_config wsl2_start sudo cvmfs_config chksetup ls /cvmfs/neurodesk.ardc.edu.au sudo cvmfs_talk -i neurodesk.ardc.edu.au host probe sudo cvmfs_talk -i neurodesk.ardc.edu.au host info cvmfs_config stat -v neurodesk.ardc.edu.au  For Ubuntu 22.04 users If configuring CVMFS returns the following error:\n\" Error: failed to load cvmfs library, tried: './libcvmfs_fuse3_stub.so' '/usr/lib/libcvmfs_fuse3_stub.so' '/usr/lib64/libcvmfs_fuse3_stub.so' './libcvmfs_fuse_stub.so' '/usr/lib/libcvmfs_fuse_stub.so' '/usr/lib64/libcvmfs_fuse_stub.so' ./libcvmfs_fuse3_stub.so: cannot open shared object file: No such file or directory /usr/lib/libcvmfs_fuse3_stub.so: cannot open shared object file: No such file or directory /usr/lib64/libcvmfs_fuse3_stub.so: cannot open shared object file: No such file or directory ./libcvmfs_fuse_stub.so: cannot open shared object file: No such file or directory libcrypto.so.1.1: cannot open shared object file: No such file or directory /usr/lib64/libcvmfs_fuse_stub.so: cannot open shared object file: No such file or directory Failed to read CernVM-FS configuration  A temporary workaround is:\n\" wget https://mirror.umd.edu/ubuntu/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2.15_amd64.deb dpkg -i libssl1.1_1.1.1f-1ubuntu2.15_amd64.deb  install singularity/apptainer e.g. for Ubuntu/Debian:\n\" export VERSION=1.18.3 OS=linux ARCH=amd64 \u0026\u0026 \\ wget https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz \u0026\u0026 \\ sudo tar -C /usr/local -xzvf go$VERSION.$OS-$ARCH.tar.gz \u0026\u0026 \\ rm go$VERSION.$OS-$ARCH.tar.gz echo 'export GOPATH=${HOME}/go'  ~/.bashrc \u0026\u0026 \\ echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin'  ~/.bashrc \u0026\u0026 \\ source ~/.bashrc go get -d github.com/sylabs/singularity export VERSION=v3.10.0 # or another tag or branch if you like \u0026\u0026 \\ cd $GOPATH/src/github.com/sylabs/singularity \u0026\u0026 \\ git fetch \u0026\u0026 \\ git checkout $VERSION # omit this command to install the latest bleeding edge code from master export VERSION=3.10.0 \u0026\u0026 # adjust this as necessary \\ mkdir -p $GOPATH/src/github.com/sylabs \u0026\u0026 \\ cd $GOPATH/src/github.com/sylabs \u0026\u0026 \\ wget https://github.com/sylabs/singularity/releases/download/v${VERSION}/singularity-ce-${VERSION}.tar.gz \u0026\u0026 \\ tar -xzf singularity-ce-${VERSION}.tar.gz \u0026\u0026 \\789 cd ./singularity-ce-${VERSION} \u0026\u0026 \\ ./mconfig --without-seccomp --without-conmon ./mconfig --without-seccomp --without-conmon \u0026\u0026 \\ make -C ./builddir \u0026\u0026 \\ sudo make -C ./builddir install export PATH=\"/usr/local/singularity/bin:${PATH}\"  use of Neurodesk CVMFS containers The containers are now available in /cvmfs/neurodesk.ardc.edu.au/containers/ and can be started with:\n\" singularity shell /cvmfs/neurodesk.ardc.edu.au/containers/itksnap_3.8.0_20201208/itksnap_3.8.0_20201208.simg  make sure that SINGULARITY_BINDPATH include the directories you want to work with:\n\" export SINGULARITY_BINDPATH='/cvmfs,/mnt,/home'  WSL doesn’t support homedirectory - so don’t mount this \" singularity shell --no-home /cvmfs/neurodesk.ardc.edu.au/containers/itksnap_3.8.0_20201208/itksnap_3.8.0_20201208.simg  or configure permanently:\n\" sudo vi /etc/singularity/singularity.conf  set\n\" mount home = no  install module system: \" sudo yum install lmod  configure module system: content of /usr/share/module.sh :\n\" # system-wide profile.modules # # Initialize modules for all sh-derivative shells # #----------------------------------------------------------------------# trap \"\" 1 2 3 case \"$0\" in -bash|bash|*/bash) . /usr/share/lmod/6.6/init/bash ;; -ksh|ksh|*/ksh) . /usr/share/lmod/6.6/init/ksh ;; -zsh|zsh|*/zsh) . /usr/share/lmod/6.6/init/zsh ;; -sh|sh|*/sh) . /usr/share/lmod/6.6/init/sh ;; *) . /usr/share/lmod/6.6/init/sh ;; # default for scripts esac trap - 1 2 3  use of containers in the module system: add this to .bashrc:\n\" if [ -f '/usr/share/module.sh' ]; then source /usr/share/module.sh; fi if [ -d /cvmfs/neurodesk.ardc.edu.au/neurodesk-modules ]; then # export MODULEPATH=\"/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules\" module use /cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/* else export MODULEPATH=\"/neurodesktop-storage/containers/modules\" module use $MODULEPATH export CVMFS_DISABLE=true fi if [ -f '/usr/share/module.sh' ]; then echo 'Run \"ml av\" to see which tools are available - use \"ml \" to use them in this shell.' if [ -v \"$CVMFS_DISABLE\" ]; then if [ ! -d $MODULEPATH ]; then echo 'Neurodesk tools not yet downloaded. Choose tools to install from the Application menu.' fi fi fi  use of containers in the module system: \" export SINGULARITY_BINDPATH='/cvmfs,/mnt,/home' module use /cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/* ml fsl fslmaths  ","categories":"","description":"Neurodesk Singularity Containers on CVMFS\n","excerpt":"Neurodesk Singularity Containers on CVMFS\n","ref":"/neurodesk.github.io/docs/neurocontainers/cvmfs/","tags":"","title":"CVMFS"},{"body":"Once this is completed: https://github.com/ReproNim/containers/issues/64#issuecomment-999126787\n","categories":"","description":"Neurodesktop containers can be used in datalad container run\n","excerpt":"Neurodesktop containers can be used in datalad container run\n","ref":"/neurodesk.github.io/docs/neurocontainers/datalad/","tags":"","title":"Datalad"},{"body":"Our containers are automatically built in https://github.com/NeuroDesk/neurocontainers/ and hosted on dockerhub or on github\nPull Docker containers e.g. for a julia container docker\ndocker pull vnmd/julia_1.6.1 build singularity image from dockerhub\nsingularity build julia_1.6.1.simg docker://vnmd/julia_1.6.1 Replace julia_1.6.1 with your selected application. You can find the available containers here: https://www.neurodesk.org/applications/\n","categories":"","description":"Neurodesk Docker containers\n","excerpt":"Neurodesk Docker containers\n","ref":"/neurodesk.github.io/docs/neurocontainers/docker/","tags":"","title":"Docker"},{"body":"This notebook demonstrates how to use all Neurodesk applications in Google Colab: https://colab.research.google.com/drive/1g5cnZxj1llRaHmOs4xSglqsXnFkQYuol?usp=sharing\n","categories":"","description":"Neurodesk Singularity Containers for Google Colab\n","excerpt":"Neurodesk Singularity Containers for Google Colab\n","ref":"/neurodesk.github.io/docs/neurocontainers/googlecolab/","tags":"","title":"Google Colab"},{"body":"  Get started with Neurodesk A flexible, scalable, and browser-based data analysis environment for reproducible neuroimaging\nWhat is Neurodesk ?  Linux   Windows   Mac   HPC   Cloud   Play        Neurodesktop  Fully featured desktop in a container\nRead more …\n   Neurocommand  Core installer\nRead more …\n   Neurocontainers  Software container library\nRead more …\n   Neurodesk Play  (New) Try out Neurodesk in the browser\nRead more …\n   Nectar Desktop Service  Run Neurodesktop in the Nectar Virtual Desktop Service (Requires login)\nRead more …\n   Google Colab  Run Neurodesk Singularity Containers in Google Colab\nRead more …\n       FAQ  Frequently Asked Questions\nRead more …\n   Discussions  Ask questions, suggest new features or raise any issues you have (Github account required)\nRead more …\n   Contributors  Contributors\nRead more …\n    ","categories":"","description":"","excerpt":"  Get started with Neurodesk A flexible, scalable, and browser-based …","ref":"/neurodesk.github.io/","tags":"","title":"Neurodesk"},{"body":"Click the link below for your own instance of Neurodesk on your browser running on Oracle cloud resources.\nhttps://play.neurodesk.org/v2/gh/neurodesk/jupyter-neurodesktop-image/main?urlpath=neurodesktop\n You can upload data to the desktop by simply drag-and-dropping files on the browser window. Data uploaded during your session are stored on Oracle Cloud, and will be automatically deleted at the end of the session. To download your files before deletion: You need to open the guacamole settings by pressing CTRL-ALT-SHIFT (Control-Command-Shift on Mac). This will open a menu on the side:\nwhere you can click on “Shared Drive”:\nand a click (or double clink on Mac) on the file will start the download.\nYou can browse into folders in the shared drive by clicking (double clicking on Mac) on them. To get back to the base of the shared drive, press on the drive icon in the top left of the side menu (just below the “Shared Drive” title).\nTo close the side menu, click on CTRL-ALT-SHIFT once more (Control-Command-Shift on Mac).\n","categories":"","description":"Run a demo of neurodesktop _without_ installing anything\n","excerpt":"Run a demo of neurodesktop _without_ installing anything\n","ref":"/neurodesk.github.io/docs/neurodesktop/getting-started/play/","tags":"","title":"Play"},{"body":"","categories":"","description":"","excerpt":"","ref":"/neurodesk.github.io/search/","tags":"","title":"Search Results"},{"body":"Our docker containers are converted to singularity containers and stored on Object storage.\nDownload Singularity Containers First get an overview which containers are available as Singularity containers: https://github.com/NeuroDesk/neurodesk/blob/master/cvmfs/log.txt\ncurl -s https://raw.githubusercontent.com/NeuroDesk/neurodesk/master/cvmfs/log.txt assign the container name to a variable:\nexport container=itksnap_3.8.0_20201208 Then download the containers. An easy way is to use CURL (e.g. downloading from the US location):\ncurl -X GET https://objectstorage.us-ashburn-1.oraclecloud.com/n/sd63xuke79z3/b/neurodesk/o/${container}.simg -O or from australia\ncurl -X GET https://objectstorage.ap-sydney-1.oraclecloud.com/n/sd63xuke79z3/b/neurodesk/o/${container}.simg -O A faster way is pulling from multiple storage locations at once using aria2:\naria2c https://objectstorage.us-ashburn-1.oraclecloud.com/n/sd63xuke79z3/b/neurodesk/o/${container}.simg https://objectstorage.eu-frankfurt-1.oraclecloud.com/n/sd63xuke79z3/b/neurodesk/o/${container}.simg https://objectstorage.ap-sydney-1.oraclecloud.com/n/sd63xuke79z3/b/neurodesk/o/${container}.simg https://swift.rc.nectar.org.au/v1/AUTH_dead991e1fa847e3afcca2d3a7041f5d/neurodesk/${container}.simg Transparent Singularity The singularity containers can be also be used in combination with our Transparent Singularity Tool tool, that wraps the executables inside a container to make them easily available for pipelines. More information can be found here:\none example to do this is:\ncurl -s https://raw.githubusercontent.com/NeuroDesk/neurodesk/master/cvmfs/log.txt export container=itksnap_3.8.0_20201208 git clone https://github.com/NeuroDesk/transparent-singularity ${container} cd ${container} ./run_transparent_singularity.sh ${container} ","categories":"","description":"Neurodesk Singularity Containers\n","excerpt":"Neurodesk Singularity Containers\n","ref":"/neurodesk.github.io/docs/neurocontainers/singularity/","tags":"","title":"Singularity"},{"body":"1. Install WSL Follow the instructions to enable Windows Subsystem for Linux 2 in Windows 11: https://docs.microsoft.com/en-us/windows/wsl/install\n2. Configure CVFMS, Singularity and LMOD (only needs to be done once) Install build tools \" sudo apt update sudo apt install make gcc   Install singularity \" export SINGULARITY_VERSION=3.9.3 VERSION=1.17.2 OS=linux ARCH=amd64 wget -q https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz sudo tar -C /usr/local -xzvf go$VERSION.$OS-$ARCH.tar.gz rm go$VERSION.$OS-$ARCH.tar.gz export GOPATH=${HOME}/go export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin mkdir -p $GOPATH/src/github.com/sylabs cd $GOPATH/src/github.com/sylabs wget -q https://github.com/sylabs/singularity/releases/download/v${SINGULARITY_VERSION}/singularity-ce-${SINGULARITY_VERSION}.tar.gz tar -xzvf singularity-ce-${SINGULARITY_VERSION}.tar.gz cd singularity-ce-${SINGULARITY_VERSION} ./mconfig --prefix=/usr/local/singularity make -C builddir sudo make -C builddir install cd .. sudo rm -rf singularity-ce-${SINGULARITY_VERSION} sudo rm -rf /usr/local/go $GOPATH   Setup Bindpaths for Singularity (e.g. in .bashrc) \" export PATH=\"/usr/local/singularity/bin:${PATH}\" export SINGULARITY_BINDPATH='/cvmfs,/mnt,/home'  CVMFS Follow the instructions here: https://www.neurodesk.org/docs/neurocontainers/cvmfs/\nLMOD \" apt install lmod  3. Use Neurodesk containers \" module use /cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/* ml av ml fsl fsleyes  ","categories":"","description":"Use Neurocontainers on Windows 11 with WSL and Wayland Display Server\n","excerpt":"Use Neurocontainers on Windows 11 with WSL and Wayland Display Server\n","ref":"/neurodesk.github.io/docs/neurocontainers/windows11-wsl/","tags":"","title":"Windows 11 and Windows Subsystem for Linux"}]